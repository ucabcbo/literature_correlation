"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Satellite Image Fusion Based on Improved Fast Discrete Curvelet Transforms","K. Jemseera; P. Noufal","Dept. of Electron. & Commun., M.E.S Coll. of Eng., Kuttippuram, India; Dept. of Electron. & Commun., M.E.S Coll. of Eng., Kuttippuram, India","2015 Fifth International Conference on Advances in Computing and Communications (ICACC)","17 Mar 2016","2015","","","430","433","Image fusion is the process of merging two or more images into a more informative single image. Satellite image fusion uses high resolution panchromatic image and low resolution multispectral image. IHS, Brovery, PCA, Wavelet, Curvelet etc are the existing techniques available for image fusion. But simultaneous retention of spatial and spectral resolution is an important concern in remote sensing applications. In this paper we proposed an improved Satellite image fusion method based on Fast Discrete curvelet Transform (FDCT) via wrapping. The method uses an improved fusion rule, were the maximum FDCT coefficients from each cell of the Intensity component of the MS image and histogram matched PAN image are taken. The resulting image is then undergone a comparative analysis with the outcomes of existing methodologies. The comparative analysis proves that the proposed method retains more spatial and spectral details than other methods.","","978-1-4673-6994-7","10.1109/ICACC.2015.30","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7433897","Image Fusion;Fast Discrete Curvelet Transforms;Intensity-Hue-Transforms;wavelet transforms","Image fusion;Spatial resolution;Discrete wavelet transforms;Satellites","curvelet transforms;image fusion;remote sensing","satellite image fusion;fast discrete curvelet transforms;panchromatic image;low resolution multispectral image;remote sensing;maximum FDCT coefficients","","","","13","IEEE","17 Mar 2016","","","IEEE","IEEE Conferences"
"FPGA implementation of satellite image fusion using wavelet substitution method","G. Mamatha; V. Sumalatha; M. V. Lakshmaiah","Dept. of ECE, JNTUACEA, Ananthapuramu, India; Dept. of ECE, JNTUACEA, Ananthapuramu, India; Dept. of ECE, JNTUACEA, Ananthapuramu, India","2015 Science and Information Conference (SAI)","3 Sep 2015","2015","","","1155","1159","Image fusion is a process of merging the relevant information from a set of images into a single image. The goal of image fusion in remote sensing is to create new images that contain both low spatial resolution multispectral data (color information) and high spatial resolution panchromatic data (details). The choice of appropriate wavelet filters for the design and implementation on FPGA, a detailed analysis has been carried out in MATLAB Simulink R2010b software using averaging, additive and substitutive fusion rules. In this paper substitutive rule using the Haar, Daubechies 3 (db3) and Cohen Daubechies Feauveau (CDF) 9/7 filters are used for image decomposition and reconstruction. CDF 9/7 is found to be the best filter and is chosen for FPGA implementation. Single level 2D-DWT based image fusion has been performed using substitutive method and then the hardware software co-simulation design has been synthesized in Xilinx ISE 13.1 and implemented on ML605 Virtex 6 FPGA kit. From the results, it is observed that the design consumes a total power of 4.349W and operates at a maximum frequency of 849.618MHz.","","978-1-4799-8547-0","10.1109/SAI.2015.7237290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237290","Image Fusion;Image Resampling;Image Registration;DWT;FPGA","Image fusion;Field programmable gate arrays;Image resolution;Software;Hardware;Generators","artificial satellites;discrete wavelet transforms;field programmable gate arrays;geophysical image processing;hardware-software codesign;image colour analysis;image filtering;image fusion;image reconstruction;image resolution;remote sensing","FPGA implementation;satellite image fusion;wavelet substitution method;information merging;remote sensing;low-spatial resolution multispectral data;color information;high-spatial resolution panchromatic data;wavelet filters;MATLAB Simulink R2010b software;averaging fusion rule;additive fusion rule;substitutive fusion rule;Haar-Daubechies-3 filter;Cohen-Daubechies-Feauveau filter;CDF-9/7 filter;image decomposition;image reconstruction;single-level 2D-DWT based image fusion;substitutive method;hardware software co-simulation design;Xilinx ISE 13.1;ML605 Virtex 6 FPGA kit","","7","","10","IEEE","3 Sep 2015","","","IEEE","IEEE Conferences"
"FY-3D/MERSI-II Meteorological Satellite Image Fusion Method and its Application","Z. Yunyu; C. Yingying; W. Ming; H. Mingqiong; T. Jing","School of Resource and Environmental Science, Wuhan University, Wuhan, China; Hubei Meteorological Service Center, Wuhan, China; Institute of Heavy Rain, CMA, Wuhan, China; Hubei Meteorological Service Center, Wuhan, China; Hubei Meteorological Service Center, Wuhan, China","2020 IEEE 3rd International Conference on Information Systems and Computer Aided Education (ICISCAE)","2 Nov 2020","2020","","","237","240","In order to solve the problem that the spatial resolution of some channels of the FY-3D satellite medium-resolution spectral imager (MERSI-II) is not high enough, 19 channel images with a spatial resolution of 1000 meters are merged and enhanced. Based on the geometric correction of the original data, the Gram-Schimidt Transform remote sensing fusion algorithm is selected, and the panchromatic image extracted from the MERSI-II 250-meter spatial resolution image is used. Then selected the WMO “natural color” synthesis scheme is to display RGB three-color synthesis on the fused image. The result of FY-3D satellite image data fusion shows that the fused image has clear colors, which not only retains the multi-spectral characteristics of 1000-meter channel data, but also has the high-resolution advantage of 250-meter channel data. The comparison experiment found that compared with the original image, the fused image has greatly improved the ability to recognize the topography of rivers, lakes, land and sea boundaries, and mountain range trends. And the ability to recognize snow, vegetation cover, and structural features of cloud has also been significantly enhanced. The fusion algorithm can greatly improve the remote sensing fine analysis capability of FY-3D / MERSI - II images in the fields of disaster prevention and mitigation and ecological civilization construction.","","978-1-7281-8304-6","10.1109/ICISCAE51034.2020.9236890","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9236890","FY-3D;Image fusion;spatial resolution;remote sensing","Spatial resolution;Remote sensing;Satellites;Monitoring;Image fusion;Snow;Image color analysis","ecology;geophysical image processing;geophysical techniques;image colour analysis;image fusion;image resolution;remote sensing;sensor fusion","FY-3D satellite medium-resolution spectral imager;channel images;Gram-Schimidt Transform remote sensing fusion algorithm;panchromatic image;spatial resolution image;WMO natural color synthesis scheme;FY-3D satellite image data fusion;channel data;high-resolution advantage;MERSI-II meteorological satellite image fusion method;RGB three-color synthesis;topography;rivers;lakes;sea boundaries;land boundaries;snow;mountain range trends;vegetation cover;structural features","","","","24","IEEE","2 Nov 2020","","","IEEE","IEEE Conferences"
"Satellite Image Fusion using FDCT for Land Cover Classification","S. K. Naik; H. Ramesh","Water Resources and Ocean Engineering National Institute of Technology Karnataka, Mangalore, India; Water Resources and Ocean Engineering National Institute of Technology Karnataka, Mangalore, India","2021 IEEE 6th International Conference on Computing, Communication and Automation (ICCCA)","10 Jan 2022","2021","","","81","86","Remote sensing is a fast developing field of science involving repetitive collection of data from earth observing satellites. However each satellite system has one or more limitations, giving rise to the need of data collection from multiple sources and their fusion. Landsat 8 collects images in a broad spectrum but at a coarser spatial resolution of 30m. Cartosat-1 collects images at a high spatial resolution of 2.5m but lacks color details. Good visually interpretable images are indispensable for land cover classification. In this paper, the Landsat 8 and Cartosat-1 images are fused by using the Fast Discrete Curvelet Transform (FDCT) method. Supervised classification using the Random Forest (RF) classifier is performed on the Landsat 8 multispectral image and the fused image. The results showed high quality of image fusion based on the entropy, RMSE and CC values obtained for the given dataset. The fusion process also improved the overall accuracy of the land cover classification.","2642-7354","978-1-6654-1473-9","10.1109/ICCCA52192.2021.9666283","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9666283","Satellite image fusion;Land cover classification","Earth;Satellites;Artificial satellites;Stereo image processing;Transforms;Entropy;Spatial resolution","curvelet transforms;geophysical image processing;image classification;image fusion;image resolution;land cover;remote sensing","fused image;fusion process;land cover classification;satellite image fusion;FDCT;remote sensing;earth observing satellites;satellite system;data collection;coarser spatial resolution;high spatial resolution;good visually interpretable images;Cartosat-1 images;Fast Discrete Curvelet Transform method;supervised classification;Landsat 8 multispectral image;size 30.0 m;size 2.5 m","","","","29","IEEE","10 Jan 2022","","","IEEE","IEEE Conferences"
"A New Satellite Image Fusion Method Based on Distributed Compressed Sensing","F. Li; S. Hong; L. Wang","Department of Communication Engineering, Xiamen University, Fujian, China; Department of Communication Engineering, Xiamen University, Fujian, China; Department of Communication Engineering, Xiamen University, Fujian, China","2018 25th IEEE International Conference on Image Processing (ICIP)","6 Sep 2018","2018","","","1882","1886","In this paper, we propose a method for fusion of low-resolution multispectral (LRM) image and high-resolution panchromatic (HRP) image to obtain high-resolution multispectral (HRM) image based on distributed compressed sensing (DCS). In the proposed method, HRP image is firstly used to obtain approximation and detail dictionary. Then, joint-sparsity-model-1 (JSM-1) is applied directly to both LRM bands and HRM bands. Each band in LRM image is decomposed into common component and innovation component which can be sparsely represented over the approximation dictionary. Based on Orthogonal Matching Pursuit (OMP) algorithm, the sparse coefficients are calculated from JSM-1 of the LRM image. Lastly, each band in HRM image is modeled as the fusion of the corresponding LRM band and detail band over the detail dictionary. Two datasets are used in the experiments to validate the proposed method and the results show that the proposed method has better performance than the traditional methods.","2381-8549","978-1-4799-7061-2","10.1109/ICIP.2018.8451648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451648","Distributed compressed sensing;high-resolution panchromatic image;joint sparsity model;low-resolution multispectral image;satellite image fusion","Dictionaries;Compressed sensing;Sensors;Spatial resolution;Satellites;Matching pursuit algorithms","compressed sensing;geophysical image processing;image fusion;image resolution;iterative methods;remote sensing;sparse matrices","new satellite image fusion method;distributed compressed sensing;low-resolution multispectral image;high-resolution multispectral image;HRP image;joint-sparsity-model-1;LRM bands;HRM bands;LRM image;innovation component;approximation dictionary;JSM-1;HRM image;orthogonal matching pursuit algorithm;high-resolution panchromatic image;sparse coefficients","","1","","20","IEEE","6 Sep 2018","","","IEEE","IEEE Conferences"
"Pixel based satellite image fusion using dual-tree complex and Curvelet transform","P. M. Chaudhari; S. P. Mahajan","Department of Electronics and Telecommunication, College of Engineering, Pune, Maharashtra, India; Department of Electronics and Telecommunication, College of Engineering, Pune, Maharashtra, India","2017 International Conference on Recent Innovations in Signal processing and Embedded Systems (RISE)","11 Jun 2018","2017","","","264","268","Multisensory Image fusion is the operation of combining complementary information from two or more source images into a single fused image. The fused image will supply supplementary information from source images and reduce the redundancy. Satellite image fusion is the process of fusion between high spectral but low resolution multispectral and low-spectral but high-resolution panchromatic images. Traditional fusion methods can't give the image with high spectral and spatial resolution. Fusion using DWT achieve an image with high spectral information but failed to provide spatial information and it has less sharpness in fused image. But using Curvelet transform we get a fused image with high spatial and spectral information with more sharpness.","","978-1-5090-4760-4","10.1109/RISE.2017.8378164","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8378164","component;formatting;style;styling;insert (key words)","Image fusion;Discrete wavelet transforms;Image resolution;Distortion;Image edge detection","curvelet transforms;duality (mathematics);geophysical image processing;image fusion;image resolution;trees (mathematics)","pixel based satellite image fusion;dual-tree complex;Multisensory Image fusion;single fused image;high-resolution panchromatic images;high spectral resolution;spatial resolution;high spatial information;Curvelet transform","","","","9","IEEE","11 Jun 2018","","","IEEE","IEEE Conferences"
"Comparison and Analysis of Image Fusion Algorithms for GF-2 Satellite","W. -Z. Zhou; J. -Z. Li","The School of Information Science& Engineering, Hebei University of Science and Technology, China; The School of Information Science& Engineering, Hebei University of Science and Technology, China","2018 10th International Conference on Modelling, Identification and Control (ICMIC)","11 Nov 2018","2018","","","1","6","Image fusion is an indispensable step in the technology of satellite image processing. After orthorectification and registration can image fusion, the image fusion can effectively increase the utilization rate of the image and improve the discrimination of objects in the image. Firstly, this article introduces the background and significance of image fusion technology nowadays, and then introduced the related algorithms of image fusion in detail. Finally, the algorithm is implemented through experiments. The experiment adopts “GF-2” satellite to acquire the image data. The Xiongan New Area divided by Hebei Province was chosen as the experimental area. Comparing and analyzing the Baiyangdian Wharf in Anxin County, which is rich in features, high contrast, and low cloudiness. Several fusion algorithms were compared and analyzed by visual observation and quantitative analysis. The experimental results in this paper can be used to provide a reference for the fusion and application of “GF-2” satellite image data.","","978-1-5386-5416-3","10.1109/ICMIC.2018.8529899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8529899","Image fusion;Compared;Satellite imagery","Image fusion;Satellites;Interpolation;Spatial resolution;Principal component analysis;Wavelet analysis","geophysical image processing;image fusion;image processing;remote sensing","satellite image data;image fusion technology;satellite image processing;GF-2 satellite;image fusion algorithms","","","","18","IEEE","11 Nov 2018","","","IEEE","IEEE Conferences"
"Research of Image Fusion Method about ZY-3 Panchromatic Image and Multispectral Image","C. Qiu; J. Wei; Q. Dong","College of Geomatics, Xi’an University of Science and Technology, Xi’an, China; College of Geomatics, Xi’an University of Science and Technology, Xi’an, China; Shaanxi Institute of Surveying and Mapping of Land, Xi’an, China","2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA)","3 Jan 2019","2018","","","1","5","At present, there are few researches on the fusion method of ZY-3 satellite. The paper takes the ZY-3 image of Xi'an as an example, the image fusion experiments were mainly performed using the Brovey transform and Gram-schmidt transform method. Then qualitative analysis from the following three aspects: sharpness, texture features, and hue. Quantitative evaluation from four aspects including standard deviation, information entropy, mean value and correlation coefficient. Combined with the results of qualitative and quantitative analysis above, it shows that Gram-schmidt transform is the most suitable fusion method for panchromatic image and multispectral image of ZY-3 satellite in the existing fusion method.","","978-1-5386-6642-5","10.1109/EORSA.2018.8598582","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598582","Remote Sensing Image Fusion;ZY-3 satellite image;Brovey transform;Gram-schmidt transform;Accuracy evaluation","Transforms;Remote sensing;Image fusion;Image resolution;Histograms;Satellites;Standards","geophysical image processing;image fusion;image texture;land cover;remote sensing","image fusion method;ZY-3 Panchromatic Image;multispectral image;ZY-3 satellite;image fusion experiments;correlation coefficient;Brovey transform;Gram-schmidt transform;texture features;hue;information entropy;Xi'an","","","","10","IEEE","3 Jan 2019","","","IEEE","IEEE Conferences"
"High-reflectivity objects distributed optical satellite image fusion based on NDVI classification","Z. Zexing; X. Qizhi; W. Haibo; Y. Wenyong","Beijing Key Laboratory of Digital Media, Beihang University, Beijing, China; Beijing Key Laboratory of Digital Media, Beihang University, Beijing, China; China Centre for Resources satellite Data and Application, Beijing, China; China Centre for Resources satellite Data and Application, Beijing, China","2017 2nd International Conference on Frontiers of Sensors Technologies (ICFST)","18 Dec 2017","2017","","","231","235","Ratioing method is one type of the most famous fusion methods in remote sensing image fusion domain. Generally, the ratioing method synthesizes a low-resolution panchromatic (Pan) image by adaptive weighted summation of a multispectral (MS) image. Consequently, the accuracy of the weights for low-resolution Pan image synthesis is of great importance. However, in most cases, the optical satellite images contain lots of high-reflectivity objects, such as clouds covered regions, and high-reflectivity buildings. These objects are saturate due to their strong reflectance. The distortion of saturated objects results in the failure of weights calculation, so that causes the color distortion of fused images. To solve the problem, this paper proposes a high-reflectivity objects distributed optical satellite image fusion method based on NDVI classification. First, the NDVI index is employed to classify the pixels of a MS image into high-reflectivity group and normal group, then the pixels in normal group is used to calculate the weighted coefficients, finally the fused image is obtained by ratioing transform. Experimental results on a large number of test images show that the proposed method has good performance on reducing color distortion.","","978-1-5090-4860-1","10.1109/ICFST.2017.8210509","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8210509","Image fusion;Pan-sharpening;Remote sensing image;NDVI index","Remote sensing;Optical distortion;Optical sensors;Image color analysis;Image resolution;Optical imaging;Distortion","geophysical image processing;image classification;image colour analysis;image fusion;image resolution;sensor fusion;vegetation;vegetation mapping","high-reflectivity objects;NDVI classification;ratioing method;famous fusion methods;remote sensing image fusion domain;low-resolution panchromatic image;adaptive weighted summation;multispectral image;low-resolution Pan image synthesis;optical satellite images;high-reflectivity buildings;strong reflectance;saturated objects results;weights calculation;color distortion;fused image;optical satellite image fusion method;MS image;high-reflectivity group;test images;ratioing transform;NDVI index","","","","20","IEEE","18 Dec 2017","","","IEEE","IEEE Conferences"
"Satellite Image Fusion for Obtaining High Resolution Images Using Deep Neural Network","A. N. Rahman; V. Tripathiy; A. D. Gupta; B. Paul; M. T. Kurian; V. P. Vijayan","Innovation and Research Society, Mavelipuram, Kerala, India; Department of Computer Science and Engineering, Graphic Era Deemed to be University, Dehradun, Uttarakhand, India; Department of Geography, Chandernagore Government College, Hugli, West Bengal, India; Department of Information Technology, Rajagiri School of Engineering and Technology, Cochin, Kerala, India; Department of Electronics and Communication Engineering, Baselios Mathews II College of Engineering, Sasthamkotta, Kerala, India; Mangalam College of Engineering, Kottayam, Kerala, India","2022 International Conference on Intelligent Innovations in Engineering and Technology (ICIIET)","5 Dec 2022","2022","","","301","306","Due to its critical function in a wide range of applications, scene categorization of high-resolution remote sensing (RS) photos has drawn increasing attention. A technique for spatiotemporal fusion using deep neural networks (DNNs) with a large amount of remote sensing data as the application background. An innovative multispectral image fusion architecture is proposed in this paper. The proposed method for fusing satellite images entails two phases, each using two neural networks. In the first stage, an adaptively weighted injection-based joints detailed approach to remotely sensed image fusion is discussed. Multispectral (MS) and panchromatic (PAN) images are used to extract spatial features using a wavelet transform. In contrast to the conventional detail injection technique, dictionary learning from the sub-images themselves is used to construct the primary joint details by sparsely representing the extracted features. To minimize spectrum distortions in the fused images while keeping spatial information, we implemented a unique loss function for this DNN. This network is known as the ’Spectral Reimbursement Network (SRN).’ Finally, using three datasets, full-reference, and limited-reference criterion, the proposed strategy is compared against several state-of-the-art methods. Experiment findings demonstrate that the suggested technique can compete in both spatial and spectral parameters.","","978-1-6654-5653-1","10.1109/ICIIET55458.2022.9967537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9967537","Spectral reimbursement network;fused MS image;Deep neural network;Satellite image","Deep learning;Wavelet transforms;Technological innovation;Satellites;Neural networks;Feature extraction;Spatiotemporal phenomena","deep learning (artificial intelligence);feature extraction;geophysical image processing;image classification;image fusion;image representation;image resolution;remote sensing;wavelet transforms","adaptively weighted injection-based joints detailed approach;critical function;deep neural Network;deep neural networks;high resolution images;high-resolution remote sensing photos;loss function;multispectral image fusion architecture;panchromatic images;primary joint details;remote sensing data;satellite image fusion;satellite images;scene categorization;spatial parameter;spatial features;spatiotemporal fusion;spectral parameter;spectral reimbursement network;spectrum distortions","","","","11","IEEE","5 Dec 2022","","","IEEE","IEEE Conferences"
"Multisensor Satellite Image Fusion and Networking for All-Weather Environmental Monitoring","N. -B. Chang; K. Bai; S. Imen; C. -F. Chen; W. Gao","University of Central Florida, Orlando, FL, US; East China Normal University, Shanghai, CN; University of Central Florida, Orlando, FL, US; National Central University, Chung-Li, TW; Colorado State University, Fort Collins, CO, US","IEEE Systems Journal","2 May 2018","2018","12","2","1341","1357","Given the advancements of remote sensing technology, large volumes of remotely sensed images with different spatial, temporal, and spectral resolutions are available. To better monitor and understand the changing Earth's environment, fusion of remotely sensed images with different spatial, temporal, and spectral resolutions is critical for distinctive feature retrieval, interpretation, mapping, and decision analysis. A suite of methods have been developed to fuse multisensor satellite images for different purposes in the past few decades. This paper provides a thorough review of contemporary and classic image fusion methods and presents a summary of their phenomenological applications, with challenges and perspectives, for environmental systems analysis. Cross-mission satellite image fusion, networking, and missing value pixel reconstruction for environmental monitoring are described, and their complex integration is illustrated with a case study of Lake Nicaragua that elucidates the state-of-the-art remote sensing technologies for advancing water quality management.","1937-9234","","10.1109/JSYST.2016.2565900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7485881","Earth observation;environmental systems engineering;feature extraction;image fusion;remote sensing;satellite networking","Image fusion;Feature extraction;Remote sensing;Satellites;Spatial resolution;Data integration;Instruments","environmental monitoring (geophysics);geophysical image processing;image fusion;image resolution;lakes;remote sensing;water quality","environmental monitoring;remote sensing technology;multisensor satellite image fusion;all-weather environmental;remotely sensed images;spectral resolutions;distinctive feature retrieval;classic image fusion methods;environmental systems analysis;cross-mission satellite image fusion;spatial;Earth's environment;Lake Nicaragua;water quality management","","28","","136","IEEE","6 Jun 2016","","","IEEE","IEEE Journals"
"High PSNR based Image Fusion by Weighted Average Brovery Transform Method","N. Taxak; S. Singhal","RCEW Jaipur, Rajasthan, India; RCEW Jaipur, Rajasthan, India","2019 Devices for Integrated Circuit (DevIC)","1 Aug 2019","2019","","","451","455","Image Fusion is a method, in which two relevant Image get combine and generate a new Image. The generated image has excellent clarity as compared to the previous input image. Image Fusion Technique is improving the performance of the images and increase the application of Image Fusion. In the Base paper, they present Image Fusion for Two-Dimensional Multiresolution 2-D image. The applications of the Image fusion is using various fields like multi - Focus Images, CT, Multi-Sensor Satellite image and MR of the Human Brain. In this Paper, working for improve PSNR(Peak Signal to Noise Ratio) and Reduce to MSE (Mean Square Error). For improve the performance of Image fusion using Weighted Average Brovery Transform. In the base paper, PSNR and MSE are comparing by use PCA, DWT, DWT-PCA, DCT-PCA, DWT-DCT-PCA methods. Proposed Weighted Average Brovery Transform method is showing better results as compare to base paper results.","","978-1-5386-6722-4","10.1109/DEVIC.2019.8783400","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8783400","Image Fusion;Wavelet Transform;Fused Images;Wavelet based Fusion;Multi-Resolution;Multi-sensor image fusion;multi-resolution SVD;Image Fusion Performance Evaluation Metrics","Image fusion;Discrete wavelet transforms;Principal component analysis;Computed tomography","discrete wavelet transforms;image fusion;image resolution;mean square error methods","mean square error;MSE;peak signal to noise ratio;two-dimensional multiresolution 2-D image;weighted average Brovery transform method;high PSNR based image fusion","","3","","12","IEEE","1 Aug 2019","","","IEEE","IEEE Conferences"
"Fusenet: End- to-End Multispectral Vhr Image Fusion and Classification","J. R. Bergado; C. Persello; A. Stein","Dept. of Earth Observation Science, University of Twente, Enschede, The Netherlands; Dept. of Earth Observation Science, University of Twente, Enschede, The Netherlands; Dept. of Earth Observation Science, University of Twente, Enschede, The Netherlands","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","2091","2094","Classification of very high resolution (VHR) satellite images faces two major challenges: 1) inherent low intra-class and high inter-class spectral similarities and 2) mismatching resolution of available bands. Conventional methods have addressed these challenges by adopting separate stages of image fusion and spatial feature extraction steps. These steps, however, are not jointly optimizing the classification task at hand. We propose a single-stage framework embedding these processing stages in a multiresolution convolutional network. The network, called FuseNet, aims to match the resolution of the panchromatic and multispectral bands in a VHR image using convolutional layers with corresponding downsampling and upsampling operations. We compared FuseNet against the use of separate processing steps for image fusion, such as pansharpening and resampling through interpolation. We also analyzed the sensitivity of the classification performance of FuseNet to a selected number of its hyperparameters. Results show that FuseNet surpasses conventional methods.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8519214","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8519214","Convolutional networks;image fusion;land cover classification;VHR image;deep learning","Satellites;Spatial resolution;Feature extraction;Tiles;Image fusion","feature extraction;image classification;image fusion;image matching;image resolution;image sampling","high interclass spectral similarities;end-to-end multispectral VHR image fusion;end-to-end multispectral VHR image classification;very high resolution satellite image classification;inherent low intraclass spectral similarities;image mismatching;FuseNet network;image downsampling operation;image upsampling operation;pansharpening;interpolation;high resolution satellite images;convolutional layers;multispectral bands;panchromatic bands;multiresolution convolutional network;single-stage framework;spatial feature extraction steps","","6","","9","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"Improvement of Classification Accuracy Using Image Fusion Techniques","R. Singh; R. Gupta","Department of Civil Engineering, Birla Institute of Technology & Sciences, Pilani, Rajasthan, India; Department of Civil Engineering, Birla Institute of Technology & Sciences, Pilani, Rajasthan, India","2016 International Conference on Computational Intelligence and Applications (ICCIA)","20 Oct 2016","2016","","","36","40","Remote sensing techniques have been widely used for identification of land use and land cover features. Land information can be easily collected by classification of satellite images in the context of their use. In this paper study area has been classified into three classes i.e. settlement, trees and agricultural by classification of an image which has been enhanced using fusion of two images. The spatial and spectral resolutions of different satellite images provide better information with the aid of initial processing of image and fusion of both images. The satellite images fused together are multispectral IRS-P6 also called Resourcesat-1 satellite, on board LISS-III sensor provide image with spatial resolution of 23.5 m and an IRS-P5 also called Cartosat-1 satellite provides single band panchromatic image with spatial resolution of 2.5 m. Erdas Imagine 9.1 software has been used for image processing, fusion and supervised classification of the images. The Brovery, Multiplicative and Principal Component Analysis (PCA) method have been used for image fusion. The resultant images have been classified using the supervised classification with maximum likelihood parametric rule for information extraction and comparison between them in terms of their accuracy.","","978-1-5090-4174-9","10.1109/ICCIA.2016.21","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7600311","Image fusion techniques;image classification;accuracy assessment","Image fusion;Spatial resolution;Satellites;Principal component analysis;Remote sensing;Image classification","geophysical image processing;image classification;image enhancement;image fusion;land cover;land use;maximum likelihood estimation;principal component analysis;remote sensing","classification accuracy;image fusion techniques;remote sensing techniques;land use identification;land cover features;land information collection;satellite image classification;settlement class;trees;agricultural class;image enhancement;spatial resolutions;spectral resolutions;satellite images;multispectral IRS-P6;Resourcesat-1 satellite;LISS-III sensor;IRS-P5;Cartosat-1 satellite;single band panchromatic image;Erdas Imagine 9.1 software;image processing;image supervised classification;Brovery method;multiplicative method;principal component analysis;PCA method;maximum likelihood parametric rule;information extraction","","7","","14","IEEE","20 Oct 2016","","","IEEE","IEEE Conferences"
"Similarity Weight Learning: A New Spatial and Temporal Satellite Image Fusion Framework","H. Sun; W. Xiao","School of Geosciences and Surveying Engineering, China University of Mining and Technology, Beijing, China; School of Public Affairs, Zhejiang University, Hangzhou, China","IEEE Transactions on Geoscience and Remote Sensing","14 Apr 2022","2022","60","","1","17","Spatiotemporal fusion is a topical framework for solving the mutual restricted problem between the spatial and temporal resolution of satellite images. We pioneer an approach to replace similarity measurement steps in spatiotemporal fusion algorithms with convolutional neural networks (CNNs), building a bridge between weight function-based models and the learning-based models. Specifically, we propose a nonlocal form that separates the relational computation part from the value representation part, and construct the CNN-based similarity weight learning block for learning normalized weights. The block can be inserted into spatial and temporal adaptive reflectance fusion model (STARFM) to replace the manually designed weight calculation rules common in weight function-based methods, or into the CNN model StfNet to better utilize neighboring high-resolution images. The trained model outputs a high-resolution prediction from each base date image pair. The final result is a combination of the two predictions. In this regard, we propose the standard deviation-based weights to combine two prediction results. Four experiments are performed on Landsat–Moderate-resolution Imaging Spectroradiometer (MODIS) image pairs to determine the following: 1) the performance of the model at the target training date; 2) the generalization of the model in the target training time period; and 3) the generalization of the model at different dates and different geographical locations, each considering the different cases of giving one and two pairs of known images. Experimental results demonstrate the superiority of the similarity weight learning block and standard deviation-based weights. Among them, STARFM with the similarity weight learning block exhibits strong generalization, which testifies to the practical value of our model.","1558-0644","","10.1109/TGRS.2022.3161070","National Natural Science Foundation of China(grant numbers:42071250); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9739013","Attention;generalization capability;nonlocal module;satellite image fusion;similarity measure;spatiotemporal fusion","Spatial resolution;Image resolution;Spatiotemporal phenomena;Reflectivity;Biological system modeling;Remote sensing;Data models","geophysical image processing;image fusion;image resolution;learning (artificial intelligence);neural nets;remote sensing;sensor fusion","similarity weight learning;new spatial satellite image fusion framework;temporal satellite image fusion framework;topical framework;mutual restricted problem;spatial resolution;temporal resolution;satellite images;similarity measurement steps;spatiotemporal fusion algorithms;convolutional neural networks;weight function-based models;learning-based models;relational computation part;value representation part;CNN-based similarity weight;normalized weights;temporal adaptive reflectance fusion model;manually designed weight calculation rules;weight function-based methods;CNN model StfNet;high-resolution images;trained model;high-resolution prediction;base date image pair;standard deviation-based weights;Landsat-Moderate-resolution Imaging Spectroradiometer image pairs;target training date;target training time period;known images","","","","48","IEEE","21 Mar 2022","","","IEEE","IEEE Journals"
"Improving Satellite Image Fusion via Generative Adversarial Training","X. Luo; X. Tong; Z. Hu","College of Life Sciences and Oceanography, Shenzhen University, Shenzhen, China; College of Surveying and Geo-informatics, Tongji University, Shanghai, China; MNR Key Laboratory for Geo-Environmental Monitoring of Great Bay Area & Guangdong Key Laboratory of Urban Informatics & Shenzhen Key Laboratory of Spatial Smart Sensing and Services, Shenzhen University, Shenzhen, China","IEEE Transactions on Geoscience and Remote Sensing","21 Jul 2021","2021","59","8","6969","6982","The optical images acquired from satellite platforms are commonly multiresolution images, and converting multiresolution satellite images into full higher-resolution (HR) images has been a critical technique for improving the image quality. In this study, we introduced the generative adversarial network (GAN) and proposed a new fusion GAN (FusGAN) approach for solving the remote sensing image fusion problem. Specifically, we developed a new adversarial training strategy: 1) downscaled multiresolution images are adopted for generative network (G-Net) training, and 2) the discriminative network (D-Net) is used to adversarially train the G-Net by discriminating whether the original multiresolution images have been fused well enough. To further improve the capability of the network, we structured our G-Net with residual dense blocks by combining state-of-the-art residual and dense connection ideas. Our proposed FusGAN approach is evaluated both visually and quantitatively on Sentinel-2 and Landsat Operational Land Imager (OLI) multiresolution images. As demonstrated by the results, the proposed FusGAN approach outperforms the selected benchmark methods and both perfectly preserves spectral information and reconstructs spatial information in image fusion. Considering the common resolution disparities among intra- and intersatellite images, the proposed FusGAN approach can contribute to the quality improvement of satellite images and thus improve remote sensing applications.","1558-0644","","10.1109/TGRS.2020.3025821","National Natural Science Foundation of China(grant numbers:41631178); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9212572","Deep learning;generative adversarial networks (GANs);Landsat 8;remote sensing image fusion;residual dense blocks;Sentinel-2","Image fusion;Satellites;Training;Spatial resolution;Remote sensing","geophysical image processing;image fusion;image resolution;optical images;remote sensing","satellite image fusion;generative adversarial training;optical images;satellite platforms;multiresolution satellite images;higher-resolution images;image quality;generative adversarial network;fusion GAN approach;remote sensing image fusion problem;adversarial training strategy;generative network;G-Net;discriminative network;original multiresolution images;residual dense blocks;FusGAN approach;Landsat Operational Land Imager multiresolution images;common resolution disparities;intersatellite images;quality improvement","","7","","74","IEEE","5 Oct 2020","","","IEEE","IEEE Journals"
"A Two-step Spatio-Temporal satellite image Fusion Model for temporal changes of various LULC under one-pair prior images scenario","Yongquan Zhao; B. Huang","Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong, China; Department of Geography and Resource Management, The Chinese University of Hong Kong, Hong Kong, China","2016 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","24 Nov 2016","2016","","","1","5","This paper proposes a two-step spatio-temporal fusion model (TSTFM) for generating synthetic satellite remote sensing images with high-spatial and high-temporal resolution (HSaHTeR) based on one pair of prior images, which contain one low-spatial but high-temporal resolution (LSaHTeR) image and one high-spatial but low-temporal resolution (HSaLTeR) image. Considering both phenology and type surface temporal changes, the two steps in TSTFM are adopted to handle these two kinds of changes respectively, which are based on weighted mean and example-based image super-resolution approaches accordingly. In addition, a relative radiometric normalization process is conducted before performing the two-step spatio-temporal fusion (STF) process, which aims to calibrate radiometric differences of different kinds of satellite sensors. The proposed method was tested on two sets of test data: surface with mainly LULC phenology changes and surface with primarily LULC type changes. Experimental results show that TSTFM can capture both phenology and type changes efficiently and precisely even with one-pair prior images, and it can also maintain its robustness when facing extremely complex LULC.","","978-1-5090-2708-8","10.1109/ICSPCC.2016.7753699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7753699","Spatio-temporal fusion;weighted mean;image super-resolution;phenology change;type change;various LULC","MODIS;Satellites;Remote sensing;Earth;Spatial resolution;Satellite broadcasting","geophysical image processing;image fusion;image resolution;land use;radiometry;remote sensing","two-step spatio-temporal satellite image fusion model;LULC;one-pair prior images scenario;synthetic satellite remote sensing images;high-spatial and high-temporal resolution image;low-spatial but high-temporal resolution image;high-spatial but low-temporal resolution image;type surface temporal changes;phenology changes;TSTFM;weighted mean;example-based image super-resolution;relative radiometric normalization process;STF process;HSaHTeR image;LSaHTeR image;HSaLTeR image","","","","9","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"Satellite Image Fusion Using an Iterative Ihs-Based Approach","M. Ghadjati; A. Benazza-Benyahia; A. Moussaoui","Laboratoire de Génie Electrique de Guelma (LGEG), Université 8 mai 45 de Guelma, BP 401 Guelma, ALGERIA; LR11TIC01, COSIM Lab, Cité Technologique des Communications, University of Carthage SUP’COM, Rte de Raoued Km 3,5, Ariana, TUNISIA; Laboratoire de Génie Electrique de Guelma (LGEG), Université 8 mai 45 de Guelma, BP 401 Guelma, ALGERIA","2020 Mediterranean and Middle-East Geoscience and Remote Sensing Symposium (M2GARSS)","2 Jun 2020","2020","","","133","136","Intensity-Hue-Saturation (IHS) method is a pansharpening method belonging to the spectral class methods. In this class of methods, the multispectral image undergoes a spectral transformation and then one of the resulting components is totally replaced by the panchromatic image, hence leading to a significant color distortion. To alleviate this shortcoming, in the literature, the wavelet transform is often integrated to the spectral methods in order to transfer only the spatial details of the panchromatic image. Furthermore, the spatial information quantity transferred during the fusion is usually defined by the resolution ratio between the multispectral and panchromatic images. However, this is not necessarily the optimal way to generate the best fused image. In this paper, we propose an iterative IHS-based method (called IIHS), to continuously transfer the spatial information from the panchromatic image to the multispectral image while controling the perceptual quality of the fused image. Experiments on remote sensing images show that the proposed method presents the best visual and objective performances comparatively to the state-of-art IHS methods.","","978-1-7281-2190-1","10.1109/M2GARSS47143.2020.9105197","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9105197","Pansharpening;IHS method;iterative IHS;spatial information;quality with no reference index","Wavelet transforms;Visualization;Satellites;Image color analysis;Pansharpening;Distortion;Iterative methods","geophysical image processing;hyperspectral imaging;image colour analysis;image fusion;image resolution;iterative methods;remote sensing;wavelet transforms","IIHS;remote sensing images;panchromatic images;color distortion;panchromatic image;spectral transformation;multispectral image;spectral class methods;pansharpening method;Intensity-Hue-Saturation method;iterative IHS-based approach;satellite image fusion","","","","8","IEEE","2 Jun 2020","","","IEEE","IEEE Conferences"
"Assessment of WorldView-2 satellite-image fusion using Daubechies Wavelet transform","R. J. Medina Daza; E. S. U. Cardona","Proyecto Curricular Ingeniería Catastral y Geodesia, Facultad de ingeniería, Universidad Distrital Francisco Jose de Caldas, Bogota, CO; Proyecto Curricular Ingeniería Catastral y Geodesia, Facultad de ingeniería, Universidad Distrital Francisco Jose de Caldas, Bogota, CO","2015 10th Iberian Conference on Information Systems and Technologies (CISTI)","30 Jul 2015","2015","","","1","6","This paper aims to show an outline of transform Wavelet Daubechies, the main characteristics of them and subsequently exposed methodological form that was used in the development of experimental procedures were performed to apply RGB-HIS method together with ARSIS technique to fused WorldView-2 images, finally presents the results obtained with the application of this method using five filters associated to Wavelet Daubechies (db2, bd3, db4, db5 y db8) on five levels of decomposition.","2166-0727","978-9-8998-4345-5","10.1109/CISTI.2015.7170564","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7170564","Wavelet Daubechies;Fusion;satellite images;panchromatic;multispectral","Image resolution;Discrete wavelet transforms;Image color analysis;Continuous wavelet transforms;Biomedical imaging","image fusion;wavelet transforms","worldview-2 satellite-image fusion;Daubechies Wavelet transform;RGB-HIS method;ARSIS technique","","","","23","","30 Jul 2015","","","IEEE","IEEE Conferences"
"Improving Satellite-Aerial Image Matching Success Rate by Image Fusion","J. -I. Shin; T. Kim; W. -S. Yoon; H. -J. Park","Research Center of Geoinformatic Enineering, Inha University, Incheon, Republic of Korea; Department of Geoinformatic Engineering, Inha University, Incheon, Republic of Korea; Department of Geoinformatic Engineering, Inha University, Incheon, Republic of Korea; Department of Geoinformatic Engineering, Inha University, Incheon, Republic of Korea","2018 2nd European Conference on Electrical Engineering and Computer Science (EECS)","25 Nov 2019","2018","","","224","227","Image matching is an important method to collect ground control points (GCPs) by finding correspondence between incoming images and chips of reference image maps. It is an essential process for automated precise geo-registration of satellite imagery. To get higher georeferencing accuracy, reference chips must be matched precisely on the images. The importance of higher matching success rate is increased with limited number of chips. In this study, we aim to match incoming satellite images against reference chips generated from aerial color ortho-images. Matching the two dataset is difficult since they have different spectral responses as well as different textures. We try to improve matching success rate by using pansharpened satellite images. The results showed higher matching success rate with pansharpened images due to similar spectral range and higher spatial resolution. Therefore, pansharpened image is helpful to improve image matching success rate in automated precise georeferencing of high-resolution satellite imagery.","","978-1-7281-1929-8","10.1109/EECS.2018.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8910110","image matching;satellite image;pan-sharpening","Image matching;Satellites;Image color analysis;Color;Spatial resolution;Image fusion;Correlation","geographic information systems;geophysical image processing;image colour analysis;image fusion;image matching;image registration;image resolution;remote sensing","image fusion;ground control points;reference image maps;automated precise geo-registration;higher georeferencing accuracy;reference chips;incoming satellite images;aerial color ortho-images;pansharpened satellite images;automated precise georeferencing;high-resolution satellite imagery;satellite-aerial image matching success rate","","1","","8","IEEE","25 Nov 2019","","","IEEE","IEEE Conferences"
"2D Discrete Cosine Transform for Fusion of Multitemporal Satellite Images","A. Asokan; J. Anitha","ECE Department, Karunya Institute of Technology and Sciences, Coimbatore, India; ECE Department, Karunya Institute of Technology and Sciences, Coimbatore, India","2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS)","10 Mar 2019","2018","","","5","10","This paper analyses the quantitative performance metrics on applying image fusion method on satellite images and compares it with the fusion methods when applied to filtered images. The satellite images are obtained from over long distances and are immensely huge in size. During transmission, the satellite images get distorted by the presence of different noise components in the atmosphere. In this paper, satellite image fusion is done using Discrete Cosine Transform and compared with the image fusion after filtering operation on satellite images. The results are compared by calculating the Peak Signal-to-N oise Ratio, Mean Square Error and Entropy. From the results, it can be inferred that the image fusion on filtered images gives improved results in comparison to fusion on unfiltered images.","","978-1-5386-2842-3","10.1109/ICCONS.2018.8662832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8662832","Multitemporal;image fusion;Laplacian.change detection;Landsat","Satellites;Feature extraction;Image fusion;Thresholding (Imaging);Image quality;Wavelet transforms","artificial satellites;discrete cosine transforms;entropy;geophysical image processing;image filtering;image fusion;mean square error methods","mean square error calculation;entropy calculation;peak signal-to-noise ratio calculation;multitemporal satellite image fusion method;unfiltered imaging;2D discrete cosine transform;filtered imaging","","1","","12","IEEE","10 Mar 2019","","","IEEE","IEEE Conferences"
"SIRF: Simultaneous Satellite Image Registration and Fusion in a Unified Framework","C. Chen; Y. Li; W. Liu; J. Huang","Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA; IBM Thomas J. Watson Research Center, Yorktown Heights, NY, USA; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA","IEEE Transactions on Image Processing","11 Aug 2015","2015","24","11","4213","4224","In this paper, we propose a novel method for image fusion with a high-resolution panchromatic image and a low-resolution multispectral (Ms) image at the same geographical location. The fusion is formulated as a convex optimization problem which minimizes a linear combination of a least-squares fitting term and a dynamic gradient sparsity regularizer. The former is to preserve accurate spectral information of the Ms image, while the latter is to keep sharp edges of the high-resolution panchromatic image. We further propose to simultaneously register the two images during the fusing process, which is naturally achieved by virtue of the dynamic gradient sparsity property. An efficient algorithm is then devised to solve the optimization problem, accomplishing a linear computational complexity in the size of the output image in each iteration. We compare our method against six state-of-the-art image fusion methods on Ms image data sets from four satellites. Extensive experimental results demonstrate that the proposed method substantially outperforms the others in terms of both spatial and spectral qualities. We also show that our method can provide high-quality products from coarsely registered real-world IKONOS data sets. Finally, a MATLAB implementation is provided to facilitate future research.","1941-0042","","10.1109/TIP.2015.2456415","National Science Foundation(grant numbers:IIS-1423056,CMMI-1434401,CNS-1405985); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7156141","Image fusion;pan-sharpening;image registration;dynamic gradient sparsity;group sparsity;joint fusion;Image fusion;pan-sharpening;image registration;dynamic gradient sparsity;group sparsity;joint fusion","Image fusion;Distortion;Image registration;Remote sensing;Distortion measurement;Spatial resolution","geophysical image processing;image fusion;image registration;image resolution;iterative methods;least squares approximations;mathematics computing;optimisation;terrain mapping","simultaneous satellite image registration;SIRF;high-resolution panchromatic image;low-resolution multispectral image;geographical location;convex optimization problem;linear least-squares fitting combination;dynamic gradient sparsity regularizer;spectral information;Ms image;image edges;linear computational complexity;dynamic gradient sparsity property;image iteration;state-of-the-art image fusion methods;spectral qualities;spatial qualities;high-quality products;MATLAB implementation;coarsely registered real-world IKONOS data sets;future research","","100","","53","IEEE","14 Jul 2015","","","IEEE","IEEE Journals"
"Remote sensing image fusion using Hausdorff fractal dimension in shearlet domain","B. Biswas; A. Dey; K. N. Dey","Department of Computer Science and Engineering, University of Calcutta; Department of Computer Science and Engineering, University of Calcutta; Department of Computer Science and Engineering, University of Calcutta","2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","28 Sep 2015","2015","","","2180","2185","Preservation of spectral information and enhancement of spatial resolution is the most important issue in remote sensing image fusion. In this paper, a new remote sensing satellite image fusion method using shearlet transform (ST) with Hausdorff fractal dimension(HFD) estimation method is proposed. Firstly, ST is used in each high-spatial-resolution panchromatic (PAN) image and multi-spectral image (MS). Then, the low frequency sub-band coefficients from different images are combined according to the HFD method which estimates and selects the modified low-pass band automatically. The composition of different high-pass sub-band coefficients achieved by the ST decomposition is discussed in detail. Finally, we achieve fusion results from the inverse transformation of ST. Experimental results show that the proposed method outperforms many state-of-the-art techniques in both subjective and objective evaluation measures.","","978-1-4799-8792-4","10.1109/ICACCI.2015.7275939","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7275939","Remote sensing image fusion;Shearlet Transform;Hausdorff fractal dimension;mutual information","Image fusion;Remote sensing;Fractals;Image edge detection;Satellites;Discrete wavelet transforms","image colour analysis;image enhancement;image fusion;image resolution;inverse transforms;remote sensing","Hausdorff fractal dimension estimation method;shearlet domain;spectral information preservation;spatial resolution enhancement;remote sensing image fusion;HFD estimation method;remote sensing satellite image fusion method;high-spatial resolution panchromatic image;high-spatial resolution PAN image;multispectral image;MS image;modified low-pass band automatic selection;high-pass subband coefficients;ST decomposition","","","","20","IEEE","28 Sep 2015","","","IEEE","IEEE Conferences"
"Fusion of satellite images in transform domain","H. Venkatesh; K. Viswanath","Siddaganga Institute of Technology, Tumkur, Karnataka, IN; Telecommunication Engineering Department, Siddaganga Institute of Technology, Tumakuru, Karnataka","2016 International Conference on Communication and Signal Processing (ICCSP)","24 Nov 2016","2016","","","1884","1888","Image fusion taking into account the wavelet and fourier change grades rich multispectral points of importance yet provides fewer spatial subtle elements from basis images. Wavelet performs well at direct elements yet not at non-straight cutoffs since Wavelets don't utilize the geometric assets of assemblies. Curvelet overwhelmed such challenges in highlight representation. A novel Image fusion principle through high pass exploiting Local Magnitude Ratio (LMR) in (FDCT) Fast Discrete Curvelet Transforms area and Discrete wavelet transform (DWT) is characterized. Indian Remote Sensing Geo satellite pictures are utilized for MS and Pan pictures. This mixture guideline produces HR multispectral picture with high spatial determination resolution. This strategy is contrasted and wavelet, Principal Component Analysis (PCA), Fast Discrete Curvelet Transforms area combination techniques. The Proposed procedure results in multispectral information alongside spatial points of interest.","","978-1-5090-0396-9","10.1109/ICCSP.2016.7754497","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7754497","Image Fusion;Discrete wavelet transforms Fast Discrete Curvelet Transforms;Principal Component Analysis;Guided Filtering","Image fusion;Discrete wavelet transforms;Satellites;Remote sensing;Spatial resolution","artificial satellites;curvelet transforms;discrete wavelet transforms;geophysical image processing;image filtering;image fusion;principal component analysis;remote sensing","satellite image fusion;multispectral points;local magnitude ratio;FDCT;fast discrete curvelet transforms;discrete wavelet transform;Indian Remote Sensing Geo satellite pictures;Pan pictures;MS pictures;HR multispectral picture;high spatial determination resolution;principal component analysis;PCA;multispectral information;transform domain","","1","","14","IEEE","24 Nov 2016","","","IEEE","IEEE Conferences"
"A survey on fusion of multispectral and panchromatic images for high spatial and spectral information","S. Sonnad","Dept. of Electronics & Communication Engineering, APPA Institute of Engineering & Technology, Kalaburagi, Karnataka, India","2016 International Conference on Wireless Communications, Signal Processing and Networking (WiSPNET)","15 Sep 2016","2016","","","177","180","The purpose of satellite image fusion of multispectral and panchromatic images is a method to combine the desirable characteristic of high spatial panchromatic (PAN) image and low spatial multispectral (MS) image to obtain single multispectral image with high spatial resolution and high spectral resolution. This paper furnish a survey on various image fusion algorithms of MS and PAN images such as, Brovey transform, Intensity-Hue-Saturation (IHS) transform, Principal Component Analysis (PCA), Highpass Filtering, Wavelet transform, Integration of different transform methods with IHS, fusion method based on PCA and feature product of Wavelet transform, Fourier transform, General Intensity- Hue-Saturation (GIHS) transform, Optimal Filter design, modified Wavelet Averaging Merging method and modified Bi-cubic Interpolation method in non Subsampled Contourlet transform, improved IHS and PCA merges based on Wavelet decomposition, etc.","","978-1-4673-9338-6","10.1109/WiSPNET.2016.7566115","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7566115","Panchromatic;Wavelet;Multispectral;Fusion;PCA;IHS","Image fusion;Principal component analysis;Wavelet transforms;Spatial resolution;Indexes","Fourier transforms;image colour analysis;image filtering;image fusion;image resolution;interpolation;principal component analysis;wavelet transforms","multispectral image fusion;panchromatic image fusion;spectral information;satellite image fusion;high spatial panchromatic image;spatial multispectral image;high spectral resolution;high spatial resolution;PAN image;MS image;PCA;wavelet transform feature product;Fourier transform;general intensity-hue-saturation transform;GIHS transform;optimal filter design;wavelet averaging merging method;bicubic Interpolation method;nonsubsampled contourlet transform","","3","","18","IEEE","15 Sep 2016","","","IEEE","IEEE Conferences"
"Satellite image registration using hybrid salient region detection method","C. Shanthini; J. Anitha","Department of Electronics and Communication, Karunya University, Tamil Nadu, India; Karunya Institute of Technology and Sciences, Coimbatore, Tamil Nadu, IN","2016 International Conference on Circuit, Power and Computing Technologies (ICCPCT)","4 Aug 2016","2016","","","1","5","In remote sensing multisensor image fusion or registration is the process of combining relevant information from two or more images into a single image. The resulting image will be more informative than any of the input images. In order to transform the remote sensing images to retrieve more information, this paper proposes a hybrid method that consists of image segmentation, salient region detection and image fusion. First of all, the paper presents the superpixel segmentation method in order to divide the image into subareas and for the feature extraction we implemented the difference of Gaussian and local binary pattern from the salient regions. This proposed method is tested on remote sensing images. Software results shows that the method is fast and gives less error compared to other existing methods.","","978-1-5090-1277-0","10.1109/ICCPCT.2016.7530356","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530356","Image segmentation;Salient region detection;Local binary pattern;Remote sensing images","Image segmentation;Image registration;Remote sensing;Histograms;Feature extraction;Image edge detection;Computers","feature extraction;geophysical image processing;image fusion;image registration;image retrieval;image segmentation;object detection;remote sensing","satellite image registration;hybrid salient region detection method;remote sensing multisensor image fusion;information retrieval;superpixel segmentation method;feature extraction;difference of Gaussian;local binary pattern","","","","11","IEEE","4 Aug 2016","","","IEEE","IEEE Conferences"
"A Multi-Cooperative Deep Convolutional Neural Network for Spatiotemporal Satellite Image Fusion","W. Li; C. Yang; Y. Peng; X. Zhang","Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Oct 2021","2021","14","","10174","10188","Remote sensing satellite images with high temporal and high spatial resolution play a critical role in earth science applications. However, it is difficult for a single satellite to obtain such images due to technical and cost constraints. Therefore, spatiotemporal image fusion based on deep learning has received extensive attention in recent years. This article proposes a multicooperative deep convolutional neural network (MCDNet) for spatiotemporal satellite image fusion. This method is a new multinetwork model in which multiple networks work together to reconstruct the predicted image. The multinetwork model consists of a super-resolution network, a difference reconstruction network, and a collaborative training network. First, the super-resolution network uses the combination of a novel multiscale mechanism and dilated convolutions to make full use of the spectral information of the coarse image and upgrade it to a transitional image that matches the fine image. The difference reconstruction network uses structural relevance to complete the reconstruction of the fine difference image. The collaborative training network extracts the hidden information from the fine image and uses the time relevance to restrict the training of the difference reconstruction network. Finally, the fine difference image and the known fine image are combined to complete the image fusion. The new compound loss function can help multinetwork models better complete cooperative training. Through experiments on two datasets and comparison with existing fusion algorithms, the subjective and objective results prove that MCDNet can effectively reconstruct higher-quality prediction images.","2151-1535","","10.1109/JSTARS.2021.3113163","National Natural Science Foundation of China(grant numbers:61972060,U1713213,62027827); National Key R&D Program of China(grant numbers:2019YFE0110800); Natural Science Foundation of Chongqing(grant numbers:cstc2020jcyj-zdxmX0025,cstc2019cxcyljrc-td0270); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9540272","Convolutional neural network (CNN);dilated convolution;multiscale mechanism;spatiotemporal fusion","Image reconstruction;Convolutional neural networks;Spatiotemporal phenomena;Spatial resolution;Feature extraction;Satellites;Training","convolutional neural nets;deep learning (artificial intelligence);feature extraction;image fusion;image reconstruction;image resolution;remote sensing","multicooperative deep convolutional neural network;spatiotemporal satellite image fusion;remote sensing satellite images;temporal resolution;spatial resolution;deep learning;super-resolution network;difference reconstruction network","","4","","45","CCBY","16 Sep 2021","","","IEEE","IEEE Journals"
"Sallfus, library for satellite images fusion on homogeneous and heterogeneous computing architectures","M. -D. Rubén Javier; V. -P. Nelson Enrique; R. -R. Andrés Ovidio",Universidad Distrital Francisco Jose de Caldas; Universidad Distrital Francisco Jose de Caldas; Universidad Distrital Francisco Jose de Caldas,"IEEE Latin America Transactions","12 Apr 2021","2020","18","12","2130","2137","Fusion of satellite images consists of improving the quality of a multispectral image by combining data from a high spatial resolution panchromatic image with a high spectral resolution multispectral image. To carry out this, different techniques are available, which perform various operations at the pixel level, which leads to generating a dependency between the computational requirement and the image size. Currently, there are some libraries that implement these fusion methods, however, none of them allow this fusion process to be carried out on heterogeneous architectures, which enable the integration of acceleration platforms that reduce execution time through massive parallelization. For this reason, this document presents a library called Sallfus, which allows executing and evaluating the quality and performance of image fusion methods such as the Brovey transform, Multiplicative method, Principal Component Analysis (PCA) and Wavelet A trous, on homogeneous and heterogeneous architectures. Likewise, an evaluation of the library is made from an analysis of execution times and image quality using mathematical-statistical indices such as the correlation coefficient (CC), BIAS coefficient and Root of the Root Mean Square Error (RMSE). The results of the library evaluation showed that the merging process with images of 8192 pixels, presents a speed-up of approximately 591x for Brovey, 309x for Multiplicative, 18x for PCA and 6x for A trous. Additionally, it was observed that the methods that presented the best performance both computationally and in the quality of the merged image were Brovey and Wavelet A trous. Availability and implementation: https://github.com/Parall-UD/sallfus.","1548-0992","","10.1109/TLA.2020.9400441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9400441","Brovey transform;Heterogenous Computing;Multiplicative transform;Principal Component Analysis;Satellite-image fusion;Wavelet À trous","Principal component analysis;Wavelet transforms;Graphics processing units;Libraries;Satellites;Image fusion;Computer architecture","correlation methods;image enhancement;image fusion;image resolution;remote sensing","spectral resolution multispectral image;spatial resolution panchromatic image;heterogeneous computing architectures;homogeneous computing architectures;satellite images fusion;library evaluation;image quality","","","","","IEEE","12 Apr 2021","","","IEEE","IEEE Journals"
"Pansharpening Using Data Driven Model Based on Linear Regression","M. B. Devi; R. Devanathan","Electronics and Communication Engineering, Hindustan Institute of Technology and Science, Chennai, India; Electrical and Electronics Engineering, Hindustan Institute of Technology and Science, Chennai, India","2018 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)","8 Oct 2018","2018","","","1","6","With the launching of many earth's observation satellites, the amount of data capturing the Earth's surface has been increasing to a great extent. In this paper, we emphasize the need for analyzing the satellite image data particularly in the context of data fusion applied to data taken from sensors of different resolution. The problem lies in maintaining the spectral characteristics of the multispectral images when panchromatic image is used to estimate the high spatial multispectral image. We take a wholesome approach based on the reflectance data irrespective of the sensor physics. The approach aims to produce an enhanced spatial resolution multispectral image having the same resolution as that of the panchromatic data while still preserving the spectral characteristics of the multispectral image. Using a linear regression model between multispectral and panchromatic data, an optimal solution in terms of Lagrange multiplier is provided and validated to maximize the spectral consistency of the fused image. The chi-square test is used to check the “goodness of fitd” of the data. The experimental results are discussed and presented using IKONOS satellite data.","","978-1-5386-1112-8","10.1109/CONECCT.2018.8482388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8482388","data fusion;image fusion;spectral consistency;Lagrange multiplier","Spatial resolution;Satellites;Image fusion;Data integration;Linear regression;Sensors","geophysical image processing;image fusion;image resolution;regression analysis","data driven model;satellite image data;data fusion;spectral characteristics;panchromatic image;high spatial multispectral image;sensor physics;enhanced spatial resolution multispectral image;panchromatic data;linear regression model;fused image;IKONOS satellite data;reflectance data;multispectral data;chi-square test","","1","","18","IEEE","8 Oct 2018","","","IEEE","IEEE Conferences"
"Satellite image enhancement based on multi-technology fusion","L. M. Satapathy; A. Dalai; S. Satapathy; A. Jena","Department of Electrical and Electronics Engineering, Deemed to be University, Bhubaneswar, India; Department of Electrical and Electronics Engineering, Deemed to be University, Bhubaneswar, India; Department of Electrical and Electronics Engineering, Deemed to be University, Bhubaneswar, India; Department of Electrical and Electronics Engineering, Deemed to be University, Bhubaneswar, India","2018 Second International Conference on Inventive Communication and Computational Technologies (ICICCT)","27 Sep 2018","2018","","","1677","1680","In this paper, a novel contrast enhancement technique based on bi-dimensional empirical mode decomposition (BEMD) and principal component analysis (PCA) is proposed for low contrast satellite image. The proposed method first decomposes the image into various intrinsic mode functions (IMF). The edge information is obtained by applying a weighted method between the residue and the gradient of the original image. The resultant image is calculated by applying PCA based fusion to the original image and the reconstructed image. Experiments are conducted on various satellite images to compare and analyze the performance of the proposed algorithm. The effectiveness of the presented approach is quantified in terms of entropy ratio (ER), peak signal to noise ratio (PSNR), the absolute mean brightness error (AMBE), image quality index(IQI) and structural similarity index measure (SSIM).","","978-1-5386-1974-2","10.1109/ICICCT.2018.8473070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8473070","BEMD;enhancement;image fusion;morphological gradient;PCA","Histograms;Principal component analysis;Satellites;Entropy;Image edge detection;Brightness","entropy;image enhancement;image reconstruction;principal component analysis","reconstructed image;satellite images;structural similarity index measure;satellite image enhancement;multitechnology fusion;principal component analysis;low contrast satellite image;intrinsic mode functions;edge information;weighted method;PCA based fusion;contrast enhancement technique","","5","","10","IEEE","27 Sep 2018","","","IEEE","IEEE Conferences"
"Spatiotemporal Satellite Image Fusion Using Deep Convolutional Neural Networks","H. Song; Q. Liu; G. Wang; R. Hang; B. Huang","Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Collaborative Innovation Center on Forecast and Evaluation of Meteorological Disasters, Nanjing University of Information Science and Technology, Nanjing, China; Jiangsu Key Laboratory of Big Data Analysis Technology, Jiangsu Collaborative Innovation Center on Atmospheric Environment and Equipment Technology, Nanjing University of Information Science and Technology, Nanjing, China; Chinese University of Hong Kong, Hong Kong","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","12 Mar 2018","2018","11","3","821","829","We propose a novel spatiotemporal fusion method based on deep convolutional neural networks (CNNs) under the application background of massive remote sensing data. In the training stage, we build two five-layer CNNs to deal with the problems of complicated correspondence and large spatial resolution gaps between MODIS and Landsat images. Specifically, we first learn a nonlinear mapping CNN between MODIS and low-spatial-resolution (LSR) Landsat images and then learn a super-resolution CNN between LSR Landsat and original Landsat images. In the prediction stage, instead of directly taking the outputs of CNNs as the fusion result, we design a fusion model consisting of high-pass modulation and a weighting strategy to make full use of the information in prior images. Specifically, we first map the input MODIS images to transitional images via the learned nonlinear mapping CNN and further improve the transitional images to LSR Landsat images via the fusion model; then, via the learned SR CNN, the LSR Landsat images are supersolved to transitional images, which are further improved to Landsat images via the fusion model. Compared with the previous learning-based fusion methods, mainly referring to the sparse-representation-based methods, our CNNs-based spatiotemporal method has the following advantages: 1) automatically extracting effective image features; 2) learning an end-to-end mapping between MODIS and LSR Landsat images; and 3) generating more favorable fusion results. To examine the performance of the proposed fusion method, we conduct experiments on two representative Landsat-MODIS datasets by comparing with the sparse-representation-based spatiotemporal fusion model. The quantitative evaluations on all possible prediction dates and the comparison of fusion results on one key date in both visual effect and quantitative evaluations demonstrate that the proposed method can generate more accurate fusion results.","2151-1535","","10.1109/JSTARS.2018.2797894","National Natural Science Foundation of China(grant numbers:41501377,61532009,91546117); Foundation of Jiangsu Province of China(grant numbers:BK20150906,15KJA520001); National Social and Scientific Fund Program(grant numbers:16ZDA047); HKRGC General Research Fund(grant numbers:14606315); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8291042","Convolutional neural network (CNN);nonlinear mapping (NLM);spatial resolution;temporal resolution","Remote sensing;Earth;Artificial satellites;Spatial resolution;MODIS;Spatiotemporal phenomena;Training","feature extraction;feedforward neural nets;geophysical image processing;image fusion;image representation;image resolution;learning (artificial intelligence);remote sensing","Landsat-MODIS datasets;end-to-end mapping learning;automatic effective image feature extraction;MODIS images;massive remote sensing data;low-spatial-resolution Landsat images;accurate fusion results;spatiotemporal fusion model;representative Landsat-MODIS datasets;spatiotemporal method;sparse-representation-based methods;learned SR CNN;LSR Landsat images;learned nonlinear mapping CNN;transitional images;prior images;super-resolution CNN;spatial resolution gaps;spatiotemporal fusion method;deep convolutional neural networks;spatiotemporal satellite image fusion","","170","","35","IEEE","13 Feb 2018","","","IEEE","IEEE Journals"
"A Pseudo-Siamese Deep Convolutional Neural Network for Spatiotemporal Satellite Image Fusion","W. Li; C. Yang; Y. Peng; J. Du","Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China; Chongqing Key Laboratory of Image Cognition, Chongqing University of Posts and Telecommunications, Chongqing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","27 Jan 2022","2022","15","","1205","1220","Due to technology and cost limitations, it is challenging to obtain high temporal and spatial resolution images from a single satellite spectrometer, which significantly limits the specific application of such remote sensing images in earth science. To solve the problem that the existing algorithms cannot effectively balance the spatial detail preservation and spectral change reconstruction, a pseudo-Siamese deep convolutional neural network (PDCNN) for spatiotemporal fusion is proposed in this article. The method proposes a pseudo-Siamese network framework model for fusion. This framework has two independent and equal feature extraction streams, but the weights are not shared. The two feature extraction streams process the image information at the previous and later moments and reconstruct the fine image of the corresponding time to fully extract the image information at different times. In the feature extraction stream, the multiscale mechanism and dilated convolution of flexible perception are designed, which can flexibly obtain feature image information and improve the model reconstruction accuracy. In addition, an attention mechanism is introduced to improve the weight of the crucial information for the remote sensing images. Adding a residual connection enhances the reuse of the initial feature information in shallow networks and reduces the loss of feature information in deep networks. Finally, the fine images obtained from the two feature extraction streams are weighted and fused to obtain the final predicted image. The subjective and objective results demonstrate that the PDCNN can effectively reconstruct the fusion image with higher quality.","2151-1535","","10.1109/JSTARS.2022.3143464","National Natural Science Foundation of China(grant numbers:61972060,U1713213,61802148,62027827); National Key Research and Development Program of China(grant numbers:2019YFE0110800); Natural Science Foundation of Chongqing(grant numbers:cstc2020jcyj-zdxmX0025,cstc2019cxcyljrc-td0270); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9684706","Convolutional neural network (CNN);multiscale mechanism;pseudo-Siamese network;spatiotemporal fusion","Feature extraction;Streaming media;Remote sensing;Spatial resolution;Image reconstruction;Convolutional neural networks;Spatiotemporal phenomena","feature extraction;geophysical image processing;image classification;image fusion;image reconstruction;image representation;image resolution;learning (artificial intelligence);neural nets;remote sensing","fusion image;pseudoSiamese deep convolutional neural network;spatiotemporal satellite image fusion;cost limitations;high temporal resolution images;spatial resolution images;single satellite spectrometer;remote sensing images;spectral change reconstruction;spatiotemporal fusion;pseudoSiamese network framework model;independent feature extraction streams;equal feature extraction streams;feature extraction stream;fine image;feature image information;model reconstruction accuracy;initial feature information;shallow networks;deep networks;final predicted image","","3","","55","CCBY","18 Jan 2022","","","IEEE","IEEE Journals"
"Satellite image resolution enhancement using DTCWT and DTCWT based fusion","V. V. Naik; S. Gharge","Department of Electronics and Telecommunication, V.E. S. Institute of Technology, India; Department of Electronics and Telecommunication, V.E. S. Institute of Technology, India","2016 International Conference on Advances in Computing, Communications and Informatics (ICACCI)","3 Nov 2016","2016","","","1957","1962","To increase the resolution of any image, interpolation techniques are adopted. The high frequency components in the low resolution (LR) image are lost when the images are interpolated. To overcome this problem a new satellite image resolution enhancement algorithm based on Dual Tree Complex Wavelet transform (DTCWT) and its rotated version have been proposed. DTCWT and Rotated DTCWT give 32 subbands of an image, out of which 24 are high frequency (HF) subbands which give 12 different angular information and 8 are low frequency (LF) subbands. The HF subbands are interpolated by Lanczos Interpolation to preserve the high frequency contents of the image. Non Local Means (NLM) filtering is used to eliminate the artifacts which are generated by DTCWT and rotated DTCWT. To obtain the two enhanced high resolution images inverse transforms are performed over respective subbands. The final two high resolution (HR) images are fused together with DTCWT based fusion to give resolution enhanced HR image. To evaluate the performance of the proposed algorithm three performance parameters namely PSNR, SSIM and Q-Index are evaluated for a database of 60 grayscale images of resolution 256×256. The subjective and objective results are compared with the existing techniques to prove the superiority of the proposed algorithm.","","978-1-5090-2029-4","10.1109/ICACCI.2016.7732338","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7732338","Dual Tree Complex Wavelet Transform (DTCWT]!;Non Local Means (NLM) filtering;Resolution Enhancement (RE)","Image resolution;Interpolation;Satellites;Discrete wavelet transforms;Filtering","image colour analysis;image enhancement;image filtering;image fusion;image resolution;interpolation;wavelet transforms","satellite image resolution enhancement;DTCWT based fusion;low resolution image;dual tree complex wavelet transform;Lanczos interpolation;non local means filtering;NLM filtering;high resolution images;grayscale images","","3","","14","IEEE","3 Nov 2016","","","IEEE","IEEE Conferences"
"A Compressed-Sensing-Based Pan-Sharpening Method for Spectral Distortion Reduction","M. Ghahremani; H. Ghassemian","Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran; Faculty of Electrical and Computer Engineering, Tarbiat Modares University, Tehran, Iran","IEEE Transactions on Geoscience and Remote Sensing","10 Mar 2016","2016","54","4","2194","2206","Recently, the compressed sensing (CS) theory has become an interesting topic for pan-sharpening of multispectral images. The CS theory ensures that, under the sparsity regularization, an unknown sparse signal can be exactly recovered from a drastically smaller number of linear measurements. In this paper, we propose a CS-based approach for fusion of the multispectral and panchromatic satellite images. The contribution of this paper is twofold. First, with the spatial and spectral characteristics of the satellite images, we assume that each patch of the unknown high spatial resolution intensity (HRI) component can be represented as a linear combination of atoms in a dictionary trained only from the panchromatic image; thus, the problem of generating an optimal dictionary is solved. Second, we propose an iterative algorithm to obtain the sparsest coefficients. The sparsest coefficients ensure that the estimated HRI component can be correctly recovered from the panchromatic image. The IKONOS, QuickBird, and WorldView-2 data are used to evaluate the performance of the proposed method. The experimental results demonstrate that the proposed method generates high-quality pan-sharpened multispectral bands quantitatively and perceptually.","1558-0644","","10.1109/TGRS.2015.2497309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7335613","Compressed sensing (CS);image fusion;multispectral data;panchromatic data;pan-sharpening;sparse representation;Compressed sensing (CS);image fusion;multispectral data;panchromatic data;pan-sharpening;sparse representation","Spatial resolution;Distortion;Satellites;Transforms;Image coding","compressed sensing;geophysical image processing;geophysical techniques;image fusion;image resolution;iterative methods","high-quality pan-sharpened multispectral bands;QuickBird data;WorldView-2 data;IKONOS data;sparse coefficients;iterative algorithm;optimal dictionary;atom linear combination;unknown high spatial resolution intensity component;spatial characteristic;spectral characteristic;panchromatic satellite image fusion;multispectral satellite image fusion;linear measurements;unknown sparse signal;sparsity regularization;multispectral image pan-sharpening;spectral distortion reduction;compressed-sensing-based pan-sharpening method","","66","","52","IEEE","23 Nov 2015","","","IEEE","IEEE Journals"
"Application of Domestic Satellite Image Fast Ortho-Rectification Method in Dynamic Remote Sensing Monitoring of Sea Area","J. Chu; J. Zhao; N. Gao; D. Song; J. Fan; X. Wang","National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China; National Marine Environmental Monitoring Center, Dalian, China","2018 Ninth International Conference on Intelligent Control and Information Processing (ICICIP)","10 Jan 2019","2018","","","134","138","To cater for the need for dynamic remote sensing monitoring in the sea area and the characteristics of the domestic high-resolution satellite imagery in coastal areas, a set of effective and fast ortho-rectification methods based on PCI Geoimaging Accelerator (GXL) system are developed in this paper. The technical flow generated and parameters setting of key technological linkages are described in details. Upon the application in actual production and the analysis of production efficiency of GXL, the automatic and fast ortho-rectification method of domestic satellite imagery based on dynamic remote sensing monitoring in the sea area is further demonstrated to meet the business needs.","","978-1-5386-5860-4","10.1109/ICICIP.2018.8606723","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606723","Dynamic remote sensing monitoring of sea area;high-resolution satellite imagery;PCI GeoImaging accelerator;fast Ortho-Rectification","Satellites;Hafnium;Geomagnetism;Information technology;Remote sensing;Monitoring;Image fusion","image resolution;oceanographic techniques;remote sensing","dynamic remote sensing monitoring;sea area;domestic high-resolution satellite imagery;coastal areas;PCI Geoimaging Accelerator system;domestic satellite image fast ortho-rectification method;technical flow;technological linkages;GXL production efficiency","","","","8","IEEE","10 Jan 2019","","","IEEE","IEEE Conferences"
"Empirical analysis of SIFT, Gabor and fused feature classification using SVM for multispectral satellite image retrieval","C. Joshi; S. Mukherjee","AIM&ACT, Banasthali University, Rajasthan, India; AIM&ACT, Banasthali University, Rajasthan, India","2017 Fourth International Conference on Image Information Processing (ICIIP)","12 Mar 2018","2017","","","1","6","High Level image understanding and Content extraction is becoming a challenging task in Content based image retrieval system for satellite images. Retrieval based on the low level extraction techniques does not bridge the semantic gap. In the experiment high level feature extraction techniques i.e. scale invariant feature transform and Gabor descriptors are used. The novel approach is proposed in which both the feature descriptors are fused to retrieve the results with more accuracy rate. The experiment is conducted on the multispectral satellite images, of Landsat 8 sensor. The similarity of the query image to that of stored database images is matched by the Manhattan distance. The Precision and Recall is computed for the data set. The results have shown the improved retrieval rate. The retrieval efficiency is further increased by using the SVM classifier by classifying the satellite images based on Urban area, Water body and Vegetation. The experimental results shows that the fusion technique gives better result and more accuracy can be obtained by classifying the dataset using SVM.","","978-1-5090-6734-3","10.1109/ICIIP.2017.8313776","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8313776","SIFT;Gabor;CBIR;Landsat 8;Precision;Recall;SVM","Feature extraction;Support vector machines;Satellites;Information processing;Remote sensing;Vegetation mapping;Gabor filters","content-based retrieval;feature extraction;geophysical image processing;image classification;image fusion;image matching;image retrieval;support vector machines","empirical analysis;fused feature classification;multispectral satellite image retrieval;High Level image understanding;Content extraction;Content based image retrieval system;low level extraction techniques;semantic gap;scale invariant feature;Gabor descriptors;feature descriptors;multispectral satellite images;query image;stored database images;improved retrieval rate;retrieval efficiency;SVM classifier;fusion technique;experiment high level feature extraction techniques;Manhattan distance;Landsat 8 sensor;Precision;Recall","","3","","17","IEEE","12 Mar 2018","","","IEEE","IEEE Conferences"
"Multiple feature fusion using a multiset aggregated canonical correlation analysis for high spatial resolution satellite image scene classification","D. Lin; X. Xu; F. Pu","Signal Processing Laboratory, Wuhan University, Wuhan, China; Signal Processing Laboratory, Wuhan University, Wuhan, China; Wireless Communication and Sensor Network Laboratory, Wuhan University, Wuhan, China","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","481","484","This paper presents a novel classification method for high-spatial-resolution satellite scene classification introducing multiset aggregated canonical correlation analysis (MACCA)-based feature fusion to fuse and combine multiple features. Firstly, a superpixel representation of the scene is constructed by employing a high-efficiency linear iterative clustering algorithm. After that, three diverse and complementary visual descriptors are extracted to characterize each superpixel. For taking full advantage of multiset features to yield the effective discriminant information and eliminating the redundancy between multiset features to some extent, MACCA is performed on three different feature sets to acquire fused feature for classification. Experimental analysis on high-spatial-resolution satellite scenes reveals that the suggested method achieves exceedingly promising performance and surpasses other off-the-shelf methods in classification accuracy.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7325805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325805","Feature fusion;scene classification;canonical correlation analysis (CCA)","Correlation;Satellites;Feature extraction;Remote sensing;Spatial resolution;Accuracy;Image color analysis","image classification;image fusion;pattern clustering","high-spatial-resolution satellite image scene classification accuracy;multiset aggregated canonical correlation analysis-based feature fusion;superpixel representation;high-efficiency linear iterative clustering algorithm;visual descriptors;multiset features;off-the-shelf methods;multiple feature fusion","","","","12","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Optimal Image Fusion Algorithm using Modified Whale Optimization Algorithm Amalgamed with Local Search and BAT Algorithm","S. Dutta; A. Banerjee","Department of Electronics and Telecommunication Engineering, Indian Institute of Engineering Science and Technology, Shibpur; Department of Electronics and Telecommunication Engineering, Indian Institute of Engineering Science and Technology, Shibpur","2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC)","23 Apr 2020","2020","","","709","715","Image fusion has an extensive application in the area of medical and satellite image analysis. Having such large applicability, the uses of image fusion is restricted because of the lack of precise algorithm and dedicated hardware. Researchers have tried to use the metaheuristic algorithm in the image processing field. The WOA (whale optimization algorithm) is one of the most popular metaheuristic algorithms used in recent days, but any such straight forward metaheuristic algorithm has some drawbacks. To overcome this drawback, a MWOA (modified WOA) has been proposed in this paper. This modified WOA is incorporated with LSA and BA algorithm. LSA makes this WOA more accurate, and BA makes this system faster. The problem of premature convergence and trapping of local minima is also shorted by using this MWOA. This Modified WOA have greater accuracy for identifying the object which has been compared with other heuristic and metaheuristic algorithm. The optimization algorithm is tasted by using MATLAB R2018b. The proposed design is synthesized using Xilinx Vivado 18.2 synthesis tool and simulated using ModelSim. The outcomes of the synthesis report and simulation of the circuit outshine other metaheuristic optimization approach. This MWOA is performed by using our own designed algorithm.","","978-1-7281-4889-2","10.1109/ICCMC48092.2020.ICCMC-000132","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076434","Modified WOA;camera and sound probe;WOA;LSS;BA;prey;heuristic optimization;metaheuristic optimization","Satellites;Computational modeling;Metaheuristics;Approximation algorithms;Mathematical models;Probes;Integrated circuit modeling","evolutionary computation;field programmable gate arrays;image fusion;search problems","image processing field;whale optimization algorithm;metaheuristic algorithm;MWOA;modified WOA;BA algorithm;heuristic algorithm;metaheuristic optimization approach;optimal image fusion algorithm;local search;bat algorithm;medical image analysis;satellite image analysis;Xilinx Vivado 18.2 synthesis tool;ModelSim","","1","","30","IEEE","23 Apr 2020","","","IEEE","IEEE Conferences"
"Fused Recurrent Network Via Channel Attention For Remote Sensing Satellite Image Super-Resolution","X. Li; D. Zhang; Z. Liang; D. Ouyang; J. Shao","University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China; University of Electronic Science and Technology of China, Chengdu, China","2020 IEEE International Conference on Multimedia and Expo (ICME)","9 Jun 2020","2020","","","1","6","Remote sensing satellite images often suffer from low spatial resolution. Image super-resolution plays an important role in remote sensing image processing. However, existing methods show that increasing network depth will inevitably lead to the dramatic increase of model parameters and the over-fitting problem. Besides, most methods treat different types of information (low-frequency and high-frequency) equally. Motivated by these observations, we propose a fused recurrent network via channel attention (CA-FRN) in this paper. The basic module, recursive channel attention block (RCAB), pays enough attention to the high-frequency information and diminishes the low-frequency information adaptively through channel attention. Based on RCAB, we render our model effective by retaining and fusing hierarchical local information of both low-resolution and high-resolution, and we enhance the network performance simply by increasing the number of RCABs without adding extra parameters. We evaluate the proposed model on satellite images from different datasets, and the proposed CA-FRN is superior to the state-of-the-art methods. Code is available at https://github.com/lxy0922/CAFRN.","1945-788X","978-1-7281-1331-9","10.1109/ICME46284.2020.9102948","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9102948","Satellite image super-resolution;fused recurrent network;channel attention","Satellites;Remote sensing;Spatial resolution;Recurrent neural networks;Feature extraction;Image reconstruction","artificial satellites;geophysical image processing;image fusion;image resolution;recurrent neural nets;remote sensing","remote sensing satellite image super-resolution;low spatial resolution;remote sensing image processing;fused recurrent network;recursive channel attention block;RCAB;high-frequency information;low-frequency information;hierarchical local information;CA-FRN","","1","","23","IEEE","9 Jun 2020","","","IEEE","IEEE Conferences"
"Using Deep Networks for Semantic Segmentation of Satellite Images","T. Selea; M. Neagul","Faculty of Mathematics and Informatics, West University of Timisoara, Timisoara, România; Faculty of Mathematics and Informatics, West University of Timisoara, Timisoara, România","2017 19th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)","11 Nov 2018","2017","","","409","415","In this paper we aim to investigate different deep learning techniques for automatic extraction of valuable information from large sized satellite image data. We focus on the problem of semantic segmentation which attaches a class label to each pixel from the image. We investigate two semantic segmentation architectures based an convolutional neural networks: segnet and u-net. We analyse different tiling strides with reverse aggregation methods. We compare two classical methods (averaging and maximum) and propose a new method based on entropy. We test the models with distinct types of images, emphasizing the need to predict the results using information from all of them. We discuss various fusion strategies and introduce a fusion strategy based on the observations obtained from separately analysing the distinct image types.","","978-1-5386-2626-9","10.1109/SYNASC.2017.00074","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8531320","semantic segmentation;segnet;u net;cnn;satellite image","Machine-to-machine communications;Scientific computing","convolution;entropy;feature extraction;feedforward neural nets;geophysical image processing;image classification;image fusion;image segmentation;learning (artificial intelligence);remote sensing","deep networks;class label;semantic segmentation architectures;convolutional neural networks;reverse aggregation methods;fusion strategy;deep learning techniques;information extraction;satellite image data;tiling strides;entropy","","1","","15","IEEE","11 Nov 2018","","","IEEE","IEEE Conferences"
"Fusion of WorldView-2 Stereo and Multitemporal TerraSAR-X Images for Building Height Extraction in Urban Areas","Y. Xu; P. Ma; E. Ng; H. Lin","Institute of Future Cities, The Chinese University of Hong Kong, Hong Kong, China; Institute of Space and Earth Information Science and Shenzhen Research Institute, The Chinese University of Hong Kong, Hong Kong, China; School of Architecture, the Institute of Environment, Energy and Sustainability (IEES), and the Institute of Future Cities (IOFC), The Chinese University of Hong Kong, Hong Kong, China; Institute of Space and Earth Information Science and Shenzhen Research Institute, The Chinese University of Hong Kong, Hong Kong, China","IEEE Geoscience and Remote Sensing Letters","15 Jun 2015","2015","12","8","1795","1799","We investigated the joint use of the high-resolution WorldView-2 optical satellite images and the multitemporal TerraSAR-X synthetic aperture radar (SAR) satellite images to extract building height information in high-density urban areas. The main idea of the proposed fusion approach is to take full advantage of both data sets in building height retrieval. The proposed approach includes two main stages. First, initial building height estimates are extracted from WorldView-2 stereo images and multitemporal SAR images. These initial results are then combined using a novel object-based fusion approach, in which the heights of points for the same building footprint are retrieved and integrated. Experiments on the Mong Kok area of Hong Kong showed that the proposed approach using both data sets outperforms the use of either stereo images or SAR images alone. According to the results of the proposed approach, the average absolute height retrieval error is 6.53 m, which is much lower than using stereo and SAR images (9.08 and 12.24 m, respectively). The proposed fusion approach is suitable for building height retrieval in urban areas where single satellite data have limitations.","1558-0571","","10.1109/LGRS.2015.2427738","Hong Kong Research Grants Council(grant numbers:CUHK 14408214); Innovation and Technology Support Program of HKSAR(grant numbers:ITS/075/13); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7109861","Building height;object-based fusion;synthetic aperture radar (SAR);WorldView-2;Building height;object-based fusion;synthetic aperture radar (SAR);WorldView-2","Buildings;Synthetic aperture radar;Remote sensing;Urban areas;Laser radar;Optical imaging;Optical sensors","geophysical image processing;image fusion;image resolution;image retrieval;radar imaging;spaceborne radar;stereo image processing;synthetic aperture radar","Hong Kong;Mong Kok area;object-based fusion approach;image retrieval;high-density urban area;synthetic aperture radar;high-resolution WorldView-2 optical satellite image fusion;building height information extraction;multitemporal TerraSAR-X satellite image fusion;distance 6.53 m;distance 9.08 m;distance 12.24 m","","14","1","21","IEEE","18 May 2015","","","IEEE","IEEE Journals"
"An effective pansharpening method for WorldView-2 satellite images","Xu Li; Weifeng Qi","School of Electronics and Information, Northwestern Polytechnical University, Xi'an, P. R. China; School of Electronics and Information, Northwestern Polytechnical University, Xi'an, P. R. China","2015 International Conference on Estimation, Detection and Information Fusion (ICEDIF)","1 Oct 2015","2015","","","88","92","Pansharpening has been an important tool in remote sensing applications, which transforms a set of low-spatial-resolution multispectral images to high-spatial-resolution images by fusing a co-registered fine-spatial-resolution panchromatic image. The new style very high-resolution WorldView-2 satellite images have posed challenges to the image fusion techniques. An effective pansharpening method based on correspondence analysis is presented in this paper. The experimental results show that the presented method can effectively obtain a better trade-off between the spectral fidelity and the spatial resolution enhancement compared to some existing methods.","","978-1-4799-6418-5","10.1109/ICEDIF.2015.7280168","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7280168","pansharpening;resolution;multispectral;panchromatic","Spatial resolution;Linear regression;Roads;Buildings;Indexes","image fusion;remote sensing","effective pansharpening method;WorldView-2 satellite image;remote sensing application;low-spatial-resolution multispectral image;high-spatial-resolution image;co-registered fine-spatial-resolution panchromatic image fusion;image fusion technique;correspondence analysis;spectral fidelity;spatial resolution enhancement","","","","11","IEEE","1 Oct 2015","","","IEEE","IEEE Conferences"
"Machine Learning based Image Processing Techniques for Satellite Image Analysis -A Survey","A. Asokan; J. Anitha","ECE Department, Karunya Institute of Technology and Sciences, Coimbatore, India; ECE Department, Karunya Institute of Technology and Sciences, Coimbatore, India","2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon)","11 Oct 2019","2019","","","119","124","This paper presents the detailed comparison of various image processing techniques for analyzing satellite images. The satellite images are large in size, acquired from long distances and are affected by noise and other environmental conditions. Hence it is necessary to process them so that they can be used by the researchers for analysis. Satellite images are widely used in many real time applications such as in agriculture land detection, navigation and in geographical information systems. In this paper, a review of some popular machine learning based image processing techniques is presented. Also a detailed comparison of various techniques is performed. Limitations in each image processing method are also described. In addition to reviewing of different methods, different metrics for performance evaluation in each of the image processing areas is studied.","","978-1-7281-0211-5","10.1109/COMITCon.2019.8862452","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862452","Remote Sensing. Machine Learning;Segmentation;Enhancement;Feature Extraction","Feature extraction;Satellites;Image segmentation;Classification algorithms;Image enhancement;Image fusion","agriculture;geographic information systems;geophysical image processing;learning (artificial intelligence)","image processing areas;satellite image analysis;machine learning based image processing techniques;agriculture land detection;geographical information systems","","13","","25","IEEE","11 Oct 2019","","","IEEE","IEEE Conferences"
"Deep-Learning-Based Multispectral Satellite Image Segmentation for Water Body Detection","K. Yuan; X. Zhuang; G. Schaefer; J. Feng; L. Guan; H. Fang","Department of Computer Science, Loughborough University, Loughborough, U.K.; Southwest Jiaotong University, Chengdu, China; Department of Computer Science, Loughborough University, Loughborough, U.K.; Information Engineering College, Dalian University, Dalian, China; Department of Computer Science, Loughborough University, Loughborough, U.K.; Department of Computer Science, Loughborough University, Loughborough, U.K.","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","4 Aug 2021","2021","14","","7422","7434","Automated water body detection from satellite imagery is a fundamental stage for urban hydrological studies. In recent years, various deep convolutional neural network (DCNN)-based methods have been proposed to segment remote sensing data collected by conventional RGB or multispectral imagery for such studies. However, how to effectively explore the wider spectrum bands of multispectral sensors to achieve significantly better performance compared to the use of only RGB bands has been left underexplored. In this article, we propose a novel DCNN model-multichannel water body detection network (MC-WBDN)-that incorporates three innovative components, i.e., a multichannel fusion module, an Enhanced Atrous Spatial Pyramid Pooling module, and Space-to-Depth/Depth-to-Space operations, to outperform state-of-the-art DCNN-based water body detection methods. Experimental results convincingly show that our MC-WBDN model achieves remarkable water body detection performance, is more robust to light and weather variations, and can better distinguish tiny water bodies compared to other DCNN models.","2151-1535","","10.1109/JSTARS.2021.3098678","Government of Chengdu City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9492784","Deep convolutional neural networks (DCNNs);feature fusion;multispectral remote sensing;semantic segmentation;water body detection","Feature extraction;Image segmentation;Remote sensing;Indexes;Satellites;Vegetation mapping;Urban areas","convolutional neural nets;deep learning (artificial intelligence);feature extraction;geophysical image processing;geophysics computing;image colour analysis;image fusion;image resolution;image segmentation;object detection;remote sensing","multichannel fusion module;MC-WBDN model;multispectral satellite image segmentation;automated water body detection;satellite imagery;urban hydrological studies;deep convolutional neural network;multispectral imagery;multispectral sensors;RGB bands;DCNN model;remote sensing data segmentation;multichannel water body detection network;enhanced atrous spatial pyramid pooling module;space-to-depth/depth-to-space operations","","19","","54","CCBY","21 Jul 2021","","","IEEE","IEEE Journals"
"An online tensor robust PCA algorithm for sequential 2D data","Z. Zhang; D. Liu; S. Aeron; A. Vetro","Department of ECE, Tufts University, Medford, MA; Mitsubishi Electric Research Laboratories, Cambridge, MA; Department of ECE, Tufts University, Medford, MA; Mitsubishi Electric Research Laboratories, Cambridge, MA","2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","19 May 2016","2016","","","2434","2438","Tensor robust principal component analysis (PCA) approaches have drawn considerable interests in many applications such as background subtraction, denoising, and outlier detection, etc. In this paper we propose an online tensor robust PCA where the multidimensional data (tensor) is revealed sequentially in online mode, and tensor PCA is updated based on the latest estimation and the newly collected data. Compared to the tensor robust PCA in batch mode, we significantly reduce the required memory and improve the computation efficiency. Application on fusing cloud-contaminated satellite images demonstrates that the proposed method shows superiority in both convergence speed and performance compared to the state-of-the-art approaches.","2379-190X","978-1-4799-9988-0","10.1109/ICASSP.2016.7472114","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7472114","Tensor Robust PCA;online learning;t-SVD;sequential data;cloud removal","Tensile stress;Principal component analysis;Robustness;Matrix decomposition;Modules (abstract algebra);Discrete Fourier transforms;Laboratories","estimation theory;image fusion;principal component analysis;tensors","online tensor robust PCA algorithm;sequential 2D data;principal component analysis;background subtraction;outlier detection;cloud-contaminated satellite image fusion","","17","1","14","IEEE","19 May 2016","","","IEEE","IEEE Conferences"
"Pan-sharpening based on sparse representation","S. Ayas; E. T. Görmüs; M. Ekinci","Bilgisayar Mühendisliği Bölümü, Karadeniz Teknik Üniversitesi, Trabzon, Türkiye; Harita Mühendisliği Bölümü, Karadeniz Teknik Üniversitesi, Trabzon, Türkiye; Bilgisayar Mühendisliği Bölümü, Karadeniz Teknik Üniversitesi, Trabzon, Türkiye","2017 25th Signal Processing and Communications Applications Conference (SIU)","29 Jun 2017","2017","","","1","4","Pan-sharpening in remote sensing aims to obtain a multispectral image with high spectral and spatial information by combining spectral information of a low resolution multispectral image and spatial information of a high resolution panchromatic image. In this paper, a pan-sharpening method based on sparse representation was proposed. Firstly, a dictionary was learned from the multispectral image patches. Then, sparse coefficients of low resolution multispectral image and high resolution panchromatic image were calculated. Thus, pan-sharpened multispectral image was obtained by using these sparse coefficients and dictionary. The IKONOS satellite image was used to test the proposed method. The quantitative and visual results demonstrate the effectiveness of the proposed method in pan-sharpening of the remote sensing images.","","978-1-5090-6494-6","10.1109/SIU.2017.7960662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7960662","Pan-sharpening;sparse representation;dictionary learning;IKONOS","Remote sensing;Spatial resolution;Dictionaries;Satellites;Image fusion;Principal component analysis","geophysical image processing;image representation;image resolution;remote sensing;sparse matrices","remote sensing;spectral information;spatial information;low-resolution multispectral image;high-resolution panchromatic image;sparse representation;dictionary learning;multispectral image patches;sparse coefficients;pan-sharpened multispectral image;IKONOS satellite image;quantitative analysis;visual analysis","","","","12","IEEE","29 Jun 2017","","","IEEE","IEEE Conferences"
"Multimodal Information Fusion for Weather Systems and Clouds Identification From Satellite Images","C. Bai; D. Zhao; M. Zhang; J. Zhang","Key Laboratory of Visual Media Intelligent Processing Technology of Zhejiang Province, Hangzhou, China; Key Laboratory of Visual Media Intelligent Processing Technology of Zhejiang Province, Hangzhou, China; Key Laboratory of Visual Media Intelligent Processing Technology of Zhejiang Province, Hangzhou, China; School of Control Science and Engineering, Shandong University, Jinan, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","9 Sep 2022","2022","15","","7333","7345","Seeing the cloud and then understanding the weather is one of the important means for people to forecast weather. There has been a certain progress in the use of deep learning technology for weather forecasting, especially in the automatic understanding of disaster weather from satellite image, which can be seen as the image classification problem. Publicly available satellite image benchmark database tries to link weather directly with satellite images. However, single image modal is far from enough to correctly identify weather systems and clouds. Thus, we integrate images with meteorological elements, in which five kinds of meteorological elements, such as season, month, date stamp, and geographic longitude, and latitude, are labeled. To effectively use such various modalities for clouds and weather systems identification through satellite image classification tasks, we propose a new satellite image classification framework: multimodal auxiliary network (MANET). MANET consists of three parts: image feature extraction module based on convolutional neural network, meteorological information feature extraction module based on perceptron, and layer-level multimodal fusion. MANET successfully integrates the multimodal information, including meteorological elements and satellite images. The experimental results show that MANET can achieve better weather systems and clouds and land cover classification results based on satellite images.","2151-1535","","10.1109/JSTARS.2022.3202246","National Key Research and Development Program of China(grant numbers:2018YFE0126100); Zhejiang Provincial Natural Science Foundation of China(grant numbers:LR21F020002); Key Research and Development Program of Jiangsu Province(grant numbers:BE2021093); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869335","Clouds;image classification;meteorology;multimodal","Meteorology;Image classification;Task analysis;Satellites;Clouds;Cloud computing;Mobile ad hoc networks","atmospheric techniques;clouds;convolutional neural nets;deep learning (artificial intelligence);feature extraction;geophysical image processing;image classification;image fusion;perceptrons;remote sensing;weather forecasting","weather forecasting;disaster weather;single image modal;meteorological elements;satellite image classification tasks;image feature extraction module;satellite image benchmark database;clouds;date stamp;geographic longitude;multimodal auxiliary network;convolutional neural network;meteorological information feature extraction module;perceptron;layer-level multimodal fusion;land cover classification","","","","76","CCBY","29 Aug 2022","","","IEEE","IEEE Journals"
"A novel and simple method for panchromatic sharpening","D. E. Canbay","Istanbul Teknik Universitesi, Istanbul, TR","2018 26th Signal Processing and Communications Applications Conference (SIU)","9 Jul 2018","2018","","","1","3","Panchromatic sharpening methods are frequently used in remote sensing technologies where satellite images are processed to obtain more useful forms. Obtaining high resolution images, by combining the images collected via different sensors with various wave lengths and resolutions, is very useful in imaging water resources, agricultural areas, forests, etc. In this study, application of a simple and very fast panchromatic sharpening method is presented including a comparative analysis (in terms of quality metrics) with the existing methods in the literature.","","978-1-5386-1501-0","10.1109/SIU.2018.8404640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8404640","Panchromatic sharpening;IHS;Brovey;YUV420;remote sensing;satellite image;LANDSAT","Remote sensing;Artificial satellites;Earth;Principal component analysis;Satellites;Image resolution;Measurement","geophysical image processing;geophysical signal processing;hydrological techniques;image fusion;image resolution;principal component analysis;remote sensing;water resources","simple method;panchromatic sharpening methods;remote sensing technologies;satellite images;high resolution images;wave lengths;resolutions;simple sharpening method;very fast panchromatic sharpening method;novel method;imaging water resources;agricultural areas;forests;comparative analysis","","2","","","IEEE","9 Jul 2018","","","IEEE","IEEE Conferences"
"Feature Fusion based Unsupervised Change Detection in Optical Satellite Images","N. Gupta; P. Singh; S. Ari","Department of Electronics and Communication Engineering, National Institute of Technology, Rourkela, India; Department of Electronics and Communication Engineering, National Institute of Technology, Rourkela, India; Department of Electronics and Communication Engineering, National Institute of Technology, Rourkela, India","2019 IEEE 5th International Conference for Convergence in Technology (I2CT)","12 Mar 2020","2019","","","1","5","This paper proposes a feature fusion technique for unsupervised change detection. Features extracted from two different techniques are fused to get the final feature vectors. The first technique utilizes the Gabor wavelet at multiple orientations and scales, where maximum magnitude over all orientation in each scale is taken to create features of two multitemporal satellite images. The second technique applies canonical correlation analysis (CCA) on the combination of original multispectral bands and extracted local neighborhood information from all the bands. Next, the difference feature vectors obtained from individual techniques are fused to generate the final feature vectors. Furthermore, to get the binary change map, fuzzy c-means clustering is applied on final extracted features. In this feature fusion, the local neighborhood information from Gabor wavelet kernel is combined with joint change information from group of pixels extracted by CCA to produce more discriminant features. Experiments conducted on optical satellite images, which are collected by two sensors of Landsat satellite, and it shows the better performance of the proposed technique compared to earlier stated techniques.","","978-1-5386-8075-9","10.1109/I2CT45611.2019.9033712","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9033712","Binary change map;Canonical correlation analysis (CCA);Change detection;fuzzy c-means clustering;Gabor wavelet kernel;multitemporal satellite image","Feature extraction;Kernel;Satellites;Correlation;Optical imaging;Remote sensing;Optical sensors","feature extraction;fuzzy set theory;geophysical image processing;image fusion;pattern clustering;remote sensing;wavelet transforms","fuzzy c-means clustering;CCA;canonical correlation analysis;Landsat satellite;Gabor wavelet kernel;feature extraction;binary change map;difference feature vectors;local neighborhood information;multispectral bands;multitemporal satellite images;feature vectors;feature fusion technique;optical satellite images;unsupervised change detection","","2","","19","IEEE","12 Mar 2020","","","IEEE","IEEE Conferences"
"Fusion pipeline of 3D terrain data from different input images","Y. j. Ban; H. s. Kim; C. j. Park","Electronics and Telecommunications, Research Institute, Daejeon, Korea; Electronics and Telecommunications, Research Institute, Daejeon, Korea; Electronics and Telecommunications, Research Institute, Daejeon, Korea","2019 International Conference on Information and Communication Technology Convergence (ICTC)","27 Dec 2019","2019","","","1096","1098","Nowadays, researches for reconstructing 3D terrain from images are being widely carried out. The result of reconstruction according to the kind of the input image is different. In this paper, we propose a 3D terrain fusion method of textured mesh models reconstructed from different altitude images or generated by hand. We merged 3D models depending on the priority and connected edges seamlessly.","2162-1233","978-1-7281-0893-3","10.1109/ICTC46691.2019.8939798","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8939798","3D mesh;merge;fusion;aerial image;satellite image;reconstruction","Face recognition;Satellites;Image reconstruction;Three-dimensional displays;Conferences;Geomagnetism","image fusion;image reconstruction;image texture;mesh generation;solid modelling;terrain mapping","fusion pipeline;textured mesh models;3D terrain data fusion method;altitude images;image reconstruction","","","","6","IEEE","27 Dec 2019","","","IEEE","IEEE Conferences"
"Fast Unsupervised Spatiotemporal Super-Resolution for Multispectral Satellite Imaging Using Plug-and-Play Machinery Strategy","C. -H. Lin; C. -Y. Sie; P. -Y. Lin; J. -T. Lin","Miin Wu School of Computing, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan; Department of Electrical Engineering, National Cheng Kung University, Tainan, Taiwan","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2568","2571","Acquiring high-spatial-resolution (HSR) images at high temporal sampling rate is not economical and even not achievable using contemporary multispectral satellite imaging hardware. An alternative is to fuse a set of HSR images acquired at low sampling rate, with another set of low-spatial-resolution images acquired at high sampling rate, and such fusion problem is referred to as spatiotemporal super-resolution (STSR). We mitigate the ill-posedness of the STSR problem by incorporating the image self-similarity prior (S2P), which is the key behind the design of several state-of-the-art imaging inverse problems. Unlike most super-resolution works in the computer vision area, our method does not rely on collecting big data. Instead, we propose a fully unsupervised STSR method by adopting the popular strategy in machine learning, known as plug-and-play optimization, and by carefully refining the required matrix computation/inversion. We term our method as STSRS2P, whose superiority and low computational complexity will be experimentally verified.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554710","Einstein Program (Young Scholar Fellowship Program) of Ministry of Science and Technology (MOST), Taiwan(grant numbers:MOST 109-2636-E-006-022); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554710","Multispectral satellite;image fusion;spatiotemporal super-resolution;image self-similarity;plug-and-play","Computer vision;Satellites;Superresolution;Refining;Imaging;Big Data;Benchmark testing","","","","1","","14","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Water Pollution Detection in Acapulco Coasts Using Merged Data from the Sentinel-2 and Sentinel-3 Satellites","R. Lomelí-Huerta; H. Avila-George; J. P. Rivera-Caicedo; M. De-la-Torre","Departamento de Ciencias Computacionales e Ingenierías, Universidad de Guadalajara; Departamento de Ciencias Computacionales e Ingenierías, Universidad de Guadalajara; CONACyT-UAN, Secretaría de Investigation y Posgradom, Universidad Autónoma de Nayarit; Departamento de Ciencias Computacionales e Ingenierías, Universidad de Guadalajara","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","1518","1521","Acapulco coasts are occasionally contaminated by illegal discharges originated by temporary or permanent floods that disembogue to the pacific ocean. Plumes formed by contaminated water running through the ocean can be distinguished in satellite imagery, and their reflectance is related to the polluting elements. Although some spacial agencies provide data from diverse multispectral sensors, application-specific requirements are fulfilled by merging heterogeneous imagery (differences in spatial, temporal, and spectral resolutions). This paper proposes a continuous monitoring strategy to detect pollution in water discharges by combining data from Sentinel-2 and Sentinel-3 platforms. First, the region of interest to be monitored is detected using the bands with high spatial resolution. Then, distance-based supervised machine learning is employed to detect pixel-wise pollution in water. Finally, the historic detections over time are presented to detect recurrent discharges.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553929","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553929","Sentinel;satellite image fusion;contaminated water;monitoring system;remote sensing","Reflectivity;Image sensors;Satellites;Oceans;Merging;Machine learning;Water pollution","environmental monitoring (geophysics);floods;geophysical image processing;marine pollution;oceanographic regions;oceanographic techniques;remote sensing;supervised learning;water pollution measurement","water pollution detection;Sentinel-2 satellite;Sentinel-3 satellite;illegal discharges;temporary floods;permanent floods;Pacific Ocean;plumes;contaminated water;satellite imagery;diverse multispectral sensors;heterogeneous imagery;water discharges;distance-based supervised machine learning;pixel-wise pollution;Acapulco coasts;Mexico;permanent flood","","1","","11","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Change Detection Method of High Resolution Remote Sensing Image Based on D-S Evidence Theory Feature Fusion","J. Zhao; S. Liu; J. Wan; M. Yasir; H. Li","College of Oceanography and Space Informatics, China University of Petroleum Qingdao, Qingdao, China; College of Oceanography and Space Informatics, China University of Petroleum Qingdao, Qingdao, China; College of Oceanography and Space Informatics, China University of Petroleum Qingdao, Qingdao, China; School of Geosciences, China University of Petroleum Qingdao, Qingdao, China; College of Oceanography and Space Informatics, China University of Petroleum Qingdao, Qingdao, China","IEEE Access","8 Jan 2021","2021","9","","4673","4687","Using high-resolution satellite image to detect change has been a hotspot in the field of remote sensing for a long time series. The change detection method combining feature extraction and machine learning could extract the change information effectively, but the manual sample selection is a huge workload for a wide range remote sensing images, and it is also difficult to ensure the accuracy of the pre-detection sample using a single difference image. Therefore, in this paper, a new method for change detection has been put forward based on multi-feature fusion of D-S evidence theory. In this approach, the texture difference image has calculated by structural similarity, because the difference image based on structural similarity plays a great role in change detection, which was verified in experiments. The difference images based on texture features and traditional spectral features are fused by D-S evidence theory, and texture features and spectral features have been fully utilized. Setting rules to select samples with high confidence based on pixels, and SLIC super-pixel segmentation has applied in order to improve further the credibility of the sample. Finally, the samples selected by SLIC segmentation optimization are sent to the classifier training to obtain the final result. The experimental results show that texture features play a very important role in the change detection of high-resolution remote sensing images, and D-S evidence theory could effectively fuse spectral texture features to improve the accuracy of change detection. The proposed method has high accuracy and good performance in change detection.","2169-3536","","10.1109/ACCESS.2020.3047915","National Key Research and Development Program of China(grant numbers:2017YFC145600); National Natural Science Foundation of China(grant numbers:41776182); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9310308","Change detection;D-S evidence theory;structural similarity (SSIM);multi feature fusion;remote sensing;high-resolution satellite image","Remote sensing;Feature extraction;Data mining;Support vector machines;Monitoring;Image segmentation;Satellites","feature extraction;geophysical image processing;image classification;image fusion;image segmentation;image texture;learning (artificial intelligence);object detection;remote sensing","change detection method;high resolution remote sensing image;D-S evidence theory feature;high-resolution satellite image;feature extraction;machine learning;change information;wide range remote sensing images;pre-detection sample;single difference image;multifeature fusion;texture difference image;traditional spectral features;high-resolution remote sensing images;spectral texture features","","10","","66","CCBY","29 Dec 2020","","","IEEE","IEEE Journals"
"Dense Fusion Classmate Network for Land Cover Classification","C. Tian; C. Li; J. Shi",Harbin Institute of Technology; SenseTime Group Limited; SenseTime Group Limited,"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)","16 Dec 2018","2018","","","262","2624","Recently, FCNs based methods have made great progress in semantic segmentation. Different with ordinary scenes, satellite image owns specific characteristics, which elements always extend to large scope and no regular or clear boundaries. Therefore, effective mid-level structure information extremely missing, precise pixel-level classification becomes tough issues. In this paper, a Dense Fusion Classmate Network (DFCNet) is proposed to adopt in land cover classification. DFCNet is jointly trained with auxiliary road dataset seemed as “classmate”, which properly compensates the lack of mid-level information. Meanwhile, a dense fusion module is also integrated, which guarantees the precise discrimination of confused pixels and benefits the network optimization from scratch. Score on Deep- Globe land cover classification competition shows that our approach has achieved good performance.","2160-7516","978-1-5386-6100-0","10.1109/CVPRW.2018.00049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8575509","","Roads;Image segmentation;Semantics;Task analysis;Training;Convolution;Satellites","geophysical image processing;image classification;image fusion;image segmentation;optimisation;terrain mapping","semantic segmentation;satellite image;DFCNet;network optimization;pixel-level classification;dense fusion classmate network;land cover classification;FCN based methods;mid-level structure information;Deep-Globe land cover classification competition","","18","","22","IEEE","16 Dec 2018","","","IEEE","IEEE Conferences"
"Guided filtering based real time flood area identification on bitemporal satellite images","A. Asokan; J. Anitha","Department of ECE, Sri Krishna College of Technology Kovaipudur, Coimbatore, Tamil Nadu, India; Department of ECE, Karunya Institute of Technology and Sciences","2021 Fourth International Conference on Electrical, Computer and Communication Technologies (ICECCT)","29 Nov 2021","2021","","","1","4","Satellite images are considered as the most reliable source of information concerning disaster affected areas. The ease of satellite image acquisition in extreme weather and frequent availability with wider coverage makes it effective for proper disaster response. This paper focuses on change detection in flood areas in bitemporal satellite imagery. The proposed method is based on three stages: guided filter for image enhancement and spatial feature extraction, difference image creation and classification. The difference image is classified to identify the changes in pre-event and post-event images to form a binary change map. The performance of the proposed method is assessed by applying on image sets acquired before and after the floods. Experiments show that the proposed method gives promising results over existing methods.","","978-1-6654-1480-7","10.1109/ICECCT52121.2021.9616955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9616955","bitemporal;image fusion;multispectral;change map;feature extraction","Satellites;Feature extraction;Information filters;Real-time systems;Communications technology;Floods;Reliability","disasters;feature extraction;floods;geophysical image processing;image classification;image enhancement;remote sensing","time flood area identification;bitemporal satellite images;disaster affected areas;satellite image acquisition;extreme weather;frequent availability;wider coverage;proper disaster response;change detection;flood areas;bitemporal satellite imagery;image enhancement;spatial feature extraction;difference image creation;classification;post-event images;binary change map;image sets;floods","","","","20","IEEE","29 Nov 2021","","","IEEE","IEEE Conferences"
"Fuzzy-fusion approach for land cover classification","T. M. A. Santos; A. Mora; R. A. Ribeiro; J. M. N. Silva","Computational Intelligence Group of CTS/UNINOVA, FCT / NOVA University of Lisbon, Portugal; Computational Intelligence Group of CTS/UNINOVA, FCT / NOVA University of Lisbon, Portugal; Computational Intelligence Group of CTS/UNINOVA, FCT / NOVA University of Lisbon, Portugal; CCIAM - Climate Change Impacts, Adaptation & Modelling research group, CE3C, FCUL, Lisboa, Portugal","2016 IEEE 20th Jubilee International Conference on Intelligent Engineering Systems (INES)","29 Aug 2016","2016","","","177","182","The use of computational intelligent techniques for feature extraction and classification from earth observation satellite images, like Landsat multispectral images, can contribute to improve remote sensing analysis. Image fusion techniques are applied to fuse the spectral images into a higher-level image of the land cover distribution. In this paper we propose a fuzzy-fusion inference approach for satellite image classification based on a fuzzy process, which uses both a hybrid method to train the classifier and reinforcement aggregation operators in the inference scheme. The approach was tested with land cover maps for the district of Mandimba of the Niassa province, Mozambique and was validated against an expert classification and then with Decision trees and Artificial Neural Networks.","","978-1-5090-1216-9","10.1109/INES.2016.7555116","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7555116","","Satellites;Histograms;Training;Remote sensing;Earth;Fitting;Vegetation mapping","decision trees;feature extraction;fuzzy reasoning;geophysical image processing;image classification;image fusion;neural nets;remote sensing","fuzzy-fusion approach;land cover classification;computational intelligent techniques;feature extraction;feature classification;earth observation satellite images;Landsat multispectral images;artificial neural networks;decision trees;Mozambique;Niassa province;Mandimba;inference scheme;reinforcement aggregation operators;fuzzy process;satellite image classification;fuzzy-fusion inference approach;land cover distribution;Image fusion techniques;remote sensing analysis","","5","","30","IEEE","29 Aug 2016","","","IEEE","IEEE Conferences"
"NBR-Net: A Nonrigid Bidirectional Registration Network for Multitemporal Remote Sensing Images","Y. Xu; J. Li; C. Du; H. Chen","College of Electronic Science and Technology, National University of Defense Technology, Hunan, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Hunan, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Hunan, Changsha, China; College of Electronic Science and Technology, National University of Defense Technology, Hunan, Changsha, China","IEEE Transactions on Geoscience and Remote Sensing","14 Apr 2022","2022","60","","1","15","Remote sensing image registration is the basis of change detection, environmental monitoring, and image fusion. Under severe appearance differences, feature-based methods have difficulty in finding sufficient feature matches to solve the global transformation and tackling the local deformation caused by height undulations and building shadows. By contrast, nonrigid registration methods are more flexible than feature-based matching methods, while often ignoring the reversibility between images, resulting in misalignment and inconsistency. To this end, this article proposes a nonrigid bidirectional registration network (NBR-Net) to estimate the flow-based dense correspondence for remote sensing images. We first propose an external cyclic registration network to strengthen the registration reversibility and geometric consistency by registering Image A to Image B and then reversely registering back to Image A. Second, we design an internal iterative refinement strategy to optimize the rough predicted flow caused by large distortion and viewpoint difference. Extensive experiments demonstrate that our method shows a performance superior to the state-of-the-art models on the multitemporal satellite image dataset. Furthermore, we attempt to extend our method to heterogeneous remote sensing image registration, which is more common in the real world. Therefore, we test our pretrained model in a satellite and unmanned aerial vehicle (UAV) image registration task. Due to the cyclic registration mechanism and coarse-to-fine refinement strategy, the proposed approach obtains the best performance on two GPS-denied UAV image datasets. Our code will be released at https://github.com/xuyingxiao/ NBR-Net.","1558-0644","","10.1109/TGRS.2022.3162094","National Natural Science Foundation of China(grant numbers:U19A2058,61806211,41971362); Natural Science Foundation of Hunan Province China(grant numbers:2020JJ4103); Hunan Provincial Innovation Foundation For Postgraduate(grant numbers:CX20210005); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9740686","Cycle consistency;iterative refinement;nonrigid;remote sensing image registration;reversibility;unmanned aerial vehicle (UAV) image registration","Remote sensing;Image registration;Satellites;Bidirectional control;Sensors;Strain;Feature extraction","autonomous aerial vehicles;geophysical image processing;image fusion;image matching;image registration;iterative methods;remote sensing","nonrigid bidirectional registration network;multitemporal remote sensing images;image fusion;height undulations;feature-based matching methods;flow-based dense correspondence;external cyclic registration network;multitemporal satellite image dataset;heterogeneous remote sensing image registration;unmanned aerial vehicle image registration task;GPS-denied UAV image datasets;internal iterative refinement strategy","","2","","59","IEEE","24 Mar 2022","","","IEEE","IEEE Journals"
"Fusion of SAR and Multispectral Satellite Images Using Multiscale Analysis and Dempster-Shafer Theory for Flood Extent Extraction","M. O. Sghaier; M. Hadzagic; J. Patera","Centre de recherches math´ematiques, Universit´e de Montr´eal, Montréal, Québec, Canada; OODA Technologies Inc., Montréal, Québec, Canada; Centre de recherches math´ematiques, Universit´e de Montr´eal, Montréal, Québec, Canada","2019 22th International Conference on Information Fusion (FUSION)","27 Feb 2020","2019","","","1","8","Monitoring flood extent by means of Synthetic Aperture Radar (SAR) images has become a very common practice among decision makers and planners in disaster management as these images provide wide area coverage in extreme weather conditions. However, due to the satellite revisit time, their availability hinders their efficient use in disaster management. To capitalize on SAR images characteristics, this work considers both SAR and optical multispectral (MS) images, and proposes a novel method for SAR and optical image fusion in application to flood extent monitoring, which is based on two main steps: 1- Extraction of water pixels from the pre- and post-flooding images using a Modified Water Index (MWI) for water bodies identification from optical MS images and the Structural Feature Set (SFS) texture measurement for homogeneous areas extraction from SAR images, and 2- Applying the Max-Tree structure to estimate mass functions based on the multiscale and the multishape analysis of the input features map which are subsequently incorporated into the fusion module using Dempster-Shafer theory (DST). The results obtained in the evaluation of the proposed fusion method for three flood events characterized by different satellite image scenarios demonstrate the benefits of the multiscale DST fusion strategy in terms of chosen metrics in the classification of water body and monitoring of flood extent.","","978-0-9964527-8-6","10.23919/FUSION43075.2019.9011209","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9011209","SAR;multispectral satellite images;Dempster-Shafer fusion;multiscale image analysis;flood extent extraction","Synthetic aperture radar;Feature extraction;Optical imaging;Indexes;Radiometry;Monitoring;Sensors","floods;geophysical image processing;image classification;image fusion;optical images;radar imaging;synthetic aperture radar;terrain mapping","Dempster-Shafer theory;fusion method;flood events;multiscale DST fusion strategy;multispectral satellite images;multiscale analysis;flood extent Extraction;Synthetic Aperture Radar images;decision makers;disaster management;wide area coverage;extreme weather conditions;satellite revisit time;SAR images characteristics;optical multispectral images;optical image fusion;flood extent monitoring;water pixels;post-flooding images;Modified Water Index;water bodies identification;optical MS images;Structural Feature Set texture measurement;homogeneous areas extraction;fusion module;Max-Tree structure;satellite image scenarios","","","","24","","27 Feb 2020","","","IEEE","IEEE Conferences"
"Information Content of Very-High-Resolution SAR Images: Semantics, Geospatial Context, and Ontologies","C. O. Dumitru; S. Cui; G. Schwarz; M. Datcu","Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR),, Weßling, Germany; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR),, Weßling, Germany; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR),, Weßling, Germany; Remote Sensing Technology Institute (IMF), German Aerospace Center (DLR),, Weßling, Germany","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","22 May 2015","2015","8","4","1635","1650","Currently, the amount of collected Earth Observation (EO) data is increasing considerably with a rate of several Terabytes of data per day. As a consequence of this increasing data volume, new concepts for exploration and information retrieval are urgently needed. To this end, we propose to explore satellite image data via an image information mining (IIM) approach in which the main steps are feature extraction, classification, semantic annotation, and interactive query processing. This leads to a new process chain and a robust taxonomy for the retrieved categories capitalizing on human interaction and judgment. We concentrated on land cover categories that can be retrieved from high-resolution synthetic aperture radar (SAR) images of the spaceborne TerraSAR-X instrument, where we annotated different urban areas all over the world and defined a taxonomy element for each prevailing surface cover category. The annotation resulted from a test dataset comprising more than 100 scenes covering diverse areas of Africa, Asia, Europe, the Middle East, and North and South America. The scenes were grouped into several collections with similar source areas and each collection was processed separately in order to discern regional characteristics. In the first processing step, each scene was tiled into patches. Then the features were extracted from each patch by a Gabor filter bank and a support vector machine with relevance feedback classifying the feature sets into user-oriented land cover categories. Finally, the categories were semantically annotated using Google Earth for ground truthing. The annotation followed a multilevel approach that allowed the fusion of information being visible on different resolution levels. The novelty of this paper lies in the fact that a semantic annotation was performed with a large number of high-resolution radar images that allowed the definition of more than 850 surface cover categories. This opens the way toward an automated identification and classification of urban areas, infrastructure (e.g., airports), geographic objects (e.g., mountains), industrial installations, military compounds, vegetation, and agriculture. Applications that may result from this work can be a semantic catalog of urban images to be used in crisis situations or after a disaster. In addition, the proposed taxonomies can become a basis for building a semantic catalog of satellite images. Finally, we defined four powerful types of high-level queries. Querying on such high levels provides new opportunities for users to search an image database for specific parameters or semantic relationships.","2151-1535","","10.1109/JSTARS.2014.2363595","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6960829","Annotation;classification;feature extraction;high-resolution images;indexing;ontologies;querying;semantic catalogs;synthetic aperture radar (SAR);taxonomies;TerraSAR-X;Annotation;classification;feature extraction;high-resolution images;indexing;ontologies;querying;semantic catalogs;synthetic aperture radar (SAR);taxonomies;TerraSAR-X","Synthetic aperture radar;Remote sensing;Feature extraction;Semantics;Satellites;Taxonomy;Earth","data mining;feature extraction;Gabor filters;geophysical image processing;image classification;image fusion;image resolution;image retrieval;land cover;ontologies (artificial intelligence);radar imaging;remote sensing by radar;support vector machines;synthetic aperture radar;terrain mapping;visual databases","Gabor filter bank;support vector machine;user-oriented land cover categories;Google Earth;ground truthing;high-resolution radar image fusion;surface cover categories;urban area automated identification;urban area automated classification;infrastructure;geographic objects;industrial installations;military compounds;vegetation;agriculture;semantic catalog;urban images;crisis situations;disaster;high-level queries;image database;semantic relationships;information content;very-high-resolution SAR images;geospatial context;ontologies;regional characteristics;source areas;South America;North America;Middle East;Europe;Asia;Africa;surface cover category;taxonomy element;spaceborne TerraSAR-X instrument;high-resolution synthetic aperture radar images;land cover categories;human judgment;human interaction;interactive query processing;semantic annotation;feature classification;feature extraction;image information mining approach;satellite image data;information retrieval;data volume;collected Earth Observation data","","44","","37","IEEE","20 Nov 2014","","","IEEE","IEEE Journals"
"Coarse-to-fine ship detection using visual saliency fusion and feature encoding for optical satellite images","Y. Yin; N. Liu; C. Li; W. Wan; T. Fang","Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China","2016 International Conference on Audio, Language and Image Processing (ICALIP)","9 Feb 2017","2016","","","705","710","In order to overcome cloud clutters and varied sizes of objects in high-resolution optical satellite images, a novel coarse-to-fine ship detection framework is proposed. Initially, a modified saliency fusion algorithm is derived to reduce cloud clutters and extract ship candidates. Then, in coarse discrimination stage, candidates are described by introducing shape feature to eliminate regions which are not conform to ship characteristics. In fine discrimination stage, candidates are represented by local descriptor-based feature encoding, and then linear SVM is used for discrimination. Experiments on 60 images (including 467 objects) collected from Microsoft Virtual Earth demonstrate the effectiveness of the proposed framework. Specifically, the fusion of visual saliency achieves 17.07% higher Precision and 7.23% higher Recall compared with those of individual one. Moreover, using local descriptor in fine discrimination makes Precision and F-measure further be improved by 7.23% and 1.74%, respectively.","","978-1-5090-0654-0","10.1109/ICALIP.2016.7846579","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7846579","feature encoding;optical satellite images;ship detection;visual saliency","Marine vehicles;Feature extraction;Visualization;Encoding;Shape;Adaptive optics;Optical imaging","clouds;feature extraction;image coding;image fusion;object detection;optical information processing;remote sensing;ships;support vector machines","Microsoft Virtual Earth;linear SVM;local descriptor-based feature encoding;shape feature;coarse discrimination stage;ship candidate extraction;modified saliency fusion algorithm;coarse-to-fine ship detection framework;cloud clutter reduction;optical satellite image encoding","","3","","13","IEEE","9 Feb 2017","","","IEEE","IEEE Conferences"
"Weather Visibility Prediction Based on Multimodal Fusion","C. Zhang; M. Wu; J. Chen; K. Chen; C. Zhang; C. Xie; B. Huang; Z. He","Pattern Recognition and Intelligent System Lab, Beijing University of Posts and Telecommunications, Beijing, China; Pattern Recognition and Intelligent System Lab, Beijing University of Posts and Telecommunications, Beijing, China; Pattern Recognition and Intelligent System Lab, Beijing University of Posts and Telecommunications, Beijing, China; Pattern Recognition and Intelligent System Lab, Beijing University of Posts and Telecommunications, Beijing, China; Division of Energy Processes, KTH Royal Institute of Technology, Stockholm, Sweden; National Meteorological Center, Beijing, China; National Meteorological Center, Beijing, China; Department of Statistics and Computer Science, McGill University, Montreal, QC, Canada","IEEE Access","17 Jun 2019","2019","7","","74776","74786","Visibility affects all forms of traffic: roads, sailing, and aviation. Visibility prediction is meaningful in guiding production and life. Different from weather prediction, which relies solely on atmosphere factors, the factors that affect meteorological visibility are more complicated, such as the air pollution caused by factory exhaust emission. However, the current prediction of visibility is mostly based on the numerical prediction method similar to the weather prediction. We proposed a method using multimodal fusion to build a weather visibility prediction system in this paper. An advanced numerical prediction model and a method for emission detection were used to build a multimodal fusion visibility prediction system. We used the most advanced regression algorithm, XGBoost, and LightGBM, to train the fusion model for numerical prediction. Through the estimation of factory emission by the traditional detector in the satellite image, we propose to add the result of estimation based on Landsat-8 satellite images to assist the prediction. By testing our numerical model in atmosphere data of various meteorological observation stations in Beijing-Tianjin-Hebei region from 2002 to 2018, our numerical prediction model turns out to be more accurate than other existing methods, and after fusing with emission detection method, the accuracy of our visibility prediction system has been further improved.","2169-3536","","10.1109/ACCESS.2019.2920865","National Natural Science Fund(grant numbers:61773071); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8731972","Visibility prediction;emission estimation;numerical prediction;satellite image","Satellites;Numerical models;Predictive models;Production facilities;Estimation;Prediction algorithms;Forecasting","air pollution;atmospheric techniques;geophysical image processing;image fusion;regression analysis;remote sensing;weather forecasting","multimodal fusion visibility prediction system;fusion model;emission detection method;weather prediction;atmosphere factors;meteorological visibility;factory exhaust emission;weather visibility prediction system;advanced numerical prediction model;Beijing-Tianjin-Hebei region;AD 2002 to 2018","","17","","41","OAPA","5 Jun 2019","","","IEEE","IEEE Journals"
"Preprocessing and fusion analysis of GF-2 satellite Remote-sensed spatial data","D. -D. Zhang; F. Xie; L. Zhang","Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University, Shanghai, China; Shanghai Institute of Technical Physics, East China Normal University, Shanghai, China; MOE International Joint Lab of Trustworthy Software, East China Normal University, China","2018 International Conference on Information Systems and Computer Aided Education (ICISCAE)","14 Mar 2019","2018","","","24","29","There is no pansharpening method that can be applied to all kinds of images at present due to the principle of fusion processing and the characteristics of sensors that acquire images. In order to explore the suitable fusion method for the "" Gaofen-2 "" satellite image, PCA, HPF, Gram-Schmidt and NNDiffuse four kinds of fusion methods were selected to merge the panchromatic and multi spectral data of Gaofen-2 satellite images, the fusion results of the image were synthetically compared and evaluated with subjective evaluation and quantitative analysis. The test results show that the NNDiffuse transform method has the best combination effect and is very prominent in the fusion effect of the visible light band; And in the fusion of near-infrared band, Gram-Schmidt method can be considered. The research results of this paper can provide reference for the fusion processing and application of Gaofen-2 satellite image data.","","978-1-5386-5738-6","10.1109/ICISCAE.2018.8666873","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666873","Pansharpening;Gaofen-2;NNDiffuse;subjective evaluation;quantitative analysis","Spatial resolution;Satellites;Principal component analysis;Transforms;Distortion;Remote sensing","geophysical image processing;geophysical techniques;image fusion;remote sensing","NNDiffuse transform method;fusion effect;Gram-Schmidt method;fusion processing;Gaofen-2 satellite image data;pansharpening method;suitable fusion method;fusion methods;fusion results;fusion analysis;GF-2 satellite Remote-sensed spatial data preprocessing;PCA;HPF;panchromatic data;multi spectral data;quantitative analysis;visible light band;near-infrared band","","5","","21","IEEE","14 Mar 2019","","","IEEE","IEEE Conferences"
"$M^3\text{Fusion}$: A Deep Learning Architecture for Multiscale Multimodal Multitemporal Satellite Data Fusion","P. Benedetti; D. Ienco; R. Gaetano; K. Ose; R. G. Pensa; S. Dupuy","UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; LIRMM Laboratory, Montpellier, France; UMR TETIS, University of Montpellier, AgroParisTech, CIRAD, CNRS, IRSTEA, Montpellier, France; UMR-TETIS Laboratory, IRSTEA, University of Montpellier, Montpellier, France; Department of Computer Science, University of Turin, Turin, Italy; UMR TETIS, University of Montpellier, AgroParisTech, CIRAD, CNRS, IRSTEA, Montpellier, France","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","4 Jan 2019","2018","11","12","4939","4949","Modern Earth Observation systems provide remote sensing data at different temporal and spatial resolutions. Among all the available spatial mission, today the Sentinel-2 program supplies high temporal (every five days) and high spatial resolution (HSR) (10 m) images that can be useful to monitor land cover dynamics. On the other hand, very HSR (VHSR) imagery is still essential to figure out land cover mapping characterized by fine spatial patterns. Understanding how to jointly leverage these complementary sources in an efficient way when dealing with land cover mapping is a current challenge in remote sensing. With the aim of providing land cover mapping through the fusion of multitemporal HSR and VHSR satellite images, we propose a suitable end-to-end deep learning framework, namely M3Fusion, which is able to simultaneously leverage the temporal knowledge contained in time series data as well as the fine spatial information available in VHSR images. Experiments carried out on the Reunion Island study area confirm the quality of our proposal considering both quantitative and qualitative aspects.","2151-1535","","10.1109/JSTARS.2018.2876357","Agence Nationale de la Recherche; Investments for the Future Program(grant numbers:ANR-16-CONV-0004 (DigitAg)); GEOSUD project(grant numbers:ANR-10-EQPX-20); Programme National de Télédétection Spatiale; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8516352","Data fusion;deep learning;land cover mapping;satellite image time series;sentinel-2;very high spatial resolution (VHSR)","Time series analysis;Spatial resolution;Remote sensing;Feature extraction;Satellites","geophysical image processing;image classification;image fusion;learning (artificial intelligence);remote sensing;terrain mapping;time series","Sentinel-2 program supplies high temporal;high spatial resolution images;land cover dynamics;HSR imagery;land cover mapping;fine spatial patterns;suitable end-to-end deep learning framework;temporal knowledge;time series data;fine spatial information;VHSR images;multiscale multimodal multitemporal satellite data Fusion;Modern Earth Observation systems;remote sensing data;different temporal resolutions;spatial resolutions;available spatial mission","","47","","33","IEEE","31 Oct 2018","","","IEEE","IEEE Journals"
"Multiscale Building Extraction With Refined Attention Pyramid Networks","Q. Tian; Y. Zhao; Y. Li; J. Chen; X. Chen; K. Qin","National Key Laboratory of Remote Sensing Information and Image Analysis Technology, Beijing Research Institute of Uranium Geology, Beijing, China; National Key Laboratory of Remote Sensing Information and Image Analysis Technology, Beijing Research Institute of Uranium Geology, Beijing, China; Zachry Department of Civil and Environmental Engineering, Texas A&M University, College Station, TX, USA; Iflytek Intelligent Information Technology Company, Ltd., Hefei, China; National Key Laboratory of Remote Sensing Information and Image Analysis Technology, Beijing Research Institute of Uranium Geology, Beijing, China; National Key Laboratory of Remote Sensing Information and Image Analysis Technology, Beijing Research Institute of Uranium Geology, Beijing, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","Automatic building extraction from high-resolution aerial and satellite images has many practical applications, such as urban planning and disaster management. However, the complex appearance and various scales of buildings in remote-sensing images bring a challenge for building extraction. In this study, we developed a novel multiscale building extraction method based on refined attention pyramid networks (RAPNets). We built an encoder–decoder structure, and combine atrous convolution, deformable convolution, attention mechanism, and pyramid pooling module to improve the performance of feature extraction in the encoding path. Moreover, the salient multiscale features were extracted by embedding the convolutional block attention module into the lateral connections. Finally, the refined feature pyramid structure was adopted in the decoding path to fuse the multiscale features to obtain the final extraction results. Experiments on two standard data sets (Inria aerial image labeling data set and xBD data set) show that our method achieves reliable results and outperforms the comparing methods.","1558-0571","","10.1109/LGRS.2021.3075436","National Natural Science Foundation of China(grant numbers:41602333); National Key Laboratories Stable Supporting Program of China(grant numbers:ZS1901); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9423811","Aerial image;building extraction;deep learning;refined attention pyramid networks (RAPNets);satellite image","Feature extraction;Buildings;Semantics;Data mining;Task analysis;Satellites;Data models","feature extraction;geophysical image processing;image classification;image fusion;image resolution;object detection;remote sensing","refined attention pyramid networks;automatic building extraction;high-resolution aerial;satellite images;urban planning;disaster management;remote-sensing images;multiscale building extraction method;encoder-decoder structure;atrous convolution;deformable convolution;attention mechanism;pyramid pooling module;feature extraction;salient multiscale features;convolutional block attention module;refined feature pyramid structure;final extraction results;Inria aerial image labeling data","","8","","24","IEEE","4 May 2021","","","IEEE","IEEE Journals"
"Evidential Fusion Based Technique for Detecting Landslide Barrier Lakes From Cloud-Covered Remote Sensing Images","X. Chen; J. Li; Y. Zhang; W. Jiang; L. Tao; W. Shen","State Key Laboratory of Earth Surface Processes and Resource Ecology and the Academy of Disaster Reduction and Emergency Management, Beijing Normal University, Ministry of Civil Affairs/Ministry of Education of China, Beijing, China; State Key Laboratory of Earth Surface Processes and Resource Ecology and the Academy of Disaster Reduction and Emergency Management, Beijing Normal University, Ministry of Civil Affairs/Ministry of Education of China, Beijing, China; State Key Laboratory of Earth Surface Processes and Resource Ecology and the Academy of Disaster Reduction and Emergency Management, Beijing Normal University, Ministry of Civil Affairs/Ministry of Education of China, Beijing, China; State Key Laboratory of Earth Surface Processes and Resource Ecology and the Academy of Disaster Reduction and Emergency Management, Beijing Normal University, Ministry of Civil Affairs/Ministry of Education of China, Beijing, China; State Key Laboratory of Earth Surface Processes and Resource Ecology and the Academy of Disaster Reduction and Emergency Management, Beijing Normal University, Ministry of Civil Affairs/Ministry of Education of China, Beijing, China; College of Marine Sciences, Shanghai Ocean University, Shanghai, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","20 May 2017","2017","10","5","1742","1757","Landslide barrier lakes usually form quickly after disasters and require very timely remote sensing images to monitor the land-cover change. However, cloud-free images are not always available in emergency situations. This paper provides a method to fuse multitemporal cloud-covered images for change detection, based on the evidential fusion framework. First, the frame of discernment is defined by postclassification comparison results. Second, a way of measuring the basic belief assignment (BBA) is introduced based on the confusion matrixes. Next, a simple BBA redistribution process is proposed to deal with cloud coverage problems. Then, the complementary and redundant information from the input images can be fused following the evidence combination and decision making rules in the evidential fusion framework. Finally, the land-cover change map can be derived. Thanks to the Dempster-Shafer evidence theory, the proposed method can complete the change detection process-including data fusion and cloud removal-in an integrated manner. The proposed method is applied to detect the landslide barrier lake in a real case study, using a series of cloud-covered images from the GF-1 satellite. Result comparisons show that the proposed method is more effective than some basic fusion strategies that perform change detection and cloud removal in separate steps. Then, some approaches to improve the proposed method are discussed: introducing new evidence combination rule, improving the classification accuracy, and adding new evidences. All the results indicate the potential of evidential fusion for change detection from cloud-covered images.","2151-1535","","10.1109/JSTARS.2017.2665529","National Natural Science Foundation of China(grant numbers:51379104,41571342,51579135); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7892890","Barrier lake;change detection;cloud;evidence theory;GF-1 satellite;image sequence analysis;remote sensing","Remote sensing;Lakes;Terrain factors;Earth;Decision making;Data integration;Satellites","disasters;geomorphology;geophysical image processing;image fusion;lakes;land cover;remote sensing","evidential fusion technique;landslide barrier lake detection;cloud-covered remote sensing image;disaster;land-cover change;cloud-free image;multitemporal cloud-covered image;basic belief assignment;BBA redistribution process;cloud coverage;Dempster-Shafer evidence theory;data fusion;cloud removal;GF-1 satellite;basic fusion strategy;classification accuracy","","7","","32","IEEE","5 Apr 2017","","","IEEE","IEEE Journals"
"BSSNet: Building Subclass Segmentation From Satellite Images Using Boundary Guidance and Contrastive Learning","H. Xie; X. Hu; H. Jiang; J. Zhang","School of Remote Sensing and Information Engineering, Wuhan University, Wuhan, China; Hubei Luojia Laboratory, Wuhan, China; National Geomatics Center of China, Beijing, China; Key Laboratory of Network Information System Technology, Institute of Electronic, and The Aerospace Information Research Institute, Chinese Academic of Sciences, Beijing, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","15 Sep 2022","2022","15","","7700","7711","Building subclass segmentation, aimed at predicting classes of buildings (high-rise zone, low-rise zone, single high-rise, and single low-rise) from satellite images, is beneficial in numerous applications, including human geography, urban planning, and humanitarian aid. However, problems, such as complex scenes and similar characteristics of different building categories make it difficult for general models to balance the accuracy of localization and classification in building subclass segmentation. Therefore, this article proposes a novel network for building subclass segmentation called building subclass segmentation network (BSSNet), which uses two subnetworks to divide and conquer the problem. The first network guides the building locations through binary building segmentation, called localization network. The spatial gradient fusion module in the localization network improves the binary segmentation result by supervising the spatial gradient map of prediction. The second network is a classification network, which predicts building subclasses. Intermediate features of the second network are optimized by contrastive learning loss to improve feature consistency. Finally, predictions of the two networks are combined to obtain the final result. The experimental results demonstrate that our BSSNet can perform significant improvements on the Hainan dataset we produced and the xBD dataset. In particular, the BSSNet achieves the best performance compared to current methods on the Hainan dataset.","2151-1535","","10.1109/JSTARS.2022.3202524","National Natural Science Foundation of China(grant numbers:41771363,92038301); Special Fund of Hubei Luojia Laboratory(grant numbers:220100028); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9869688","Building subclass segmentation;contrastive learning loss;convolutional neural network (CNN);feature fusion;satellite image;spatial gradient fusion (SGF)","Buildings;Image segmentation;Task analysis;Location awareness;Remote sensing;Semantics;Head","feature extraction;geography;geophysical image processing;image classification;image fusion;image segmentation;learning (artificial intelligence);town and country planning","BSSNet;satellite images;high-rise zone;single high-rise;different building categories;building subclass segmentation called building subclass segmentation network;building locations;binary building segmentation;called localization network;binary segmentation result;building subclasses","","","","57","CCBY","29 Aug 2022","","","IEEE","IEEE Journals"
"DifUnet++: A Satellite Images Change Detection Network Based on Unet++ and Differential Pyramid","X. Zhang; Y. Yue; W. Gao; S. Yun; Q. Su; H. Yin; Y. Zhang","School of Computer Science and Technology, Northwestern Polytechnical University, Xi’an, China; School of Software, Northwestern Polytechnical University, Xi’an, China; School of Software, Northwestern Polytechnical University, Xi’an, China; School of Software, Northwestern Polytechnical University, Xi’an, China; School of Computer Science and Technology, Northwestern Polytechnical University, Xi’an, China; School of Computer Science and Technology, Northwestern Polytechnical University, Xi’an, China; School of Computer Science and Technology, Northwestern Polytechnical University, Xi’an, China","IEEE Geoscience and Remote Sensing Letters","30 Dec 2021","2022","19","","1","5","Change detection (CD) is one of the most important topics in the field of remote sensing. In this letter, we propose an effective satellite images CD network named DifUnet++. As the presentation of explicit difference is more conducive to extract change features, we design a differential pyramid of two input images as the input of Unet++. Considering the scale diversity of changed regions in remote sensing images, a multiply side-outs fusion strategy is adopted to predict the detection results of different scales. Furthermore, a learning upsampling method is utilized to refine the details of CD. The proposed architecture is evaluated on two public satellite image CD data sets. The experimental results show that our method performs much better than state-of-the-art methods.","1558-0571","","10.1109/LGRS.2021.3049370","National Natural Science Foundation of China(grant numbers:61971356,61801395,61971273); National Natural Science Foundation of Shaanxi Province(grant numbers:2020GM-137); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9333611","Change detection (CD);deep learning;differential information;semantic learning","Convolution;Feature extraction;Remote sensing;Semantics;Image segmentation;Decoding;Satellites","feature extraction;geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);remote sensing;terrain mapping","scale diversity;changed regions;remote sensing images;multiply side-outs fusion strategy;public satellite image CD data sets;satellite images change detection network;effective satellite images CD network;DifUnet;explicit difference;change features;differential pyramid;input images;Unet","","11","","21","IEEE","22 Jan 2021","","","IEEE","IEEE Journals"
"S3: A Spectral-Spatial Structure Loss for Pan-Sharpening Networks","J. -S. Choi; Y. Kim; M. Kim","School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Artificial Intelligence Research Division, Korea Aerospace Research Institute, Daejeon, South Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea","IEEE Geoscience and Remote Sensing Letters","22 Apr 2020","2020","17","5","829","833","Recently, many deep-learning-based pan-sharpening methods have been proposed for generating high-quality pan-sharpened (PS) satellite images. These methods focused on various types of convolutional neural network (CNN) structures, which were trained by simply minimizing a spectral loss between network outputs and the corresponding high-resolution (HR) multi-spectral (MS) target images. However, owing to different sensor characteristics and acquisition times, HR panchromatic (PAN) and low-resolution MS image pairs tend to have large pixel misalignments, especially for moving objects in the images. Conventional CNNs trained with only the spectral loss with these satellite image data sets often produce PS images of low visual quality including double-edge artifacts along strong edges and ghosting artifacts on moving objects. In this letter, we propose a novel loss function, called a spectral-spatial structure (S3) loss, based on the correlation maps between MS targets and PAN inputs. Our proposed S3 loss can be very effectively used for pan-sharpening with various types of CNN structures, resulting in significant visual improvements on PS images with suppressed artifacts.","1558-0571","","10.1109/LGRS.2019.2934493","National Research Foundation of Korea (NRF); Ministry of Science, ICT and Future Planning through the Basic Science Research Program(grant numbers:2017R1A2A2A05001476); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812763","Convolutional neural network (CNN);deep learning;pan colorization;pan-sharpening;satellite imagery;spectral-spatial structure;super-resolution (SR)","Training;Satellites;Correlation;Spatial resolution;Visualization;Convolutional neural networks","convolutional neural nets;geophysical image processing;image classification;image fusion;image resolution;learning (artificial intelligence);remote sensing","spectral-spatial structure loss;MS targets;PAN inputs;CNN structures;PS images;deep-learning-based pan-sharpening methods;high-quality pan-sharpened satellite images;convolutional neural network structures;spectral loss;network outputs;multispectral target images;HR panchromatic;moving objects;satellite image data sets;double-edge artifacts;strong edges;ghosting artifacts;loss function","","11","","32","IEEE","26 Aug 2019","","","IEEE","IEEE Journals"
"Soil organic matter estimation by using Landsat-8 pansharpened image and machine learning","A. Bouasria; K. I. Namr; A. Rahimi; E. M. Ettachfini","Department of Geology, Faculty of Sciences, Chouaib Doukkali University, El Jadida, Morocco; Department of Geology, Faculty of Sciences, Chouaib Doukkali University, El Jadida, Morocco; Department of Geology, Faculty of Sciences, Chouaib Doukkali University, El Jadida, Morocco; Department of Geology, Faculty of Sciences, Chouaib Doukkali University, El Jadida, Morocco","2020 Fourth International Conference On Intelligent Computing in Data Sciences (ICDS)","30 Nov 2020","2020","","","1","8","Considering the significant position of soil organic matter (SOM) in soil quality and maintenance, and its role in the functioning of soil physicochemical and biological processes, it is essential to monitor frequently the SOM status and its dynamics. It is a time-consuming and expensive task if we depend exclusively on chemical analysis, particularly in a semi-arid irrigated zone and with intensive agricultural activities and a very fragmented landscape. It is the Sidi Bennour region, which is situated in Doukkala Irrigated Perimeter in Morocco. Data from satellites could be a good alternative to conventional methods and fill this void with low costs. There has been a great deal of interest in satellite image prediction models, especially with free and abundant availability of satellite data. This work intends to predict SOM using Decision Trees (DT), k-Nearest Neighbors (k-NN), and Artificial Neural Networks (ANN). The soil samples (369 points) were collected at 0-30 cm of depth and the laboratory analysis was carried out. A multispectral Landsat-8 image was acquired and then calibrated. An image pansharpening processing was applied to produce a PAN image with 15m of resolution from 30m image resolution (MS). The obtained results indicate that the ANN model outperformed the other predictive models for both images (MS and PAN) with R2= 0.6553 and R2=0.6985, respectively. The statistical RMSE of predictive models was 0.2153 and 0.2014, and MAE was 0.1682 and 0.1573 for both images, MS and PAN respectively. For this predictive model, the image pansharpening could increase the prediction accuracy of R2 by 4.32%and reduce the RMSE by 1.39%.","","978-1-7281-8084-7","10.1109/ICDS50568.2020.9268725","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268725","Soil organic matter;digital soil mapping;remote sensing;machine learning;neural networks","Soil;Predictive models;Artificial neural networks;Remote sensing;Neurons;Data models;Earth","agriculture;decision trees;geophysical image processing;geophysical techniques;image fusion;image resolution;irrigation;learning (artificial intelligence);neural nets;remote sensing;soil","Artificial Neural Networks;soil samples;laboratory analysis;multispectral Landsat-8 image;image pansharpening processing;PAN image;image resolution;ANN model;predictive model;prediction accuracy;soil organic matter estimation;soil quality;biological processes;SOM status;expensive task;chemical analysis;semiarid irrigated zone;intensive agricultural activities;fragmented landscape;Sidi Bennour region;Doukkala Irrigated Perimeter;satellite image prediction models;free availability;abundant availability;satellite data;Landsat-8 pansharpened image;Decision Trees;k-Nearest Neighbors;statistical RMSE","","10","","58","IEEE","30 Nov 2020","","","IEEE","IEEE Conferences"
"SDBF-Net: Semantic and Disparity Bidirectional Fusion Network for 3D Semantic Detection on Incidental Satellite Images","Z. Rao; M. He; Z. Zhu; Y. Dai; R. He","Northwestern Polytechnical University, Xian, China; Northwestern Polytechnical University, Xian, China; Northwestern Polytechnical University, Xian, China; Northwestern Polytechnical University, Xian, China; Nanyang Technological University, Singapore","2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","5 Mar 2020","2019","","","438","444","In this paper, we propose a conceptually simple, flexible, and general framework for the semantic stereo task on incidental satellite images. Our method efficiently detects the objects in an incidental satellite image for generating a high-quality segmentation map, and more accurately match the left-right incidental satellite images for obtaining a more accurate disparity map at the same time. The method, called semantic and disparity bidirectional fusion network (SDBF-Net), consists of three main modules: the Semantic Segmentation Module (SSM), the Stereo Matching Module (SMM), and the Fusion Module (FM). The semantic segmentation module takes advantage of the capacity of global context information by extending the receptive field to produce the initial segmentation map. The stereo matching module applies the 3D convolutional operation to regularize the feature map of left-right images to generate the initial disparity map. The fusion module fuses the initial segmentation and disparity map to obtain the refined segmentation and disparity map. Extensive quantitative and qualitative evaluations on the US3D dataset demonstrate the superiority of our proposed SDBF-Net approach, which outperforms state-of-the-art semantic stereo approaches significantly.","2640-0103","978-1-7281-3248-8","10.1109/APSIPAASC47483.2019.9023223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023223","","Semantics;Feature extraction;Image segmentation;Three-dimensional displays;Satellites;Task analysis;Two dimensional displays","computational geometry;convolutional neural nets;feature extraction;geophysical image processing;image fusion;image matching;image segmentation;object detection;stereo image processing","stereo matching module;semantic segmentation module;initial segmentation map;left-right images;fusion module;refined segmentation;3D semantic detection;incidental satellite image;flexible framework;semantic stereo task;high-quality segmentation map;disparity map;semantic and disparity bidirectional fusion network;SDBF-Net;receptive field;3D convolutional operation;feature map regularization","","3","","37","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"Fishing forecasting system in Adriatic sea — A model approach based on a normalized scalar product of the SST gradient and CHL gradient vectors","K. Tijani; M. T. Chiaradia; A. Morea; R. Nutricato; L. Guerriero; G. Pasquariello","Politecnico di Bari, Bari, Puglia, IT; Politecnico di Bari, Bari, Puglia, IT; Politecnico di Bari, Bari, Puglia, IT; Geophysical Applications Processing, GAP srl, Bari, Italy; Politecnico di Bari, Bari, Puglia, IT; Consiglio Nazionale delle Ricerche, Roma, Lazio, IT","2015 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","12 Nov 2015","2015","","","2257","2260","By mapping the concentration of chlorophyll-a (CHL) and the temperature of the sea surface (SST), satellite images reveal the complex dynamics of marine waters and prove to be a very powerful tool when used to detect potential fishing areas, significantly reducing the time of the search, the fuel consumption and the human effort, and simultaneously increasing the CPUE (catch per unit effort). In the present work, various techniques of multi-sensor, multi-resolution and multi-temporal data fusion are applied to multi-spectral satellite image data of MODIS-AQUA, MODIS-TERRA and VIIRS sensors, in order to detect ""fronts"" of chlorophyll concentration and temperature on the sea surface. According to the physical model of the phenomena, these fronts are generated by the upwelling of cold waters rich of nutrients (phytoplankton) which correspond to areas with a high concentration of pelagic fish and are characterized by high values of local gradients of SST and CHL with anti-parallel orientation. An automatic procedure has been developed to calibrate and validate the production in near-real time of daily maps of expected good fishing grounds to be provided to the FEDERPESCA fleet. The same procedure could be optimized also for other seas.","2153-7003","978-1-4799-7929-5","10.1109/IGARSS.2015.7326256","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7326256","Potential Fishing Zones (PFZ);Upwelling;Ocean Color Analysis;Multi-sensor data fusion","Ocean temperature;MODIS;Sea surface;Forecasting;Satellites;Data integration","geophysical image processing;gradient methods;image fusion;microorganisms;ocean temperature;oceanographic regions;oceanographic techniques;remote sensing by radar;seawater;sensor fusion","fishing forecasting system;Adriatic sea;normalized scalar product;SST gradient vector;CHL gradient vector;chlorophyll-a concentration;surface temperature;marine water;complex dynamics;potential fishing area;CPUE;multitemporal data fusion;MODIS-TERRA sensor;MODIS-AQUA sensor;VIIRS sensor;sea water upwelling;phytoplankton;antiparallel orientation;near-real daily map time production;FEDERPESCA;high pelagic fish concentration;fishing grounds","","4","","9","IEEE","12 Nov 2015","","","IEEE","IEEE Conferences"
"Multi-image saliency analysis via histogram and spectral feature clustering for satellite images","L. Zhang; Q. Sun; J. Chen","College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China; College of Information Science and Technology, Beijing Normal University, Beijing, China","2016 IEEE International Conference on Image Processing (ICIP)","19 Aug 2016","2016","","","2802","2806","Saliency analysis is an effective method to extract interesting target regions from satellite images. However, when the satellite image contains salient background information, it is difficult to eliminate this information accurately only using single image saliency analysis. In this paper, a novel multiimage saliency analysis (MSA) model based on multiple multispectral images clustering saliency analysis (MMCS) and panchromatic image co-occurrence histogram saliency analysis (PCHS) is proposed. We obtain the MMCS maps based on contrast principle, while effectively depressing the background information that is salient only within its own image. PCHS maps are obtained by co-occurrence histogram of panchromatic images that aims to enhance the saliency of target regions. Finally, multi-image saliency maps are computed by a novel fusion strategy, which can depress the background information and highlight the target regions. Experimental results show that the MSA model outperforms other state-of-art saliency analysis methods.","2381-8549","978-1-4673-9961-6","10.1109/ICIP.2016.7532870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7532870","Image processing;saliency;clustering","Histograms","artificial satellites;feature extraction;geophysical image processing;image fusion;pattern clustering;spectral analysis","fusion strategy;co-occurrence histogram;PCHS maps;contrast principle;MMCS maps;co-occurrence histogram saliency analysis;multiple multispectral image clustering saliency analysis;MSA model;multiimage saliency analysis;background information;target region extraction;satellite images;spectral feature clustering;histogram feature clustering","","1","","19","IEEE","19 Aug 2016","","","IEEE","IEEE Conferences"
"Fusion of Satellite Images and Weather Data With Transformer Networks for Downy Mildew Disease Detection","W. Maillet; M. Ouhami; A. Hafiane","PRISME Laboratory, INSA CVL, University of Orléans, Bourges, France; PRISME Laboratory, INSA CVL, University of Orléans, Bourges, France; PRISME Laboratory, INSA CVL, University of Orléans, Bourges, France","IEEE Access","20 Jan 2023","2023","11","","5406","5416","Crop diseases significantly affect the quantity and quality of agricultural production. In a context where the goal of precision agriculture is to minimize or even avoid the use of pesticides, weather and remote sensing data with deep learning can play a pivotal role in detecting crop diseases, allowing localized treatment of crops. However, combining heterogeneous data such as weather and images remains a hot topic and challenging task. Recent developments in transformer architectures have shown the possibility of fusion of data from different domains, such as text-image. The current trend is to custom only one transformer to create a multimodal fusion model. Conversely, we propose a new approach to realize data fusion using three transformers. In this paper, we first solved the missing satellite images problem, by interpolating them with a ConvLSTM model. Then, we proposed a multimodal fusion architecture that jointly learns to process visual and weather information. The architecture is built from three main components, a Vision Transformer and two transformer-encoders, allowing to fuse both image and weather modalities. The results of the proposed method are promising achieving an overall accuracy of 97%.","2169-3536","","10.1109/ACCESS.2023.3237082","European Consortium ERA-NET ICT-AGRI-FOOD; French National Research Agency (ANR)(grant numbers:ANR-21-ICAF-0002-01); European Project MERIAVINO; ICT-AGRIFOOD ERA-NET; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10017285","Remote sensing;image processing;deep learning;data fusion;vegetation indices;crop monitoring;agriculture","Transformers;Meteorology;Satellites;Feature extraction;Diseases;Crops;Computer architecture;Vegetation mapping;Indexes;Deep learning;Remote sensing","deep learning (artificial intelligence);diseases;geophysical image processing;image fusion;interpolation;recurrent neural nets","agricultural production;ConvLSTM model;crop diseases;deep learning;downy mildew disease detection;missing satellite image problem;multimodal data fusion model;multimodal fusion architecture;remote sensing data;text-imaging;transformer-encoder network architectures;vision transformer networks;weather data modalities","","","","49","CCBY","16 Jan 2023","","","IEEE","IEEE Journals"
"Information Fusion for Urban Road Extraction From VHR Optical Satellite Images","Z. Miao; W. Shi; A. Samat; G. Lisini; P. Gamba","Department of Land Surveying and Geo-Informatics, Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Land Surveying and Geo-Informatics, Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Geographic Information Science, Nanjing University, Nanjing, China; Department of Industrial and Information Engineering, University of Pavia, Pavia, Italy; Department of Industrial and Information Engineering, University of Pavia, Pavia, Italy","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","19 May 2017","2016","9","5","1817","1829","This paper presents a novel method exploiting fusion at the information level for urban road extraction from very high resolution (VHR) optical satellite images. Given a satellite image, we explore spectral and shape features computed at the pixel level, and use them to select road segments using two different methods (i.e., expectation maximization clustering and linearness filtering). A road centerline extraction method, which is relying on the outlier robust regression, is subsequently applied to extract accurate centerlines from road segments. After that, three different sets of information fusion rules are applied to jointly exploit results from these methods, which offer ways to address their own limitations. Two VHR optical satellite images are used to validate the proposed method. Quantitative results prove that information fusion following centerline extraction by multiple techniques is able to produce the best accuracy values for automatic urban road extraction from VHR optical satellite images.","2151-1535","","10.1109/JSTARS.2015.2498663","National Natural Science Foundation of China(grant numbers:41201451,40901214); Ministry of Science and Technology of China(grant numbers:2012BAJ15B04,2012AA12A305); National Administration of Surveying, Mapping, and Geoinformation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337372","Centerline;expectation maximization (EM);information fusion;linearness filter;RANdom SAmple Consensus (RANSAC);Centerline;expectation maximization (EM);information fusion;linearness filter;RANdom SAmple Consensus (RANSAC)","Roads;Feature extraction;Satellites;Data mining;Optical imaging;Image segmentation;Active contours","feature extraction;geophysical image processing;geophysical techniques;image fusion","information fusion;VHR optical satellite images;pixel level;road segments;road centerline extraction method;outlier robust regression;automatic urban road extraction","","18","","75","IEEE","25 Nov 2015","","","IEEE","IEEE Journals"
