"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"Synthetic Aperture Radar Image Synthesis by Using Generative Adversarial Nets","J. Guo; B. Lei; C. Ding; Y. Zhang","School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China; School of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences, Beijing, China","IEEE Geoscience and Remote Sensing Letters","22 Jun 2017","2017","14","7","1111","1115","Synthetic aperture radar (SAR) image simulators based on computer-aided drawing models play an important role in SAR applications, such as automatic target recognition and image interpretation. However, the accuracy of such simulators is due to geometric error and simplification in the electromagnetic calculation. In this letter, an end-to-end model was developed that could directly synthesize the desired images from the known image database. The model was based on generative adversarial nets (GANs), and its feasibility was validated by comparisons with real images and ray-tracing results. As a further step, the samples were synthesized at angles outside of the data set. However, the training process of GAN models was difficult, especially for SAR images which are usually affected by noise interference. The major failure modes were analyzed in experiments, and a clutter normalization method was proposed to ameliorate them. The results showed that the method improved the speed of convergence up to 10 times. The quality of the synthesized images was also improved.","1558-0571","","10.1109/LGRS.2017.2699196","National Natural Science Foundation of China(grant numbers:61331017); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927706","Generative adversarial nets (GANs);SAR image simulator;SAR interpretation;synthetic aperture radar (SAR)","Training;Synthetic aperture radar;Clutter;Gallium nitride;Solid modeling;Ray tracing;Biological system modeling","learning (artificial intelligence);radar clutter;radar computing;radar imaging;synthetic aperture radar","synthetic aperture radar image synthesis;generative adversarial nets;SAR image simulators;computer-aided drawing models;geometric error;electromagnetic calculation;end-to-end model;image database;GAN model training process;noise interference;failure modes;clutter normalization method;synthesized image quality","","63","1","10","IEEE","15 May 2017","","","IEEE","IEEE Journals"
"Potential of the Reverse Synthesis Method for the High-Quality SAR Image Synthesis","E. Shiro","Independent researcher, Toronto, Canada","IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium","4 Nov 2018","2018","","","8905","8908","A potential of a new Reverse synthesis method proposed at IGARSS 2017 for the high-quality Synthetic Aperture Radar (SAR) image synthesis is presented. Images produced by the method are compared with the best existing approaches for the speckle noise reduction. Further capabilities for the image quality improvement like side lobe, range and azimuth reduction, contrast improvement, autofocusing and target detectability improvement are considered. The novel approach allows both: to produce high quality and high-resolution images from existing SAR raw data and to create new high-quality systems with reduced demands to the on-board equipment.","2153-7003","978-1-5386-7150-4","10.1109/IGARSS.2018.8518457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8518457","high resolution;image quality;image synthesis;SAR;speckle noise;synthetic aperture imaging;synthetic aperture radar","Speckle;Image resolution;Synthetic aperture radar;Buildings;Automobiles;Image generation;Image edge detection","image denoising;radar imaging;speckle;synthetic aperture radar","high-quality synthetic aperture radar image synthesis;side lobe;range-and-azimuth reduction;high-quality systems;SAR raw data;high-resolution images;target detectability improvement;autofocusing;contrast improvement;image quality improvement;speckle noise reduction;IGARSS 2017;high-quality SAR image synthesis;reverse synthesis method","","","","5","IEEE","4 Nov 2018","","","IEEE","IEEE Conferences"
"SAR image synthesis with chirp scaling algorithm of 3D CAD model using EM simulator","S. Kim; J. Yu; M. -H. Ka","School of Integrated Technology, Yonsei University, Seoul, South Korea; School of Integrated Technology, Yonsei University, Seoul, South Korea; School of Integrated Technology, Yonsei University, Seoul, South Korea","2015 IEEE 5th Asia-Pacific Conference on Synthetic Aperture Radar (APSAR)","29 Oct 2015","2015","","","72","75","In this paper, we describe a simple method for SAR image synthesis of a realistic target model using the general purpose EM simulator like FEKO and demonstrate the steps by processing the simulated SAR raw data with chirp-scaling algorithm (CSA), which is one of the most widely used SAR image formation algorithms. This method can benefit us many advantages like performance evaluation for target detection, estimation and target recognition with realistic target model in a cost-and-time effective way.","","978-1-4673-7297-8","10.1109/APSAR.2015.7306157","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7306157","Synthetic Aperture Radar;Electro-Magnetic Simulation;Chirp-Scaling Algorithm","Decision support systems;Conferences;Apertures;Yttrium","CAD;object detection;radar detection;radar imaging;radar target recognition;synthetic aperture radar","synthetic aperture radar;SAR image synthesis;chirp scaling algorithm;3D CAD model;EM simulator;target model;FEKO;SAR image formation algorithms;target detection;target recognition","","","","14","IEEE","29 Oct 2015","","","IEEE","IEEE Conferences"
"High Resolution SAR Image Synthesis with Hierarchical Generative Adversarial Networks","H. Huang; F. Zhang; Y. Zhou; Q. Yin; W. Hu","College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, P.R. China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, P.R. China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, P.R. China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, P.R. China; College of Information Science and Technology, Beijing University of Chemical Technology, Beijing, P.R. China","IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium","14 Nov 2019","2019","","","2782","2785","Generative adversarial network (GAN) is an artificial neural network based on unsupervised learning method. Due to its powerful model representation capabilities, GAN has been introduced to synthesize synthetic aperture radar (SAR) image data, for the real sample is difficult to acquire. Large-scale, high-resolution SAR images play an important role in promoting SAR applications, such as automatic target recognition and image interpretation. However, on account of the difficult training problem of GAN network, especially for SAR images with speckle noise, it is difficult to obtain high-resolution SAR images by simply transfer the net from optical image. Recent studies in other image fields have shown that hierarchical structure is an effective and useful way to decompose a generation task into several smaller subtasks. How to obtain more high-resolution SAR images from limited original samples through GAN is the target of our research. Therefore, in this paper, we introduce a hierarchical GAN network model to generate SAR images, through the multi-stage network, gradually improve the quality of the generated image, and finally obtain high-resolution images. The type and aspect of generated images are determined by the input of condition vectors in the last two stages. In addition, we introduce the triple loss, in which the background loss is used to imitating background clutter noise of SAR image, the condition loss is to make the generated images' type and aspect become controllable, and the global loss for getting higher image generation quality. The generated images show high similarity with the real samples.","2153-7003","978-1-5386-9154-0","10.1109/IGARSS.2019.8900494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8900494","Generative adversarial network(GAN);synthetic aperture radar (SAR);SAR simulator;automatic target recognition (ATR);triple loss","Generative adversarial networks;Radar polarimetry;Gallium nitride;Image resolution;Synthetic aperture radar;Solid modeling;Data models","image resolution;neural nets;radar imaging;synthetic aperture radar;unsupervised learning","high resolution SAR image synthesis;hierarchical generative adversarial networks;generative adversarial network;artificial neural network;synthetic aperture radar image data;high-resolution SAR images;SAR applications;automatic target recognition;image interpretation;optical image;image fields;hierarchical GAN network model;high-resolution images;generated images;image generation quality;unsupervised learning method","","10","","8","IEEE","14 Nov 2019","","","IEEE","IEEE Conferences"
"Study on jamming method of inverse synthetic aperture radar based on three platform","M. Guo; H. Zhu; N. Tai; C. Wang; N. Yuan","National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China; National University of Defense Technology, Changsha, China","2016 IEEE Information Technology, Networking, Electronic and Automation Control Conference","5 Sep 2016","2016","","","652","655","Based on the basic principle of the multiply modulation jamming of synthetic aperture radar (SAR), a new jamming method of inverse synthetic aperture radar (ISAR) based on three platform is proposed: at first, it needs to choose an image template which is used to do 2D-FFT and compensation to generate jamming template; In order to get jamming data which need to compute the sampling interval and sample the jamming template; at last, the jamming data multiply the intercept signal to send out. The false target is created to provide an effective protection for a certain target send the result out. This method can achieve single or multiple false targets, and false targets can be adjusted according to the size, number and flight attitude of the ideal targets template. Simulation results demonstrate the effectiveness of this method. Because of the first step is independent and doesn't need any parameters of enemy ISAR system, which can be calculated in advance, comparing with the methods digital image synthesis, this method has less computational complexity.","","978-1-4673-9194-8","10.1109/ITNEC.2016.7560441","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7560441","three platform;ISAR jamming;single or multiple false target;multiply modulation","Jamming;Image resolution;Imaging;Simulation;Inverse synthetic aperture radar;Modulation","fast Fourier transforms;jamming;radar imaging;synthetic aperture radar","inverse synthetic aperture radar;ISAR;basic multiply modulation jamming principle;image template;2D-FFT;jamming template generation;jamming data;sampling interval computation;flight attitude","","","","6","IEEE","5 Sep 2016","","","IEEE","IEEE Conferences"
"LDGAN: A Synthetic Aperture Radar Image Generation Method for Automatic Target Recognition","C. Cao; Z. Cao; Z. Cui","School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Information Geoscience, UESTC, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Transactions on Geoscience and Remote Sensing","22 Apr 2020","2020","58","5","3495","3508","Under the framework of a supervised learning-based automatic target recognition (ATR) approach, recognition performance is primarily dependent on the amount of training samples. However, shortage in training samples is a consistent issue for ATR. In this article, we propose a new image to image generation method, called label-directed generative adversarial networks (LDGANs), which will provide labeled samples to be used for recognition model training. We define an entirely new loss function for the LDGAN, which utilizes the Wasserstein distance to replace the original distance measurement of the conventional generative adversarial networks (GANs), thus efficiently avoiding the collapse mode problem. The label information is also added to the loss function of the LDGAN to avoid generating a large number of unlabeled target images. More importantly, the proposed method also makes corresponding changes to the network architecture regarding the new GANs. At the same time, the detailed algorithm about the LDGAN is also introduced in this article to deal with the issue that characteristically GANs are not easy to train. Based on comparisons with other directed generation methods, the experimental results show comparative results of several types of generated images in statistical features, gradient features, classic features of synthetic aperture radar (SAR) targets and the independence from the real image. While demonstrating that the images generated by the LDGAN produced better results using the assumptions of independent and identical distribution, the experiment also explores the performance of the generated image in the ATR. A comparison of these experimental results demonstrates a better way to use the generated image for ATR. The experimental results also prove that the proposed method does have the ability to supplement information for ATR when the training sample information is insufficient.","1558-0644","","10.1109/TGRS.2019.2957453","National Natural Science Foundation of China(grant numbers:61801098); Fundamental Research Funds for the Central Universities(grant numbers:2672018ZYGX2018J013); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938701","Automatic target recognition (ATR);information supplement;label-directed generative adversarial network (LDGAN);synthetic aperture radar (SAR) image","Gallium nitride;Radar polarimetry;Image recognition;Synthetic aperture radar;Target recognition;Training;Image synthesis","feature extraction;learning (artificial intelligence);neural nets;radar computing;radar imaging;radar target recognition;synthetic aperture radar","label-directed generative adversarial networks;supervised learning-based automatic target recognition approach;synthetic aperture radar image generation method;training sample information;synthetic aperture radar targets;directed generation methods;unlabeled target images;label information;GAN;conventional generative adversarial networks;loss function;recognition model training;labeled samples;LDGAN;training samples;recognition performance;ATR","","22","","32","IEEE","23 Dec 2019","","","IEEE","IEEE Journals"
"ArcSAR: Theory, Simulations, and Experimental Verification","M. Pieraccini; L. Miccinesi","Department of Information Engineering, University of Florence, Florence, Italy; Department of Information Engineering, University of Florence, Florence, Italy","IEEE Transactions on Microwave Theory and Techniques","26 Jan 2017","2017","65","1","293","301","ArcSAR is a ground-based synthetic aperture radar (GBSAR) that has recently been receiving increasing interest in the scientific literature. While the conventional GBSAR exploits the movement of an antenna along a linear rail to synthesize a large aperture, an ArcSAR exploits the spatial diversity of the data acquired by an antenna fixed to a rotating arm. The great advantage of ArcSAR is its capability to synthesize images at 360° with a constant resolution in azimuth. In this paper, the authors propose and test a new focusing algorithm that does not require to operate in the far field and neither with narrow beam antennas; moreover, it is flexible enough to focus on any plane (not necessarily on the rotation plane) as well as in the whole 3-D space. Furthermore, the authors demonstrate theoretically and experimentally that ArcSAR images can be affected by a “defocusing effect” of the targets far from the rotation plane, which has to be taken into consideration when designing such radars.","1557-9670","","10.1109/TMTT.2016.2613926","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7588999","Ground-based synthetic aperture radar (GBSAR);radar;remote sensing;synthetic aperture radar (SAR)","Synthetic aperture radar;Spaceborne radar;Radar antennas;Apertures;Radar imaging","radar imaging;synthetic aperture radar","ground-based synthetic aperture radar;antenna movement;linear rail;spatial diversity;image synthesis;3D space;ArcSAR images;defocusing effect","","43","","23","IEEE","12 Oct 2016","","","IEEE","IEEE Journals"
"Exploring the Potential of Unsupervised Image Synthesis for SAR-Optical Image Matching","W. -L. Du; Y. Zhou; J. Zhao; X. Tian; Z. Yang; F. Bian","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; Engineering Research Center of Mine Digitization, Ministry of Education of the People's Republic of China, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; State Key Laboratory of Lunar and Planetary Sciences, Macau University of Science and Technology, Taipa, Macau; DFH Satellite Company Ltd., Beijing, China; DFH Satellite Company Ltd., Beijing, China","IEEE Access","18 May 2021","2021","9","","71022","71033","We consider SAR-optical image matching problems, where correspondences are acquired from a pair of SAR and optical images. Recent methods for such a problem typically simplify the SAR-optical image matching to the SAR-SAR or optical-optical image matchings using supervised-image-synthesis methods. However, training supervised-image-synthesis needs plenty of aligned SAR-optical image pairs while gathering sufficient amounts of aligned multi-modal image pairs is challenging in remote sensing. In this work, we investigate the applicability of unsupervised-image-synthesis for SAR-optical image matching such that the unaligned SAR-optical images could be used. To this end, we apply feature matching loss to a well known unsupervised-image-synthesis method, i.e., CycleGAN, to enforce the feature matching consistency. Moreover, we develop a shared-matching-strategy to improve the results of SAR-optical image matching further. Qualitative comparisons against CycleGAN, StarGAN, and DualGAN demonstrate the superiority of our approach. Quantitative results show that, compared with CycleGAN, StarGAN, and DualGAN, our method obtains at least 2.6 times more qualified SAR-optical matchings.","2169-3536","","10.1109/ACCESS.2021.3079327","National Natural Science Foundation of China(grant numbers:62002360,61806206,61772530); opening fund of State Key Laboratory of Lunar and Planetary Sciences, Macau University of Science and Technology (Macau FDCT)(grant numbers:119/2017/A3); Science and Technology Development Fund of Macau(grant numbers:0038/2020/A1); Fundamental Research Funds for the Central Universities(grant numbers:2020ZDPY0305); Natural Science Foundation of Jiangsu Province(grant numbers:BK20201346,BK20180639); Six Talent Peaks Project in Jiangsu Province(grant numbers:2015-DZXX-010,2018-XYDXX-044); China Postdoctoral Science Foundation(grant numbers:2020M681765); Jiangsu Province Postdoctoral Research Foundation(grant numbers:2020Z178); Xuzhou Science and Technology Program(grant numbers:KC18061); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9427486","Image matching;unsupervised-image-synthesis;synthetic aperture radar (SAR);generative adversarial networks (GANs)","Optical imaging;Image matching;Adaptive optics;Optical sensors;Radar polarimetry;Nonlinear optics;Image synthesis","geophysical image processing;image matching;image registration;optical images;radar imaging;remote sensing;synthetic aperture radar","unsupervised image synthesis;SAR-optical image matching problems;SAR-SAR;optical-optical image matchings;supervised-image-synthesis methods;training supervised-image-synthesis;aligned SAR-optical image pairs;aligned multimodal image pairs;unaligned SAR-optical images;known unsupervised-image-synthesis method;2.6 times more qualified SAR-optical matchings","","5","","57","CCBY","11 May 2021","","","IEEE","IEEE Journals"
"An Enhanced Probabilistic Posterior Sampling Approach for Synthesizing SAR Imagery With Sea Ice and Oil Spills","L. Xu; A. Wong; D. A. Clausi","School of Land Science and Technology, China University of Geosciences, Beijing, China; Systems Design Engineering Department, University of Waterloo, Waterloo, ON, Canada; Systems Design Engineering Department, University of Waterloo, Waterloo, ON, Canada","IEEE Geoscience and Remote Sensing Letters","19 May 2017","2017","14","2","188","192","Although the synthesis of the synthetic aperture radar (SAR) imagery with both sea ice and oil spills can significantly benefit in improving the consistency and comprehensiveness of testing and evaluating algorithms that are designed for mapping cold ocean regions, creating such imagery is difficult due to the heterogeneity and complexity of the source images. This letter presents an enhanced region-based probabilistic posterior sampling approach to effectively synthesize SAR imagery with different ocean features. In the proposed approach, instead of relying entirely on the SAR intensity values, the posterior sampling is performed based on a number of quantitative factors, such as intensity, label field, and the prior class probability of sampling candidates, constituting a complete probabilistic framework that addresses key aspects in the synthesis of SAR imagery from heterogeneous sources. The experiments demonstrate that the proposed approach can better address the difficulties caused by the heterogeneity in the source images compared with the existing state-of-the-art ice synthesis method, and it will improve the consistency, comprehensiveness, and fairness of the evaluation of the remote sensing classification and segmentation algorithms.","1558-0571","","10.1109/LGRS.2016.2633572","Natural Sciences and Engineering Research Council of Canada; ArcticNet; National Natural Science Foundation of China(grant numbers:41501410); Canada Research Chairs Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7797259","Image synthesis;oil spills;sea ice;statistical texture modeling","Synthetic aperture radar;Oils;Sea ice;Probabilistic logic;Image segmentation;Image generation","image sampling;marine pollution;oil pollution;pollution measurement;radar imaging;sea ice;synthetic aperture radar","enhanced probabilistic posterior sampling;SAR imagery synthesis;sea ice;oil spills;synthetic aperture radar;ocean features;source images","","3","","13","IEEE","23 Dec 2016","","","IEEE","IEEE Journals"
"Generation of SAR Images with Features for Target Recognition","G. Peng; M. Liu; S. Chen; Y. Li; F. Lu","School of Computer Science, Shaanxi Normal University, Xi’an, China; School of Computer Science, Shaanxi Normal University, Xi’an, China; Xi’an Modern Control Technology Research Institute, China, Xi’an, China; North Automatic Control Technology Institute, Taiyuan, China; Xi’an Modern Control Technology Research Institute, China, Xi’an, China","2022 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC)","23 Dec 2022","2022","","","1","4","Since it is difficult to obtain a large number of the real samples of SAR images, the accuracy of synthetic aperture radar automatic target recognition (SAR-ATR) based on deep learning is often affected by the lack of real samples. Generative adversarial network (GAN) is a method that can effectively generate samples to expand dataset. This paper proposes a GAN that adds a condition to guide image generation and modifies the true and false discriminator to a discriminator with classification (DwC). In addition to correctly recognize the real SAR images, DwC recognizes the generated images as the class N + 1. In order to make the generated images recognized as the real images by DwC, the conditional generator gradually learns to generate the images with features of a specific category. Applying the SAR images generated by our model to target recognition based on deep learning can effectively improve the accuracy.","","978-1-6654-6972-2","10.1109/ICSPCC55723.2022.9984374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9984374","synthetic aperture radar automatic target recognition (SAR-ATR);generation adversarial network (GAN);discriminator with classification (DwC)","Deep learning;Image recognition;Target recognition;Image synthesis;Signal processing;Generative adversarial networks;Radar polarimetry","image recognition;learning (artificial intelligence);radar imaging;radar target recognition;synthetic aperture radar","conditional generator;deep learning;DwC;generative adversarial network;image generation;SAR images;SAR-ATR;synthetic aperture radar automatic target recognition","","","","9","IEEE","23 Dec 2022","","","IEEE","IEEE Conferences"
"Numerical method for fourier transform of support function of SAR azimuth synthesis","Y. M. Meleshin; M. S. Khasanov; D. V. Prikhodko; V. I. Oreshkin","National Research University of Electronic Technology, Moscow, Russian Federation; National Research University of Electronic Technology, Moscow, Russian Federation; National Research University of Electronic Technology, Moscow, Russian Federation; National Research University of Electronic Technology, Moscow, Russian Federation","2017 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus)","27 Apr 2017","2017","","","1267","1269","For a radar image synthesis obtained from synthetic aperture radar it's necessary to use its own support function (matched filter impulse response) for each range line. Fourier transform of the support function takes near a third of all computations, in case of range migration - substantially more. At the same time, the support function for any distance may be obtained by simple stretching and compression of the source function. These operations, according to the properties of Fourier transform, correspond to compression and stretching respectively in Fourier transform of function. In this work the numerical algorithm for Fourier transform of support function with O(N) complexity is considered.","","978-1-5090-4865-6","10.1109/EIConRus.2017.7910796","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7910796","SAR;matched filter impulse response;azimuth synthesis kernel;chirp;LFM","Interpolation;Fourier transforms;Chirp;Synthetic aperture radar;Azimuth;Antenna radiation patterns","computational complexity;data compression;Fourier transforms;image coding;radar imaging;synthetic aperture radar","SAR azimuth synthesis support function Fourier transform;numerical method;radar image synthesis;synthetic aperture radar;range migration;source function compression;source function stretching;O(N) complexity","","5","","5","IEEE","27 Apr 2017","","","IEEE","IEEE Conferences"
"An Inverse Synthetic Aperture Radar Image Modulation Method Based on Coding Phase-Switched Screen","J. Wang; D. Feng; R. Zhang; L. Xu; W. Hu","State Key Laboratory of Complex Electromagnetic Environmental Effects on Electronics and Information System, National University of Defense Technology, Changsha, China; State Key Laboratory of Complex Electromagnetic Environmental Effects on Electronics and Information System, National University of Defense Technology, Changsha, China; National Key Laboratory of Science and Technology on Test Physics and Numerical Mathematics, Beijing, China; Naval Research Academy (NVRA), Beijing, China; College of Electrical Science, National University of Defense Technology, Changsha, China","IEEE Sensors Journal","15 Aug 2019","2019","19","18","7915","7922","Multiple false target images deception is an effective strategy to protect vital military targets from detection and recognition by inverse synthetic aperture radar (ISAR). Previous research about it focuses mainly on the interrupted-sampling and sub-Nyquist sampling repeater jamming based on digital radio frequency memory (DRFM). The digital image synthesis (DIS) technique or scatter-wave modulation is used to simulate electromagnetic scattering of the real target. However, it is difficult to realize due to the high reconnaissance accuracy requirement and a heavy computational burden. Moreover, the protected target remains in the same location and the false targets' amplitude envelope based on periodic modulation is relatively fixed, which is not conducive to deception. In this paper, an ISAR image modulation method based on coding phase-switched screen (PSS) is proposed against ISAR. The method uses the target bait made of PSS or attaches the PSS to the protected target surface to impose phase modulation onto the reflected signal. As a result, multiple false target images with verisimilar properties are formed around the protected target position when the reflected signal is received and processed by the victim ISAR. Besides, the protected target is concealed and the flexible amplitude control of false targets is achieved. The simulation results are performed to verify the effectiveness of the proposed method.","1558-1748","","10.1109/JSEN.2019.2917432","National Natural Science Foundation of China(grant numbers:61372170); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8717672","Inverse synthetic aperture radar (ISAR);phase-switched screen (PSS);false targets;coding modulation","Jamming;Frequency modulation;Radar imaging;Encoding;Switches","digital radio;electromagnetic wave scattering;image coding;jamming;military radar;object recognition;phase modulation;radar imaging;radar target recognition;synthetic aperture radar","electromagnetic scattering;periodic modulation;ISAR image modulation method;coding phase-switched screen;PSS;target bait;protected target surface;phase modulation;reflected signal;protected target position;victim ISAR;inverse synthetic aperture radar image modulation method;multiple false target images deception;vital military targets;interrupted-sampling;digital radio frequency memory;digital image synthesis technique;scatter-wave modulation","","8","","33","IEEE","17 May 2019","","","IEEE","IEEE Journals"
"Physical-aware Radar Image Synthesis with Projective Network","Q. Song; F. Xu; X. X. Zhu","Remote Sensing Technology Institute, German Aerospace Center, Wessling, Germany; Key Laboratory for Information Science of Electromagnetic Waves (MoE), Fudan University, Shanghai, China; Remote Sensing Technology Institute, German Aerospace Center, Wessling, Germany","2021 XXXIVth General Assembly and Scientific Symposium of the International Union of Radio Science (URSI GASS)","14 Oct 2021","2021","","","1","4","This paper proposed a new network module named as projection network, which explicitly combined radar's projection process with trainable network. It assumes that each 2D radar cross section (RCS) map is a projection of a 3D RCS map. And it models the projection mechanism as a differentiable layer, so that it can be integrated with other neural network layers, such as convolutional and pooling layers. The proposed model is consistent with radar projection process, hence effects such as layover is considered. It is designed and used specifically for radar applications. This paper applied the proposed network on radar image synthesis, and the simulation results showed great potential of projective network.","2642-4339","978-9-4639-6-8027","10.23919/URSIGASS51995.2021.9560559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9560559","","Graphics;Solid modeling;Radar cross-sections;Three-dimensional displays;Image synthesis;Simulation;Neural networks","neural nets;radar cross-sections;radar imaging;synthetic aperture radar","projection network;trainable network;2D radar cross section map;3D RCS map;projection mechanism;neural network layers;radar projection process;radar applications;projective network;physical-aware radar image synthesis;network module","","","","9","","14 Oct 2021","","","IEEE","IEEE Conferences"
"Successive Stripe Artifact Removal Based on Robust PCA for Millimeter Wave Automotive Radar Image","W. Shan; S. Muramatsu; A. Oshima; H. Yamada","Graduate School of Science and Technology, Niigata Univ., Niigata, Japan; Faculty of Engineering, Niigata Univ., Niigata, Japan; Graduate School of Science and Technology, Niigata Univ., Niigata, Japan; Faculty of Engineering, Niigata Univ., Niigata, Japan","2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)","5 Mar 2020","2019","","","1391","1394","This study proposes a stripe artifact removal method based on robust principal component analysis (RPCA) for millimeter wave (MW) automotive radar images. With the development of MW radar detection technology, there is a demand for installing obstacle detectors on vehicular for safety. From this background, the authors developed squint-mode synthetic aperture radar (SAR) with MW (MW-SAR) as a high-resolution imaging technique. For synthesizing radar images, a back-projection algorithm (BPA) is adopted because of its real-time processing nature with high accuracy. However, SAR images obtained with Single Input and Single Output (SISO) systems are prone to be contaminated by a stripe-shaped artifact and can affect to the obstacle detection performance. Thus, to reduce the structured noise, this paper proposes successive RPCA on the assumption that the stripe artifacts and obstacle reflection are low-rank and sparse, respectively. As a solver, the alternating direction method of multipliers (ADMM) is adopted. The main contribution of this work is to initialize the ADMM state by taking account of the similarity of low-rank components between adjacent segments. Through simulations with experimental data, the significance of the proposed method is verified.","2640-0103","978-1-7281-3248-8","10.1109/APSIPAASC47483.2019.9023349","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023349","","Synthetic aperture radar;Convex functions;Radar imaging;Image segmentation;Millimeter wave radar;Automotive engineering","millimetre wave radar;optimisation;principal component analysis;radar detection;radar imaging;road vehicle radar;synthetic aperture radar","millimeter wave automotive radar image;stripe artifact removal method;robust principal component analysis;MW radar detection technology;squint-mode synthetic aperture radar;MW-SAR;high-resolution imaging technique;radar image synthesis;real-time processing nature;SAR images;stripe-shaped artifact;obstacle detection performance;obstacle reflection;low-rank components;robust PCA;obstacle detectors;alternating direction method of multipliers","","2","","10","IEEE","5 Mar 2020","","","IEEE","IEEE Conferences"
"Formation Flying SAR: Analysis of Imaging Performance by Array Theory","A. Renga; M. D. Graziano; A. Moccia","University of Naples Federico II, Naples, Italy; University of Naples Federico II, Naples, Italy; University of Naples Federico II, Naples, Italy","IEEE Transactions on Aerospace and Electronic Systems","8 Jun 2021","2021","57","3","1480","1497","This article analyzes the process of image synthesis for a formation flying synthetic aperture radar (FF-SAR), which is a multistatic synthetic aperture radar (SAR) based on a cluster of receiving-only satellites flying in a close formation, in the framework of the array theory. Indeed, the imaging properties of different close receivers, when analyzed as isolated items, are very similar and form the so-called common array. Moreover, the relative positions among the receivers implicitly define a physical array, referred to as spatial diversity array. FF-SAR imaging can be verified as a result of the spatial diversity array weighting the common array. Hence, different approaches to beamforming can be applied to the spatial diversity array to provide the FF-SAR with distinctive capabilities, such as coherent resolution enhancement and high-resolution wide-swath imaging. Simulation examples are discussed which confirm that array theory is a powerful tool to quickly and easily characterize FF-SAR imaging performance.","1557-9603","","10.1109/TAES.2020.3043526","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9288956","Array theory;distributed arrays;formation flying SAR (FF-SAR);high-resolution wide-swath imaging;multistatic SAR;spaceborne SAR;synthetic aperture radar(sar)","Receivers;Synthetic aperture radar;Imaging;Satellites;Transmitters;Radar imaging;Spatial diversity","array signal processing;radar imaging;remote sensing by radar;synthetic aperture radar","common array;spatial diversity array;high-resolution wide-swath imaging;array theory;FF-SAR imaging performance;formation flying SAR;image synthesis;multistatic synthetic aperture radar;receiving-only satellites;imaging properties;receivers;physical array","","4","","56","CCBY","9 Dec 2020","","","IEEE","IEEE Journals"
"K-Means Clustering Guided Generative Adversarial Networks for SAR-Optical Image Matching","W. -L. Du; Y. Zhou; J. Zhao; X. Tian","School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; Engineering Research Center of Mine Digitization, Ministry of Education of the People’s Republic of China, Xuzhou, China; School of Computer Science and Technology, China University of Mining and Technology, Xuzhou, China; State Key Laboratory of Lunar and Planetary Sciences, Macau University of Science and Technology, Taipa, Macau","IEEE Access","11 Dec 2020","2020","8","","217554","217572","Synthetic Aperture Radar and optical (SAR-optical) image matching is a technique of finding correspondences between SAR and optical images. SAR-optical image matching can be simplified to single-mode image matching through image synthesis. However, the existing SAR-optical image synthesis methods are unable to provide qualified images for SAR-optical image matching. In this work, we present a K-means Clustering Guide Generative Adversarial Networks (KCG-GAN) to improve the image quality of synthesizing by constraining spatial information synthesis. KCG-GAN uses k-means segmentations as one of the image generator's inputs and introduces feature matching loss, segmentation loss, and L1 loss to the objective function. Meanwhile, to provide repeatable k-means segmentations, we develop a straightforward 1D k-means algorithm. We compare KCG-GAN with a leading image synthesis method-pix2pixHD. Qualitative results illustrate that KCG-GAN preserves more spatial structures than pix2pixHD. Quantitative results show that, compared with pix2pixHD, images synthesized by KCG-GAN are more similar to original optical images, and SAR-optical image matching based on KCG-GAN obtains at most 3.15 times more qualified matchings. Robustness tests demonstrate that SAR-optical image matching based on KCG-GAN is robust to rotation and scale changing. We also test three SIFT-like algorithms on matching original SAR-optical image pairs and matching KCG-GAN synthesized optical-optical image pairs. Experimental results show that our KCG-GAN significantly improves the performances of the three algorithms on SAR-optical image matching.","2169-3536","","10.1109/ACCESS.2020.3042213","National Natural Science Foundation of China(grant numbers:61572505,62002360,61806206,61772530,U1610124); Six Talent Peaks Project in Jiangsu Province(grant numbers:2015-DZXX-010); Natural Science Foundation of Jiangsu Province(grant numbers:BK20180639,BK20171192); China Postdoctoral Science Foundation(grant numbers:2018M642359); Science and Technology Development Fund of Macau(grant numbers:0038/2020/A1); Science and Technology Development Fund, Macu SAR under the open project of State Key Laboratory of Lunar and Planetary Science; Fundamental Research Funds for the Central Universities(grant numbers:2020ZDPY0305); Xuzhou Science and Technology Program(grant numbers:KC18061); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9279214","Image matching;image synthesis;synthetic aperture radar (SAR);generative adversarial networks (GANs)","Optical imaging;Optical sensors;Nonlinear optics;Image segmentation;Image matching;Optical distortion;Adaptive optics","image matching;image segmentation;neural nets;optical information processing;pattern clustering;radar computing;radar imaging;synthetic aperture radar;transforms","KCG-GAN;image synthesis method;SAR-optical image matching;optical-optical image pairs;SAR-optical image synthesis methods;k-means clustering guide generative adversarial networks;synthetic aperture radar;constraining spatial information synthesis;k-means segmentations;1D k-means algorithm;pix2pixHD;SIFT-like algorithms","","7","","69","CCBY","3 Dec 2020","","","IEEE","IEEE Journals"
"SAR Target Image Generation Method Using Azimuth-Controllable Generative Adversarial Network","C. Wang; J. Pei; X. Liu; Y. Huang; D. Mao; Y. Zhang; J. Yang","Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","11 Nov 2022","2022","15","","9381","9397","Sufficient synthetic aperture radar (SAR) target images are very important for the development of research works. However, available SAR target images are often limited in practice, which hinders the progress of SAR application. In this article, we propose an azimuth-controllable generative adversarial network to generate precise SAR target images with an intermediate azimuth between two given SAR images' azimuths. This network mainly contains three parts: 1) generator, 2) discriminator, and 3) predictor. Through the proposed specific network structure, the generator can extract and fuse the optimal target features from two input SAR target images to generate an SAR target image. Then, a similarity discriminator and an azimuth predictor are designed. The similarity discriminator can differentiate the generated SAR target images from the real SAR images to ensure the accuracy of the generated while the azimuth predictor measures the difference of azimuth between the generated and the desired to ensure the azimuth controllability of the generated. Therefore, the proposed network can generate precise SAR images, and their azimuths can be controlled well by the inputs of the deep network, which can generate the target images in different azimuths to solve the small sample problem to some degree and benefit the research works of SAR images. Extensive experimental results show the superiority of the proposed method in azimuth controllability and accuracy of SAR target image generation.","2151-1535","","10.1109/JSTARS.2022.3218369","National Natural Science Foundation of China(grant numbers:61901091,61901090); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9933645","Automatic target recognition (ATR);azimuth-controllable;deep learning;generative adversarial network (GAN);synthetic aperture radar (SAR);target image generation","Synthetic aperture radar;Azimuth;Radar polarimetry;Generative adversarial networks;Generators;Image synthesis;Target recognition","control engineering computing;neural nets;radar computing;radar imaging;radar tracking;synthetic aperture radar;target tracking;telecommunication control","synthetic aperture radar target images;azimuth controllable generative adversarial network;different azimuths;azimuth controllability;generated SAR target images;azimuth predictor;similarity discriminator;input SAR target images;optimal target features;intermediate azimuth;SAR application;available SAR target images;SAR target image generation method","","","","52","CCBY","31 Oct 2022","","","IEEE","IEEE Journals"
"SAR image synthesis with GAN and continuous aspect angle and class constraints","Y. Giry-Fouquet; A. Baussard; C. Enderli; T. Porges",NA; NA; NA; NA,"EUSAR 2022; 14th European Conference on Synthetic Aperture Radar","10 Nov 2022","2022","","","1","6","Target classification generally requires large databases, especially for deep learning methods. However, it is not always possible to have access to a database of sufficient size for certain imaging modalities. For example, in synthetic aperture radar (SAR) imaging only limited incidence angles and aspect angles can be available. Unfortunately, to overcome this problem, most of the classical data augmentation methods are inappropriate for SAR data. Thus, in a previous work, we evaluated conditional Generative Adversarial Networks to generate synthetic SAR images at given aspect angles and for specific target classes. Among the various models evaluated the so-called StyleGAN2-ada, slightly modified to take into account the specificity of SAR images, appear to be the most efficient model. However, we observed that some of the generated images had wrong aspect angles. In this contribution we propose to correct this problem by adding a regularization term recently proposed in a model called Generator Regularized-cGAN. Our experiments show that this modification strongly reduce the problem.","","978-3-8007-5823-4","","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9944365","","","","","","","","","","10 Nov 2022","","","VDE","VDE Conferences"
"Synthesizing Optical and SAR Imagery From Land Cover Maps and Auxiliary Raster Data","G. Baier; A. Deschemps; M. Schmitt; N. Yokoya","RIKEN Center for Advanced Intelligence Project, Tokyo, Japan; SERPICO Team of Inria, Bretagne-Atlantique, Rennes, France; Department of Geoinformatics, Munich University of Applied Sciences, Munich, Germany; RIKEN Center for Advanced Intelligence Project, Tokyo, Japan","IEEE Transactions on Geoscience and Remote Sensing","20 Dec 2021","2022","60","","1","12","We synthesize both optical RGB and synthetic aperture radar (SAR) remote sensing images from land cover maps and auxiliary raster data using generative adversarial networks (GANs). In remote sensing, many types of data, such as digital elevation models (DEMs) or precipitation maps, are often not reflected in land cover maps but still influence image content or structure. Including such data in the synthesis process increases the quality of the generated images and exerts more control on their characteristics. Spatially adaptive normalization layers fuse both inputs and are applied to a full-blown generator architecture consisting of encoder and decoder to take full advantage of the information content in the auxiliary raster data. Our method successfully synthesizes medium (10 m) and high (1 m) resolution images when trained with the corresponding data set. We show the advantage of data fusion of land cover maps and auxiliary information using mean intersection over unions (mIoUs), pixel accuracy, and Fréchet inception distances (FIDs) using pretrained U-Net segmentation models. Handpicked images exemplify how fusing information avoids ambiguities in the synthesized images. By slightly editing the input, our method can be used to synthesize realistic changes, i.e., raising the water levels. The source code is available at https://github.com/gbaier/rs_img_synth, and we published the newly created high-resolution data set at https://ieee-dataport.org/open-access/geonrw.","1558-0644","","10.1109/TGRS.2021.3068532","Japan Society for the Promotion of Science through KAKENHI(grant numbers:18K18067,20K19834); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406194","Deep learning;generative adversarial network (GAN);image synthesis;synthetic aperture radar (SAR)","Generators;Semantics;Remote sensing;Image synthesis;Radar polarimetry;Image segmentation;Training","geophysical image processing;image segmentation;land cover;synthetic aperture radar;terrain mapping","land cover maps;auxiliary raster data;synthetic aperture radar remote sensing images;precipitation maps;image content;high resolution images;data fusion;synthesized images;high-resolution data;optical Imagery;SAR Imagery;optical RGB;generative adversarial networks;size 1.0 m;size 10.0 m","","7","","49","IEEE","16 Apr 2021","","","IEEE","IEEE Journals"
"Implementation of Block Adaptive Quantizer as a peripheral module for the FPGA-based SAR system","M. Knioła; A. Kawalec; C. Leśnik; M. Szugajew","Faculty of Electronics, Military University of Technology, Warsaw, POLAND; Faculty of Electronics, Military University of Technology, Warsaw, POLAND; Faculty of Electronics, Military University of Technology, Warsaw, POLAND; Faculty of Electronics, Military University of Technology, Warsaw, POLAND","2017 18th International Radar Symposium (IRS)","14 Aug 2017","2017","","","1","9","Due to large quantity of data needed for image synthesis in SAR applications, methods of raw signal compression were developed alongside actual imaging systems. Although performance of modern processing units allows on-platform, online image synthesis, data compressor still can be a valuable addition. Since it is no longer necessary part of SAR system, it should be delivered in a flexible, easy to use and low cost form - like low-resources demanding Intellectual Property core. In this paper chosen properties of raw SAR signal and some of compression methods are presented followed by compressor IP core implementation results.","2155-5753","978-3-7369-9343-3","10.23919/IRS.2017.8008231","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008231","","Synthetic aperture radar;Image coding;Reflection;Standards;Algorithm design and analysis;Signal processing algorithms;IP networks","data compression;field programmable gate arrays;image coding;quantisation (signal);radar imaging;synthetic aperture radar","FPGA-based SAR system;peripheral module;block adaptive quantizer implementation;raw signal compression method;imaging system;on-platform online image synthesis;data compressor;intellectual property core;compressor IP core implementation","","2","","10","","14 Aug 2017","","","IEEE","IEEE Conferences"
"A new method of high resolution SAR image synthesis reducing speckle noise","E. Shiro","Toronto, Canada","2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)","4 Dec 2017","2017","","","5374","5377","A new “reverse synthesis” method for the speckle noise reduction conducted concurrently with the SAR image synthesis is proposed. The method keeps high resolution for high-quality pixels and averages by neighbors the pixels affected by the speckle noise. The method is based on analysis of the quality of each pixel to resemble the “corner reflector” reflection property. The approach was tested with the raw echo data from the Soviet Almaz-1A SAR satellite.","2153-7003","978-1-5090-4951-6","10.1109/IGARSS.2017.8128218","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128218","SAR;speckle noise","Image resolution;Speckle;Earth;Image generation;Reflection;Buildings;Noise reduction","geophysical image processing;image denoising;image resolution;remote sensing by radar;synthetic aperture radar","corner reflector reflection property;Soviet Almaz-1A SAR satellite;neighbors the pixels;high-quality pixels;speckle noise reduction;reverse synthesis method;high resolution SAR image synthesis","","3","","1","IEEE","4 Dec 2017","","","IEEE","IEEE Conferences"
"Method for Optimization of the Radar Image Synthesis in the Case of High Antenna Squint","V. K. Tsvetkov; A. Y. Sheremet; V. A. Zhmylev; Z. V. Merkulova; D. A. Baiguzov","National Research University of Electronic Technology ""MIET"", Zelenograd, Moscow; National Research University of Electronic Technology ""MIET"", Zelenograd, Moscow; National Research University of Electronic Technology ""MIET"", Zelenograd, Moscow; National Research University of Electronic Technology ""MIET"", Zelenograd, Moscow; National Research University of Electronic Technology ""MIET"", Zelenograd, Moscow","2019 IEEE Conference of Russian Young Researchers in Electrical and Electronic Engineering (EIConRus)","3 Mar 2019","2019","","","2030","2033","In radar image synthesis there are methods which allow improving the performance by reducing the number of samples in the obtained response signal. However, applying these methods before the azimuth Fourier transform can result in significant distortions. The first source of distortions is the uneven frequency response of simple decimation methods which can be mostly unnoticeable. The second type of distortions is the antenna squint and the corresponding Doppler shift in the azimuth spectrum which can be unknown. As simple decimation applies the low-pass filter response to the hologram spectrum, the effective signal might be eliminated. The proposed in this paper method allows to determine the position of Doppler spectrum as well as to suppress only the noise spectrum components, resulting in higher performance without the loss of the image quality.","2376-6565","978-1-7281-0339-6","10.1109/EIConRus.2019.8657284","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8657284","SAR;FFT;azimuth synthesis kernel;optimization","Radar imaging;Azimuth;Doppler shift;Image quality;Doppler radar","Doppler radar;Doppler shift;Fourier transforms;frequency response;low-pass filters;radar imaging;spectral analysis;synthetic aperture radar","high antenna squint;radar image synthesis;response signal;azimuth Fourier transform;uneven frequency response;azimuth spectrum;hologram spectrum;effective signal;Doppler spectrum;image quality;Doppler shift;low-pass filter;decimation methods","","1","","4","IEEE","3 Mar 2019","","","IEEE","IEEE Conferences"
"Semi-Supervised SAR ATR via Conditional Generative Adversarial Network with Multi-Discriminator","X. Liu; Y. Huang; C. Wang; J. Pei; W. Huo; Y. Zhang; J. Yang","School of Information and Communication Engineering University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering University of Electronic Science and Technology of China, Chengdu, China; School of Information and Communication Engineering University of Electronic Science and Technology of China, Chengdu, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","2361","2364","Convolutional neural networks (CNN) show superior potential in synthetic aperture radar automatic target recognition (SAR ATR). However, due to the difficulty of obtaining SAR images and the scarcity of labeled SAR images, supervised learning has poor performance in this area and is not widely applicable. To address this problem, a semi-supervised conditional generative adversarial network with a multi-discriminator (SCGAN-MD) is proposed in this paper. In our method, a conditional generative adversarial network (CGAN) is adopted with two discriminators for training the generated images and predicting the labels for unlabeled samples. Compared with other semi-supervised learning-based methods, our proposed method has more accurate image generation capability and can achieve improved recognition accuracy of SAR ATR. Experiments on the Moving and Stationary Target Acquisition and Recognition (MSTAR) database indicate that the proposed method can effectively improve the recognition accuracy and robustness of the network with a small number of labeled samples.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554365","National Natural Science Foundation of China(grant numbers:61901091,61901090,61671117); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554365","SAR ATR;semi-supervised;conditional generative adversarial network","Training;Image recognition;Target recognition;Image synthesis;Supervised learning;Generative adversarial networks;Feature extraction","image recognition;neural nets;radar computing;radar imaging;radar target recognition;supervised learning;synthetic aperture radar","recognition accuracy;semisupervised SAR ATR;conditional generative adversarial network;multidiscriminator;convolutional neural networks;synthetic aperture radar automatic target recognition;labeled SAR images;supervised learning;semisupervised learning-based methods;image generation capability;CNN;SCGAN-MD;CGAN;moving and stationary target acquisition and recognition database;MSTAR database","","3","","9","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"A Semi-Supervised Image-to-Image Translation Framework for SAR–Optical Image Matching","W. -L. Du; Y. Zhou; H. Zhu; J. Zhao; Z. Shao; X. Tian","Engineering Research Center of Mine Digitization, Ministry of Education of Peoples Republic of China, Xuzhou, China; Engineering Research Center of Mine Digitization, Ministry of Education of Peoples Republic of China, Xuzhou, China; Engineering Research Center of Mine Digitization, Ministry of Education of Peoples Republic of China, Xuzhou, China; Engineering Research Center of Mine Digitization, Ministry of Education of Peoples Republic of China, Xuzhou, China; Engineering Research Center of Mine Digitization, Ministry of Education of Peoples Republic of China, Xuzhou, China; State Key Laboratory of Lunar and Planetary Sciences, Macau University of Science and Technology, Taipa, Macau","IEEE Geoscience and Remote Sensing Letters","1 Dec 2022","2022","19","","1","5","Synthetic aperture radar (SAR) and optical image matching aims to acquire correspondences from a certain pair of SAR and optical images. Recent advances in the image-to-image translation provided a way to simplify the SAR–optical image matching into the SAR–SAR or optical–optical image matchings. The existing image-to-image translations mainly focus on supervised or unsupervised learning. However, gathering sufficient amounts of aligned training data for supervised learning is challenging, while unsupervised learning cannot guarantee enough correct correspondences. In this work, we investigate the applicability of semi-supervised image-to-image translation for SAR–optical image matching such that both aligned and unaligned SAR–optical images could be used. To this end, we combine the benefits of both supervised and unsupervised well-known image-to-image translation methods, i.e., Pix2pix and CycleGAN, and propose a simple yet effective semi-supervised image-to-image translation framework. Through extensive experimental comparisons to the baseline methods, we verify the effectiveness of the proposed framework in both semi-supervised and fully supervised settings. Our codes are available at https://github.com/WenliangDu/Semi-I2I.","1558-0571","","10.1109/LGRS.2022.3223353","National Natural Science Foundation of China(grant numbers:62002360,62272461,62101555,61806206,62106268); Science and Technology Development Fund of Macau (Macau FDCT)(grant numbers:0038/2020/A1); Opening Fund of State Key Laboratory of Lunar and Planetary Sciences (Macau University of Science and Technology) (Macau FDCT)(grant numbers:119/2017/A3); Natural Science Foundation of Jiangsu Province(grant numbers:BK20201346,BK20210488); “Double First-Class” Project of China University of Mining and Technology for Independent Innovation and Social Service(grant numbers:2022ZZCX06); China Postdoctoral Science Foundation(grant numbers:2022M713379); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9955555","Generative adversarial networks (GANs);image matching;semi-supervised image synthesis;synthetic aperture radar (SAR)","Optical imaging;Optical sensors;Adaptive optics;Image matching;Training;Synthetic aperture radar;Optical distortion","image matching;learning (artificial intelligence);optical images;radar imaging;synthetic aperture radar;unsupervised learning","aligned SAR-optical images;fully supervised settings;image-to-image translation methods;optical image matching;optical-optical image matchings;SAR-optical image;SAR-SAR;semisupervised image-to-image translation framework;unaligned SAR-optical images","","","","14","IEEE","18 Nov 2022","","","IEEE","IEEE Journals"
"Atrous cGAN for SAR to Optical Image Translation","J. Noa Turnes; J. D. B. Castro; D. L. Torres; P. J. S. Vega; R. Q. Feitosa; P. N. Happ","Department of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Department of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Department of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Department of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Department of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil; Department of Electrical Engineering, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro, Brazil","IEEE Geoscience and Remote Sensing Letters","17 Dec 2021","2022","19","","1","5","Conditional (cGAN)-based methods proposed so far for synthetic aperture radar (SAR)-to-optical image synthesis tend to produce noisy and unsharp optical outcomes. In this work, we propose the atrous-cGAN, a novel cGAN architecture that improves the SAR-to-optical image translation. The proposed generator and discriminator networks rely on atrous convolutions and incorporate an atrous spatial pyramid pooling (ASPP) module to enhance fine details in the generated optical image by exploiting spatial context at multiple scales. This letter reports experiments carried out to assess the performance of atrous-cGAN for the synthesis of Landsat-8 images from Sentinel-1A data based on three public data sets. The experimental analysis indicated that the atrous-cGAN consistently outperformed the classical pix2pix counterpart in terms of visual quality, similar to the true optical image, and as a feature learning tool for semantic segmentation.","1558-0571","","10.1109/LGRS.2020.3031199","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior (CAPES); Conselho Nacional de Desenvolvimento Científico e Tecnológico (CNPq); NVIDIA Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9241239","Atrous spatial pyramid pooling (ASPP);generative adversarial networks;synthetic aperture radar (SAR)-optical synthesis","Optical imaging;Optical sensors;Generators;Synthetic aperture radar;Convolutional codes;Optical interferometry;Artificial satellites","geophysical image processing;image classification;image enhancement;image segmentation;learning (artificial intelligence);object detection;optical images;radar imaging;synthetic aperture radar","incorporate;atrous spatial pyramid pooling module;generated optical image;Landsat-8 images;atrous-cGAN;atrous cGAN;conditional-based methods;radar-to-optical image synthesis;noisy outcomes;unsharp optical outcomes;SAR-to-optical image translation;generator;discriminator networks;atrous convolutions;current 1.0 A","","10","","18","IEEE","27 Oct 2020","","","IEEE","IEEE Journals"
"ISAR Images Generation Via Generative Adversarial Networks","R. -Y. Zhou; Z. -L. Yang; F. Wang","Key laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China; Key laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China; Key laboratory for Information Science of Electromagnetic Waves (MoE), School of Information Science and Technology, Fudan University, Shanghai, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","5267","5270","One of the challenges faced by current intelligent target recognition tasks is the lack of samples, especially in the Inverse Synthetic Aperture Radar (ISAR) images understanding. In this paper, we proposed an ISAR objects generative network to generate multi-aspect ISAR images. A simulated ISAR dataset of six types of aircrafts is produced via, using bidirectional analytic ray tracing (BART) method. Then, the proposed generative network is trained with the simulated ISAR dataset. We evaluated the performance of the proposed network using structural similarity (SSIM). The experimental results show that the generated targets are very close to the real ISAR samples, and the SSIM between generated and real ISAR images of aircrafts is larger than 0.7.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9553814","National Natural Science Foundation of China(grant numbers:61901122); Natural Science Foundation of Shanghai(grant numbers:20ZR1406300); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9553814","Inverse Synthetic Aperture Radar (ISAR);Automatic Target Recognition (ATR);Generative Adversarial Nets (GANs)","Training;Target recognition;Image synthesis;Geoscience and remote sensing;Ray tracing;Generative adversarial networks;Aircraft","","","","1","","12","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Multi-Category SAR Images Generation Based on Improved Generative Adversarial Network","S. Du; J. Hong; Y. Wang; K. Xing; T. Qiu","National Key Laboratory of Science and Technology on Microwave Imaging, Aerospace Information Research Institute, Chinese Academy of Sciences, China; National Key Laboratory of Science and Technology on Microwave Imaging, Aerospace Information Research Institute, Chinese Academy of Sciences, China; National Key Laboratory of Science and Technology on Microwave Imaging, Aerospace Information Research Institute, Chinese Academy of Sciences, China; National Key Laboratory of Science and Technology on Microwave Imaging, Aerospace Information Research Institute, Chinese Academy of Sciences, China; National Key Laboratory of Science and Technology on Microwave Imaging, Aerospace Information Research Institute, Chinese Academy of Sciences, China","2021 IEEE International Geoscience and Remote Sensing Symposium IGARSS","12 Oct 2021","2021","","","4260","4263","The generative adversarial network (GAN) provides a different way for SAR data augmentation. The traditional GAN model is mainly based on the Jensen-Shannon (JS) divergence or Wasserstein distance. The former faces mode collapse, while the latter is not suitable for multi-category image generation. In this paper, an improved model based on WGAN-GP is proposed. An encoder is used to learn the features of real samples as the input of the generator to control training to a certain extent and make the generated image quality better. In addition, a pre-trained classifier is introduced as the constraint of the generator to ensure the generated images have the correct category information. MSTAR dataset is used to verify the generation capability of the proposed model. The results show that the proposed model has the stable generation capability to provide high-quality SAR images as a supplementary training dataset, which could assist in achieving good classification accuracy.","2153-7003","978-1-6654-0369-6","10.1109/IGARSS47720.2021.9554120","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9554120","P-band;calibration;BIOMASS;parabolic antenna;target of opportunity","Training;Image quality;Image synthesis;Geoscience and remote sensing;Generative adversarial networks;Generators;Radar polarimetry","image classification;learning (artificial intelligence);maximum likelihood estimation;pattern classification;radar imaging;synthetic aperture radar","SAR data augmentation;traditional GAN model;faces mode collapse;multicategory image generation;generated image quality;pre-trained classifier;correct category information;stable generation capability;high-quality SAR images;supplementary training dataset;multicategory SAR images generation;improved generative adversarial network","","","","7","IEEE","12 Oct 2021","","","IEEE","IEEE Conferences"
"Deep Learning-Based SAR Interferogram Synthesis from Raster and Land Cover Data","P. Sibler; F. Sica; M. Schmitt","Hensoldt Sensors GmbH, Immenstaad, Germany; Department of Aerospace Engineering, University of the Bundeswehr Munich, Germany; Department of Aerospace Engineering, University of the Bundeswehr Munich, Germany","IGARSS 2022 - 2022 IEEE International Geoscience and Remote Sensing Symposium","28 Sep 2022","2022","","","5236","5239","Image-to-image translation between different imaging modalities in Earth observation has become a widely utilized application area of deep learning. However, most of the translation is performed on real-valued data, to some extent neglecting the opportunities of complex-valued SAR data for interferometric methods. In this work, we propose a multi-task deep learning approach for simulating complex-valued InSAR data based on splitting the overall task into multi-modal image-toimage translation sub-tasks. Instead of synthesizing complex-valued SAR data directly, magnitudes, phase values and coherence magnitudes are simulated in parallel and combined to full complex-valued information afterward. With experiments on a Sentinel-1 interferogram, conditioned by DEM and land cover data, we demonstrate the feasibility of the approach.","2153-7003","978-1-6654-2792-0","10.1109/IGARSS46834.2022.9884964","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9884964","image synthesis;deep learning;CNN;GAN;autoencoder;multi-task;complex-valued;SAR;SAR interferometry;coherence estimation","Deep learning;Earth;Imaging;Geoscience and remote sensing;Estimation;Coherence;Multitasking","learning (artificial intelligence);radar imaging;radar interferometry;remote sensing by radar;synthetic aperture radar","land cover data;SAR interferogram synthesis;image-to-image translation;widely utilized application area;real-valued data;complex-valued SAR data;multitask deep learning approach;complex-valued InSAR data;multimodal image-toimage translation;phase values","","","","13","IEEE","28 Sep 2022","","","IEEE","IEEE Conferences"
"Attribute-Guided Generative Adversarial Network With Improved Episode Training Strategy for Few-Shot SAR Image Generation","Y. Sun; Y. Wang; L. Hu; Y. Huang; H. Liu; S. Wang; C. Zhang","National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China; Science and Technology on Electromagnetic Scattering Laboratory, Beijing Institute of Environmental Features, Beijing, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China; National Laboratory of Radar Signal Processing, Xidian University, Xi'an, China","IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing","13 Feb 2023","2023","16","","1785","1801","Deep-learning-based models usually require a large amount of data for training, which guarantees the effectiveness of the trained model. Generative models are no exception, and sufficient training data are necessary for the diversity of generated images. However, for synthetic aperture radar (SAR) images, data acquisition is expensive. Therefore, SAR image generation under a few training samples is still a challenging problem to be solved. In this article, we propose an attribute-guided generative adversarial network (AGGAN) with an improved episode training strategy for few-shot SAR image generation. First, we design the AGGAN structure, and spectral normalization is used to stabilize the training in the few-shot situation. The attribute labels of AGGAN are designed to be the category and aspect angle labels, which are essential information for SAR images. Second, an improved episode training strategy is proposed according to the characteristics of the few-shot generative task, and it can improve the quality of generated images in the few-shot situation. In addition, we explore the effectiveness of the proposed method when using different auxiliary data for training and use the Moving and Stationary Target Acquisition and Recognition benchmark dataset and a simulated SAR dataset for verification. The experimental results show that AGGAN and the proposed improved episode training strategy can generate images of better quality when compared with some existing methods, which have been verified through visual observation, image similarity measures, and recognition experiments. When applying the generated images to the 5-shot SAR image recognition problem, the average recognition accuracy can be improved by at least 4$\%$.","2151-1535","","10.1109/JSTARS.2023.3239633","National Natural Science Foundation of China(grant numbers:61671354); National Radar Signal Processing Laboratory(grant numbers:KGJ202206); Higher Education Discipline Innovation Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10025584","Few-shot image generation;generative adversarial network (GAN);meta-learning;synthetic aperture radar (SAR);transfer learning","Training;Radar polarimetry;Transfer learning;Task analysis;Image synthesis;Image recognition;Data models","","","","","","67","CCBYNCND","24 Jan 2023","","","IEEE","IEEE Journals"
"SAR Image Change Detection Based on Geometric Mean Operator and Extreme Learning Machine","Z. K. Ling; W. Liu; C. Y. Niu; R. S. Li; Q. Hu; Y. Q. Zang","PLA Strategic Support Force, Information Engineering University, Zhengzhou, Henan, China; PLA Strategic Support Force, Information Engineering University, Zhengzhou, Henan, China; PLA Strategic Support Force, Information Engineering University, Zhengzhou, Henan, China; PLA Strategic Support Force, Information Engineering University, Zhengzhou, Henan, China; PLA Strategic Support Force, Information Engineering University, Zhengzhou, Henan, China; PLA Strategic Support Force, Information Engineering University, Zhengzhou, Henan, China","2021 CIE International Conference on Radar (Radar)","8 Feb 2023","2021","","","962","965","Synthetic Aperture Radar (SAR) image is independent of atmospheric and sunlight conditions and can be acquired under all weather and all day. As a part of SAR image application, change detection has high practical value, such as urban sprawl detection, hazard assessment of earthquake areas. In this paper, we put forward a new difference image (DI) generated by geometric mean operator which combined with log-ratio, neighborhood ratio and normal difference operator, and retained the advantages of each operator. Then, a change detection method of SAR image based on extreme learning machine (ELM) is used to classify the pixels in two original SAR images to form the final change image. Experimental results on two real SAR image datasets show that the proposed difference image generation method is robust to speckle noise, and the change detection method based on the new DI operator and ELM can effectively detect variation information in multi-phase SAR images.","2640-7736","978-1-6654-9814-2","10.1109/Radar53847.2021.10028110","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10028110","SAR image;change detection;difference image;geometric mean;extreme learning machine","Visualization;Extreme learning machines;Statistical analysis;Image synthesis;Radar detection;Radar imaging;Speckle","","","","","","14","IEEE","8 Feb 2023","","","IEEE","IEEE Conferences"
